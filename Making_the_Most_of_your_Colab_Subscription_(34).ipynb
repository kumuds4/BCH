{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription_(34).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PI9KoJNn92sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IoPMYD3y9o3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "sPWvfcK5-Ews"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- Parameters ---\n",
        "N = 128                 # Polar code block length\n",
        "K = 64                  # Number of information bits (excluding CRC)\n",
        "CRC_LEN = 8             # CRC length in bits\n",
        "LIST_SIZE = 8           # List size for SCL decoder\n",
        "SNR_DB_RANGE = np.arange(0, 4.5, 0.5)  # SNR range in dB for simulation\n",
        "\n",
        "NUM_FRAMES = 1000       # Number of frames per SNR for simulation\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- CRC Functions (simple CRC-8) ---\n",
        "CRC_POLY = 0x07  # x^8 + x^2 + x + 1\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    \"\"\" Append CRC bits to info_bits (numpy array of 0/1). \"\"\"\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    \"\"\" Check CRC of codeword (info+CRC). Return True if passes. \"\"\"\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# --- Polar code construction (using reliability sequence for N=128) ---\n",
        "# Source: Arikan's polar sequence for N=128 (from 5G standards or literature)\n",
        "# The lower the index in this sequence, the more reliable the bit channel\n",
        "polar_reliability_sequence = [\n",
        "     0,  1,  2,  4,  8,  16,  3,  5,\n",
        "     9,  6,  10,  12,  17,  24,  7,  11,\n",
        "     13,  18,  25,  20,  26,  28,  14,  19,\n",
        "     21,  22,  27,  29,  30,  31,  15,  23,\n",
        "     32,  33,  34,  36,  40,  48,  35,  37,\n",
        "     41,  38,  42,  44,  49,  56,  39,  43,\n",
        "     45,  50,  57,  52,  58,  60,  46,  51,\n",
        "     53,  54,  59,  61,  62,  63,  47,  55,\n",
        "     64,  65,  66,  68,  72,  80,  67,  69,\n",
        "     73,  70,  74,  76,  81,  88,  71,  75,\n",
        "     77,  82,  89,  84,  90,  92,  78,  83,\n",
        "     85,  86,  91,  93,  94,  95,  79,  87,\n",
        "     96,  97,  98, 100, 104, 112,  99, 101,\n",
        "    105, 102, 106, 108, 113, 120, 103, 107,\n",
        "    109, 114, 121, 116, 122, 124, 110, 115,\n",
        "    117, 118, 123, 125, 126, 127, 111, 119\n",
        "]\n",
        "\n",
        "# Select frozen and information bit indices\n",
        "info_bits_indices = sorted(polar_reliability_sequence[:K + CRC_LEN])\n",
        "frozen_bits_indices = sorted(set(range(N)) - set(info_bits_indices))\n",
        "\n",
        "# --- Polar transform (encoder) ---\n",
        "def polar_transform(u):\n",
        "    \"\"\"Apply Polar transform recursively.\"\"\"\n",
        "    N = len(u)\n",
        "    if N == 1:\n",
        "        return u\n",
        "    else:\n",
        "        u1 = (u[0:N//2] ^ u[N//2:N])\n",
        "        u2 = u[N//2:N]\n",
        "        return np.concatenate([polar_transform(u1), polar_transform(u2)])\n",
        "\n",
        "def polar_encode(info_bits):\n",
        "    \"\"\"Encode info bits with CRC and frozen bits, apply polar transform.\"\"\"\n",
        "    # Append CRC bits\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    u[info_bits_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# --- BPSK Modulation and AWGN Channel ---\n",
        "def bpsk_modulation(x):\n",
        "    return 1 - 2*x  # 0->+1, 1->-1\n",
        "\n",
        "def awgn_channel(x, snr_db):\n",
        "    snr = 10**(snr_db/10)\n",
        "    sigma = np.sqrt(1/(2*snr))\n",
        "    noise = sigma * np.random.randn(*x.shape)\n",
        "    return x + noise, sigma\n",
        "\n",
        "# --- LLR calculation for BPSK over AWGN ---\n",
        "def llr_awgn(y, sigma):\n",
        "    return 2 * y / (sigma**2)\n",
        "\n",
        "# --- SC Decoder ---\n",
        "def sc_decode(llr, frozen_bits_indices):\n",
        "    \"\"\"Successive Cancellation decoder.\"\"\"\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "    # Initialize arrays\n",
        "    u_hat = np.zeros(N, dtype=int)\n",
        "\n",
        "    def recursive_decode(llr_sub, depth, offset):\n",
        "        if depth == 0:\n",
        "            # Leaf node\n",
        "            idx = offset\n",
        "            if idx in frozen_bits_indices:\n",
        "                return 0\n",
        "            else:\n",
        "                return 0 if llr_sub >= 0 else 1\n",
        "        else:\n",
        "            half = 2**(depth - 1)\n",
        "            llr_left = f_func(llr_sub[:half], llr_sub[half:])\n",
        "            left_bits = [recursive_decode(llr_left, depth-1, offset)]\n",
        "            llr_right = g_func(llr_sub[:half], llr_sub[half:], left_bits[0])\n",
        "            right_bits = [recursive_decode(llr_right, depth-1, offset + half)]\n",
        "            return left_bits + right_bits\n",
        "\n",
        "    def f_func(a, b):\n",
        "        return np.sign(a)*np.sign(b)*np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g_func(a, b, c):\n",
        "        return b + (1 - 2*c)*a\n",
        "\n",
        "    bits = recursive_decode(llr, n, 0)\n",
        "    return np.array(bits)\n",
        "\n",
        "# --- CRC-Aided SCL Decoder ---\n",
        "# For brevity, we implement a simplified version of SCL without path pruning\n",
        "# In practice, use optimized libraries, but here is a basic version\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, llr, path, metric):\n",
        "        self.llr = llr\n",
        "        self.path = path\n",
        "        self.metric = metric\n",
        "\n",
        "def scl_decode(llr, frozen_bits_indices, list_size=LIST_SIZE):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    paths = [([], 0.0)]  # List of (decoded bits, path metric)\n",
        "    for i in range(N):\n",
        "        new_paths = []\n",
        "        for path, metric in paths:\n",
        "            # If frozen bit, only one choice\n",
        "            if i in frozen_bits_indices:\n",
        "                bit = 0\n",
        "                # Update metric with log likelihood\n",
        "                llr_i = llr[i]\n",
        "                metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                new_paths.append((path + [bit], metric_new))\n",
        "            else:\n",
        "                # For info bits, consider both 0 and 1\n",
        "                for bit in [0, 1]:\n",
        "                    llr_i = llr[i]\n",
        "                    metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                    new_paths.append((path + [bit], metric_new))\n",
        "        # Keep only best list_size paths\n",
        "        new_paths.sort(key=lambda x: x[1])\n",
        "        paths = new_paths[:list_size]\n",
        "\n",
        "    # CRC check for paths, choose the first passing CRC or best metric\n",
        "    for path, metric in paths:\n",
        "        # Extract info+CRC bits\n",
        "        info_crc_bits = np.array(path)[info_bits_indices]\n",
        "        if crc_check(info_crc_bits):\n",
        "            return np.array(path)\n",
        "    # No CRC passed, return best path\n",
        "    return np.array(paths[0][0])\n",
        "\n",
        "# --- Simple RNN Decoder using PyTorch ---\n",
        "class SimpleRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
        "        super(SimpleRNNDecoder, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, input_size)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out.squeeze(-1)\n",
        "\n",
        "# --- Training and Evaluation Functions ---\n",
        "def generate_data(num_frames):\n",
        "    \"\"\"Generate random info bits and encode with CRC and polar.\"\"\"\n",
        "    info_bits = np.random.randint(0, 2, (num_frames, K))\n",
        "    coded_bits = np.array([polar_encode(ib) for ib in info_bits])\n",
        "    return info_bits, coded_bits\n",
        "\n",
        "def simulate_channel(coded_bits, snr_db):\n",
        "    \"\"\"BPSK modulate, add noise, return received signal and LLRs.\"\"\"\n",
        "    tx_signal = bpsk_modulation(coded_bits)\n",
        "    rx_signal, sigma = awgn_channel(tx_signal, snr_db)\n",
        "    llrs = llr_awgn(rx_signal, sigma)\n",
        "    return rx_signal, llrs, sigma\n",
        "\n",
        "def evaluate_decoder(decoder_func, info_bits, coded_bits, frozen_bits_indices, snr_db):\n",
        "    \"\"\"Evaluate given decoder function over frames.\"\"\"\n",
        "    total_bit_errors = 0\n",
        "    total_block_errors = 0\n",
        "    num_frames = len(info_bits)\n",
        "    for i in range(num_frames):\n",
        "        # Channel simulation\n",
        "        _, llr, _ = simulate_channel(coded_bits[i:i+1], snr_db)\n",
        "        llr = llr[0]\n",
        "        # Decode\n",
        "        decoded = decoder_func(llr, frozen_bits_indices)\n",
        "        # Extract info+CRC bits\n",
        "        decoded_info_crc = decoded[info_bits_indices]\n",
        "        # Count errors\n",
        "        bit_errors = np.sum(decoded_info_crc[:K] != info_bits[i])\n",
        "        total_bit_errors += bit_errors\n",
        "        total_block_errors += (bit_errors > 0)\n",
        "    ber = total_bit_errors / (num_frames * K)\n",
        "    bler = total_block_errors / num_frames\n",
        "    return ber, bler\n",
        "\n",
        "def evaluate_rnn_decoder(model, info_bits, coded_bits, snr_db, batch_size=32):\n",
        "    model.eval()\n",
        "    total_bit_errors = 0\n",
        "    total_block_errors = 0\n",
        "    num_frames = len(info_bits)\n",
        "    sigma = np.sqrt(1/(2*(10**(snr_db/10))))\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_frames, batch_size):\n",
        "            batch_coded = coded_bits[i:i+batch_size]\n",
        "            batch_info = info_bits[i:i+batch_size]\n",
        "            batch_size_curr = len(batch_coded)\n",
        "            tx_signal = bpsk_modulation(batch_coded)\n",
        "            noise = sigma * np.random.randn(*tx_signal.shape)\n",
        "            rx_signal = tx_signal + noise\n",
        "            llr = 2 * rx_signal / (sigma**2)\n",
        "            # Prepare input tensor for RNN: (batch, seq_len, input_size=1)\n",
        "            input_tensor = torch.tensor(llr, dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "            outputs = model(input_tensor)\n",
        "            outputs = outputs.cpu().numpy()\n",
        "            # Hard decision threshold 0.5\n",
        "            decoded_bits = (outputs < 0.5).astype(int)\n",
        "            for j in range(batch_size_curr):\n",
        "                decoded_info_crc = decoded_bits[j, info_bits_indices]\n",
        "                bit_errors = np.sum(decoded_info_crc[:K] != batch_info[j])\n",
        "                total_bit_errors += bit_errors\n",
        "                total_block_errors += (bit_errors > 0)\n",
        "    ber = total_bit_errors / (num_frames * K)\n",
        "    bler = total_block_errors / num_frames\n",
        "    return ber, bler\n",
        "\n",
        "# --- Main Simulation and Plotting ---\n",
        "def main():\n",
        "    print(f'Running simulation on device: {device}')\n",
        "    # Generate dataset for simulation\n",
        "    info_bits_all, coded_bits_all = generate_data(NUM_FRAMES)\n",
        "\n",
        "    # Evaluate SC and SCL decoders\n",
        "    ber_sc = []\n",
        "    bler_sc = []\n",
        "    ber_scl = []\n",
        "    bler_scl = []\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        print(f'Simulating at SNR = {snr_db} dB...')\n",
        "        ber_tmp, bler_tmp = evaluate_decoder(sc_decode, info_bits_all, coded_bits_all, frozen_bits_indices, snr_db)\n",
        "        ber_sc.append(ber_tmp)\n",
        "        bler_sc.append(bler_tmp)\n",
        "        ber_tmp, bler_tmp = evaluate_decoder(lambda llr, f: scl_decode(llr, f, list_size=LIST_SIZE),\n",
        "                                             info_bits_all, coded_bits_all, frozen_bits_indices, snr_db)\n",
        "        ber_scl.append(ber_tmp)\n",
        "        bler_scl.append(bler_tmp)\n",
        "\n",
        "    # --- Train simple RNN decoder ---\n",
        "    print('Training RNN decoder (this may take a moment)...')\n",
        "    rnn_model = SimpleRNNDecoder().to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "    epochs = 3  # For demo, increase for better performance\n",
        "    batch_size = 64\n",
        "\n",
        "    # Prepare training data\n",
        "    train_info, train_coded = generate_data(2000)\n",
        "    sigma_train = np.sqrt(1/(2*(10**(1.5))))  # Fixed training SNR at 1.5 dB\n",
        "\n",
        "    rnn_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        perm = np.random.permutation(len(train_info))\n",
        "        epoch_loss = 0\n",
        "        for i in range(0, len(train_info), batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            batch_info = train_info[idx]\n",
        "            batch_coded = train_coded[idx]\n",
        "            tx_signal = bpsk_modulation(batch_coded)\n",
        "            noise = sigma_train * np.random.randn(*tx_signal.shape)\n",
        "            rx_signal = tx_signal + noise\n",
        "            llr = 2 * rx_signal / (sigma_train**2)\n",
        "            # Inputs: LLRs, Targets: coded bits\n",
        "            inputs = torch.tensor(llr, dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "            targets = torch.tensor(batch_coded, dtype=torch.float32, device=device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = rnn_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluate RNN decoder\n",
        "    ber_rnn = []\n",
        "    bler_rnn = []\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        print(f'Evaluating RNN at SNR = {snr_db} dB...')\n",
        "        ber_tmp, bler_tmp = evaluate_rnn_decoder(rnn_model, info_bits_all, coded_bits_all, snr_db)\n",
        "        ber_rnn.append(ber_tmp)\n",
        "        bler_rnn.append(bler_tmp)\n",
        "\n",
        "    # --- Plot BER/BLER ---\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_sc, 'o-', label='SC Decoder BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_sc, 'o--', label='SC Decoder BLER')\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_scl, 's-', label=f'SCL Decoder (L={LIST_SIZE}) BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_scl, 's--', label=f'SCL Decoder (L={LIST_SIZE}) BLER')\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_rnn, 'd-', label='RNN Decoder BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_rnn, 'd--', label='RNN Decoder BLER')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('Polar Code BER/BLER Simulation')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "SVCHUA-bQbbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- Parameters ---\n",
        "N = 128                 # Polar code block length\n",
        "K = 64                  # Number of information bits (excluding CRC)\n",
        "CRC_LEN = 8             # CRC length in bits\n",
        "LIST_SIZE = 8           # List size for SCL decoder\n",
        "SNR_DB_RANGE = np.arange(0, 4.5, 0.5)  # SNR range in dB for simulation\n",
        "\n",
        "NUM_FRAMES = 1000       # Number of frames per SNR for simulation\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- CRC Functions (simple CRC-8) ---\n",
        "CRC_POLY = 0x07  # x^8 + x^2 + x + 1\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# --- Polar code construction ---\n",
        "polar_reliability_sequence = [\n",
        "     0,  1,  2,  4,  8,  16,  3,  5,\n",
        "     9,  6,  10,  12,  17,  24,  7,  11,\n",
        "     13,  18,  25,  20,  26,  28,  14,  19,\n",
        "     21,  22,  27,  29,  30,  31,  15,  23,\n",
        "     32,  33,  34,  36,  40,  48,  35,  37,\n",
        "     41,  38,  42,  44,  49,  56,  39,  43,\n",
        "     45,  50,  57,  52,  58,  60,  46,  51,\n",
        "     53,  54,  59,  61,  62,  63,  47,  55,\n",
        "     64,  65,  66,  68,  72,  80,  67,  69,\n",
        "     73,  70,  74,  76,  81,  88,  71,  75,\n",
        "     77,  82,  89,  84,  90,  92,  78,  83,\n",
        "     85,  86,  91,  93,  94,  95,  79,  87,\n",
        "     96,  97,  98, 100, 104, 112,  99, 101,\n",
        "    105, 102, 106, 108, 113, 120, 103, 107,\n",
        "    109, 114, 121, 116, 122, 124, 110, 115,\n",
        "    117, 118, 123, 125, 126, 127, 111, 119\n",
        "]\n",
        "\n",
        "info_bits_indices = sorted(polar_reliability_sequence[:K + CRC_LEN])\n",
        "frozen_bits_indices = sorted(set(range(N)) - set(info_bits_indices))\n",
        "\n",
        "# --- Polar transform ---\n",
        "def polar_transform(u):\n",
        "    N = len(u)\n",
        "    if N == 1:\n",
        "        return u\n",
        "    else:\n",
        "        u1 = (u[0:N//2] ^ u[N//2:N])\n",
        "        u2 = u[N//2:N]\n",
        "        return np.concatenate([polar_transform(u1), polar_transform(u2)])\n",
        "\n",
        "def polar_encode(info_bits):\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    u[info_bits_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# --- BPSK and Channel ---\n",
        "def bpsk_modulation(x):\n",
        "    return 1 - 2*x\n",
        "\n",
        "def awgn_channel(x, snr_db):\n",
        "    snr = 10**(snr_db/10)\n",
        "    sigma = np.sqrt(1/(2*snr))\n",
        "    noise = sigma * np.random.randn(*x.shape)\n",
        "    return x + noise, sigma\n",
        "\n",
        "def llr_awgn(y, sigma):\n",
        "    return 2 * y / (sigma**2)\n",
        "\n",
        "# --- SC Decoder ---\n",
        "def sc_decode(llr, frozen_bits_indices):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    def f_func(a, b):\n",
        "        return np.sign(a)*np.sign(b)*np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g_func(a, b, c):\n",
        "        return b + (1 - 2*c)*a\n",
        "\n",
        "    def recursive_decode(llr_sub, depth, offset):\n",
        "        if depth == 0:\n",
        "            idx = offset\n",
        "            if idx in frozen_bits_indices:\n",
        "                return [0]\n",
        "            else:\n",
        "                return [0] if llr_sub >= 0 else [1]\n",
        "        else:\n",
        "            half = 2**(depth - 1)\n",
        "            llr_left = f_func(llr_sub[:half], llr_sub[half:])\n",
        "            left_bits = recursive_decode(llr_left, depth-1, offset)\n",
        "            llr_right = g_func(llr_sub[:half], llr_sub[half:], left_bits[0])\n",
        "            right_bits = recursive_decode(llr_right, depth-1, offset + half)\n",
        "            return left_bits + right_bits\n",
        "\n",
        "    bits = recursive_decode(llr, n, 0)\n",
        "   # return np.array(bits)\n",
        "    return np.array(bits)[info_indices]\n",
        "\n",
        "    def f_func(a, b):\n",
        "        return np.sign(a)*np.sign(b)*np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g_func(a, b, c):\n",
        "        return b + (1 - 2*c)*a\n",
        "\n",
        "    bits = recursive_decode(llr, n, 0)\n",
        "    return np.array(bits)\n",
        "\n",
        "# --- SCL Decoder (simplified) ---\n",
        "def scl_decode(llr, frozen_bits_indices, list_size=LIST_SIZE):\n",
        "    N = len(llr)\n",
        "\n",
        "    paths = [([], 0.0)]\n",
        "    for i in range(N):\n",
        "        new_paths = []\n",
        "        for path, metric in paths:\n",
        "            if i in frozen_bits_indices:\n",
        "                bit = 0\n",
        "                llr_i = llr[i]\n",
        "                metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                new_paths.append((path + [bit], metric_new))\n",
        "            else:\n",
        "                for bit in [0, 1]:\n",
        "                    llr_i = llr[i]\n",
        "                    metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                    new_paths.append((path + [bit], metric_new))\n",
        "        new_paths.sort(key=lambda x: x[1])\n",
        "        paths = new_paths[:list_size]\n",
        "\n",
        "    for path, metric in paths:\n",
        "        info_crc_bits = np.array(path)[info_bits_indices]\n",
        "        if crc_check(info_crc_bits):\n",
        "            return np.array(path)\n",
        "   # return np.array(paths[0][0])\n",
        "    return code[info_indices]\n",
        "\n",
        "# --- Simple RNN Decoder ---\n",
        "class SimpleRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
        "        super(SimpleRNNDecoder, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out.squeeze(-1)\n",
        "\n",
        "# --- Data generation and simulation ---\n",
        "def generate_data(num_frames):\n",
        "    info_bits = np.random.randint(0, 2, (num_frames, K))\n",
        "    coded_bits = np.array([polar_encode(ib) for ib in info_bits])\n",
        "    return info_bits, coded_bits\n",
        "\n",
        "def evaluate_decoder(decoder_func, info_bits, coded_bits, frozen_bits_indices, snr_db):\n",
        "    total_bit_errors = 0\n",
        "    total_block_errors = 0\n",
        "    num_frames = len(info_bits)\n",
        "    for i in range(num_frames):\n",
        "        _, llr, _ = simulate_channel(coded_bits[i:i+1], snr_db)\n",
        "        llr = llr[0]\n",
        "        decoded = decoder_func(llr, frozen_bits_indices)\n",
        "        decoded_info_crc = decoded[info_bits_indices]\n",
        "        bit_errors = np.sum(decoded_info_crc[:K] != info_bits[i])\n",
        "        total_bit_errors += bit_errors\n",
        "        total_block_errors += (bit_errors > 0)\n",
        "    ber = total_bit_errors / (num_frames * K)\n",
        "    bler = total_block_errors / num_frames\n",
        "    return ber, bler\n",
        "\n",
        "def simulate_channel(coded_bits, snr_db):\n",
        "    tx_signal = bpsk_modulation(coded_bits)\n",
        "    rx_signal, sigma = awgn_channel(tx_signal, snr_db)\n",
        "    llrs = llr_awgn(rx_signal, sigma)\n",
        "    return rx_signal, llrs, sigma\n",
        "\n",
        "def evaluate_rnn_decoder(model, info_bits, coded_bits, snr_db, batch_size=32):\n",
        "    model.eval()\n",
        "    total_bit_errors = 0\n",
        "    total_block_errors = 0\n",
        "    num_frames = len(info_bits)\n",
        "    sigma = np.sqrt(1/(2*(10**(snr_db/10))))\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_frames, batch_size):\n",
        "            batch_coded = coded_bits[i:i+batch_size]\n",
        "            batch_info = info_bits[i:i+batch_size]\n",
        "            batch_size_curr = len(batch_coded)\n",
        "            tx_signal = bpsk_modulation(batch_coded)\n",
        "            noise = sigma * np.random.randn(*tx_signal.shape)\n",
        "            rx_signal = tx_signal + noise\n",
        "            llr = 2 * rx_signal / (sigma**2)\n",
        "            input_tensor = torch.tensor(llr, dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "            outputs = model(input_tensor)\n",
        "            outputs = outputs.cpu().numpy()\n",
        "            decoded_bits = (outputs < 0.5).astype(int)\n",
        "            for j in range(batch_size_curr):\n",
        "                decoded_info_crc = decoded_bits[j, info_bits_indices]\n",
        "                bit_errors = np.sum(decoded_info_crc[:K] != batch_info[j])\n",
        "                total_bit_errors += bit_errors\n",
        "                total_block_errors += (bit_errors > 0)\n",
        "    ber = total_bit_errors / (num_frames * K)\n",
        "    bler = total_block_errors / num_frames\n",
        "    return ber, bler\n",
        "\n",
        "# --- Main function ---\n",
        "def main():\n",
        "    print(f'Running simulation on device: {device}')\n",
        "    info_bits_all, coded_bits_all = generate_data(NUM_FRAMES)\n",
        "\n",
        "    # SC and SCL evaluation\n",
        "    ber_sc, bler_sc = [], []\n",
        "    ber_scl, bler_scl = [], []\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        print(f'Simulating SC and SCL at SNR={snr_db} dB...')\n",
        "        ber_tmp, bler_tmp = evaluate_decoder(sc_decode, info_bits_all, coded_bits_all, frozen_bits_indices, snr_db)\n",
        "        ber_sc.append(ber_tmp)\n",
        "        bler_sc.append(bler_tmp)\n",
        "        ber_tmp, bler_tmp = evaluate_decoder(lambda llr, f: scl_decode(llr, f, list_size=LIST_SIZE),\n",
        "                                             info_bits_all, coded_bits_all, frozen_bits_indices, snr_db)\n",
        "        ber_scl.append(ber_tmp)\n",
        "        bler_scl.append(bler_tmp)\n",
        "\n",
        "    # RNN training with train/validation split and plotting\n",
        "    print('Training RNN decoder (with train/validation split)...')\n",
        "\n",
        "    train_info_all, train_coded_all = generate_data(2000)\n",
        "    split_idx = int(0.8 * len(train_info_all))\n",
        "    train_info, val_info = train_info_all[:split_idx], train_info_all[split_idx:]\n",
        "    train_coded, val_coded = train_coded_all[:split_idx], train_coded_all[split_idx:]\n",
        "\n",
        "    sigma_train = np.sqrt(1/(2*(10**(1.5))))  # Fixed training SNR\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    rnn_model = SimpleRNNDecoder().to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "    epochs = 3\n",
        "    batch_size = 64\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        rnn_model.train()\n",
        "        perm = np.random.permutation(len(train_info))\n",
        "        epoch_train_loss = 0\n",
        "        for i in range(0, len(train_info), batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            batch_info = train_info[idx]\n",
        "            batch_coded = train_coded[idx]\n",
        "            tx_signal = bpsk_modulation(batch_coded)\n",
        "            noise = sigma_train * np.random.randn(*tx_signal.shape)\n",
        "            rx_signal = tx_signal + noise\n",
        "            llr = 2 * rx_signal / (sigma_train**2)\n",
        "            inputs = torch.tensor(llr, dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "            targets = torch.tensor(batch_coded, dtype=torch.float32, device=device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = rnn_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item()\n",
        "        avg_train_loss = epoch_train_loss / (len(train_info) / batch_size)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        rnn_model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            for i in range(0, len(val_info), batch_size):\n",
        "                batch_info = val_info[i:i+batch_size]\n",
        "                batch_coded = val_coded[i:i+batch_size]\n",
        "                tx_signal = bpsk_modulation(batch_coded)\n",
        "                noise = sigma_train * np.random.randn(*tx_signal.shape)\n",
        "                rx_signal = tx_signal + noise\n",
        "                llr = 2 * rx_signal / (sigma_train**2)\n",
        "                inputs = torch.tensor(llr, dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "                targets = torch.tensor(batch_coded, dtype=torch.float32, device=device)\n",
        "                outputs = rnn_model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "            avg_val_loss = val_loss / (len(val_info) / batch_size)\n",
        "            val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(range(1, epochs+1), train_losses, 'b-o', label='Train Loss')\n",
        "    plt.plot(range(1, epochs+1), val_losses, 'r-s', label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss (BCE)')\n",
        "    plt.title('RNN Decoder Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluate RNN decoder\n",
        "    ber_rnn, bler_rnn = [], []\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        print(f'Evaluating RNN decoder at SNR={snr_db} dB...')\n",
        "        ber_tmp, bler_tmp = evaluate_rnn_decoder(rnn_model, info_bits_all, coded_bits_all, snr_db)\n",
        "        ber_rnn.append(ber_tmp)\n",
        "        bler_rnn.append(bler_tmp)\n",
        "\n",
        "    # BER and BLER plot\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_sc, 'o-', label='SC Decoder BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_sc, 'o--', label='SC Decoder BLER')\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_scl, 's-', label=f'SCL Decoder (L={LIST_SIZE}) BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_scl, 's--', label=f'SCL Decoder (L={LIST_SIZE}) BLER')\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_rnn, 'd-', label='RNN Decoder BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_rnn, 'd--', label='RNN Decoder BLER')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('Polar Code BER/BLER Simulation')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "_iGkbEHkRaJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polar+CRC+SC+SCL+RNN Decoder Debug Version\n",
        "# Fixed LLR scaling, decoder logic, and frozen set issues\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- Parameters ---\n",
        "N = 128\n",
        "K = 64\n",
        "CRC_LEN = 8\n",
        "LIST_SIZE = 8\n",
        "DEBUG = True\n",
        "SNR_DB_RANGE = [2.0] if DEBUG else np.arange(0, 4.5, 0.5)\n",
        "NUM_FRAMES = 1 if DEBUG else 1000\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CRC\n",
        "CRC_POLY = 0x07\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# Polar construction\n",
        "polar_reliability_sequence = np.argsort(np.random.rand(N))  # TEMP for demo only\n",
        "info_indices = sorted(polar_reliability_sequence[:K + CRC_LEN])\n",
        "frozen_indices = sorted(set(range(N)) - set(info_indices))\n",
        "\n",
        "# Polar encoding\n",
        "\n",
        "def polar_transform(u):\n",
        "    N = len(u)\n",
        "    if N == 1:\n",
        "        return u\n",
        "    else:\n",
        "        u1 = (u[0:N//2] ^ u[N//2:N])\n",
        "        u2 = u[N//2:N]\n",
        "        return np.concatenate([polar_transform(u1), polar_transform(u2)])\n",
        "\n",
        "def polar_encode(info_bits):\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    u[info_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# Channel\n",
        "\n",
        "def bpsk_mod(x):\n",
        "    return 1 - 2*x\n",
        "\n",
        "def awgn_channel(x, snr_db):\n",
        "    snr = 10**(snr_db/10)\n",
        "    sigma = np.sqrt(1/(2*snr))\n",
        "    noise = sigma * np.random.randn(*x.shape)\n",
        "    return x + noise, sigma\n",
        "\n",
        "def llr_awgn(y, sigma):\n",
        "    return 2 * y / (sigma**2)\n",
        "\n",
        "# SC Decoder\n",
        "\n",
        "def sc_decode(llr, frozen_indices):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    def f(a, b):\n",
        "        return np.sign(a) * np.sign(b) * np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g(a, b, c):\n",
        "        return b + (1 - 2*c) * a\n",
        "\n",
        "    def recurse(llr, depth, offset):\n",
        "        if depth == 0:\n",
        "            idx = offset\n",
        "            if idx in frozen_indices:\n",
        "                return [0]\n",
        "            else:\n",
        "                return [0] if llr >= 0 else [1]\n",
        "        half = 2**(depth - 1)\n",
        "        left = recurse(f(llr[:half], llr[half:]), depth-1, offset)\n",
        "        right = recurse(g(llr[:half], llr[half:], left[0]), depth-1, offset+half)\n",
        "        return left + right\n",
        "\n",
        "    bits = recurse(llr, n, 0)\n",
        "   # return np.array(bits)[info_indices]\n",
        "    return np.array(bits)\n",
        "\n",
        "# SCL (basic)\n",
        "def scl_decode(llr, frozen_indices, L=LIST_SIZE):\n",
        "    N = len(llr)\n",
        "    paths = [([], 0.0)]\n",
        "    for i in range(N):\n",
        "        new_paths = []\n",
        "        for path, metric in paths:\n",
        "            llr_i = llr[i]\n",
        "            if i in frozen_indices:\n",
        "                bit = 0\n",
        "                metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                new_paths.append((path + [bit], metric_new))\n",
        "            else:\n",
        "                for bit in [0, 1]:\n",
        "                    metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                    new_paths.append((path + [bit], metric_new))\n",
        "        new_paths.sort(key=lambda x: x[1])\n",
        "        paths = new_paths[:L]\n",
        "    for path, _ in paths:\n",
        "        code = np.array(path)\n",
        "        if crc_check(code[info_indices]):\n",
        "            #return code[info_indices]\n",
        "            return code\n",
        "    return np.array(paths[0][0])[info_indices]\n",
        "\n",
        "# RNN Decoder\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(input_size=1, hidden_size=64, num_layers=2, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out)\n",
        "        return self.sigmoid(out).squeeze(-1)\n",
        "\n",
        "# Main\n",
        "\n",
        "def main():\n",
        "    print(\"Device:\", device)\n",
        "    info_bits = np.random.randint(0, 2, (NUM_FRAMES, K))\n",
        "    coded = np.array([polar_encode(b) for b in info_bits])\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        tx = bpsk_mod(coded)\n",
        "        rx, sigma = awgn_channel(tx, snr_db)\n",
        "        llr = llr_awgn(rx, sigma)\n",
        "\n",
        "        # SC\n",
        "        sc_decoded = np.array([sc_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "        sc_info = sc_decoded[:, :K]\n",
        "\n",
        "        # SCL\n",
        "        scl_decoded = np.array([scl_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "        scl_info = scl_decoded[:, :K]\n",
        "\n",
        "        ber_sc = np.mean(sc_info != info_bits)\n",
        "        ber_scl = np.mean(scl_info != info_bits)\n",
        "\n",
        "\n",
        "        if DEBUG:\n",
        "            print(\"\\n[DEBUG OUTPUT]\")\n",
        "            print(\"True:\", info_bits[0])\n",
        "            print(\"SC  :\", sc_info[0])\n",
        "            print(\"SCL :\", scl_info[0])\n",
        "            print(\"LLR :\", np.round(llr[0], 2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-Z_4o0PvXmk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZQMB38GTZHLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Polar+CRC+SC+SCL Decoder with BER/BLER Plotting\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- Parameters ---\n",
        "# --- Polar Code Parameters ---\n",
        "BLOCK_LENGTH = 128\n",
        "INFO_BITS = 64\n",
        "CRC_BITS = 8\n",
        "NUM_FRAMES = 300000  # For simulation\n",
        "\n",
        "# --- Training Configuration ---\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 512\n",
        "TRAIN_SNR_DB = 2.0\n",
        "VAL_SNR_DB = 2.0\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CRC\n",
        "CRC_POLY = 0x07\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# Polar construction\n",
        "polar_reliability_sequence = np.argsort(np.random.rand(N))  # TEMP for demo only\n",
        "info_indices = sorted(polar_reliability_sequence[:K + CRC_LEN])\n",
        "frozen_indices = sorted(set(range(N)) - set(info_indices))\n",
        "\n",
        "# Polar encoding\n",
        "\n",
        "def polar_transform(u):\n",
        "    N = len(u)\n",
        "    if N == 1:\n",
        "        return u\n",
        "    else:\n",
        "        u1 = (u[0:N//2] ^ u[N//2:N])\n",
        "        u2 = u[N//2:N]\n",
        "        return np.concatenate([polar_transform(u1), polar_transform(u2)])\n",
        "\n",
        "def polar_encode(info_bits):\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    u[info_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# Channel\n",
        "\n",
        "def bpsk_mod(x):\n",
        "    return 1 - 2*x\n",
        "\n",
        "def awgn_channel(x, snr_db):\n",
        "    snr = 10**(snr_db/10)\n",
        "    sigma = np.sqrt(1/(2*snr))\n",
        "    noise = sigma * np.random.randn(*x.shape)\n",
        "    return x + noise, sigma\n",
        "\n",
        "def llr_awgn(y, sigma):\n",
        "    return 2 * y / (sigma**2)\n",
        "\n",
        "def compute_mutual_information(llrs, bits):\n",
        "    # Clip llrs for numerical stability\n",
        "    llrs = np.clip(llrs, -50, 50)\n",
        "    # Calculate MI per bit, then average over all bits\n",
        "    mi = 1 - np.mean(np.log2(1 + np.exp(-llrs * (1 - 2 * bits))))\n",
        "    return mi\n",
        "# SC Decoder\n",
        "\n",
        "def sc_decode(llr, frozen_indices):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    def f(a, b):\n",
        "        return np.sign(a) * np.sign(b) * np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g(a, b, c):\n",
        "        return b + (1 - 2*c) * a\n",
        "\n",
        "    def recurse(llr, depth, offset):\n",
        "        if depth == 0:\n",
        "            idx = offset\n",
        "            if idx in frozen_indices:\n",
        "                return [0]\n",
        "            else:\n",
        "                return [0] if llr >= 0 else [1]\n",
        "        half = 2**(depth - 1)\n",
        "        left = recurse(f(llr[:half], llr[half:]), depth-1, offset)\n",
        "        right = recurse(g(llr[:half], llr[half:], left[0]), depth-1, offset+half)\n",
        "        return left + right\n",
        "\n",
        "    bits = recurse(llr, n, 0)\n",
        "    return np.array(bits)\n",
        "\n",
        "# SCL (basic)\n",
        "def scl_decode(llr, frozen_indices, L=LIST_SIZE):\n",
        "    N = len(llr)\n",
        "    paths = [([], 0.0)]\n",
        "    for i in range(N):\n",
        "        new_paths = []\n",
        "        for path, metric in paths:\n",
        "            llr_i = llr[i]\n",
        "            if i in frozen_indices:\n",
        "                bit = 0\n",
        "                metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                new_paths.append((path + [bit], metric_new))\n",
        "            else:\n",
        "                for bit in [0, 1]:\n",
        "                    metric_new = metric + (0 if bit == (llr_i >= 0) else abs(llr_i))\n",
        "                    new_paths.append((path + [bit], metric_new))\n",
        "        new_paths.sort(key=lambda x: x[1])\n",
        "        paths = new_paths[:L]\n",
        "    for path, _ in paths:\n",
        "        code = np.array(path)\n",
        "        if crc_check(code[info_indices]):\n",
        "            return code\n",
        "    return np.array(paths[0][0])\n",
        "\n",
        "# Main with BER/BLER plot\n",
        "def main():\n",
        "    print(\"Device:\", device)\n",
        "    ber_sc_list, ber_scl_list = [], []\n",
        "    bler_sc_list, bler_scl_list = [], []\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        total_bit_errors_sc = 0\n",
        "        total_bit_errors_scl = 0\n",
        "        total_block_errors_sc = 0\n",
        "        total_block_errors_scl = 0\n",
        "\n",
        "        info_bits = np.random.randint(0, 2, (NUM_FRAMES, K))\n",
        "        coded = np.array([polar_encode(b) for b in info_bits])\n",
        "        tx = bpsk_mod(coded)\n",
        "        rx, sigma = awgn_channel(tx, snr_db)\n",
        "        llr = llr_awgn(rx, sigma)\n",
        "\n",
        "        # SC decode\n",
        "        #sc_decoded = np.array([sc_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "        #sc_info = sc_decoded[:, info_indices][:, :K]\n",
        "        sc_decoded = np.array([sc_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "        sc_u_hat = np.array([polar_transform(b) for b in sc_decoded])  # Inverse\n",
        "        sc_info = sc_u_hat[:, info_indices][:, :K]\n",
        "        bit_errors = np.sum(sc_info != info_bits)\n",
        "        block_errors = np.sum(np.any(sc_info != info_bits, axis=1))\n",
        "        ber_sc_list.append(bit_errors / (NUM_FRAMES * K))\n",
        "        bler_sc_list.append(block_errors / NUM_FRAMES)\n",
        "\n",
        "        # SCL decode\n",
        "      #  scl_decoded = np.array([scl_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "       # scl_info = scl_decoded[:, info_indices][:, :K]\n",
        "        scl_decoded = np.array([scl_decode(llr[i], frozen_indices) for i in range(NUM_FRAMES)])\n",
        "        scl_u_hat = np.array([polar_transform(b) for b in scl_decoded])  # Inverse\n",
        "        scl_info = scl_u_hat[:, info_indices][:, :K]\n",
        "        bit_errors = np.sum(scl_info != info_bits)\n",
        "        block_errors = np.sum(np.any(scl_info != info_bits, axis=1))\n",
        "        ber_scl_list.append(bit_errors / (NUM_FRAMES * K))\n",
        "        bler_scl_list.append(block_errors / NUM_FRAMES)\n",
        "\n",
        "        print(f\"SNR={snr_db:.1f} dB | BER SC={ber_sc_list[-1]:.4e}, BER SCL={ber_scl_list[-1]:.4e} | BLER SC={bler_sc_list[-1]:.4e}, BLER SCL={bler_scl_list[-1]:.4e}\")\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_sc_list, 'o-', label='SC BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, ber_scl_list, 's-', label=f'SCL (L={LIST_SIZE}) BER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_sc_list, 'o--', label='SC BLER')\n",
        "    plt.semilogy(SNR_DB_RANGE, bler_scl_list, 's--', label=f'SCL (L={LIST_SIZE}) BLER')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER / BLER')\n",
        "    plt.title(f'Polar Code N={N}, K={K}, CRC={CRC_LEN}')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.ylim([1e-4, 1])\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "QSIEvZFyZKmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5eb455ec-1fac-46b1-9f6b-2150b944356c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LIST_SIZE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-484336297.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# SCL (basic)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mscl_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLIST_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LIST_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed Polar Code Simulation Script with SC, CRC-aided SCL, BER/BLER Plots\n",
        "#latest at 4:30 PM 06/25\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "N = 128\n",
        "K = 64\n",
        "CRC_LEN = 8\n",
        "L = 8  # List size for SCL\n",
        "total_bits = K + CRC_LEN\n",
        "SNR_DB_RANGE = np.arange(0.0, 4.5, 0.5)\n",
        "NUM_FRAMES = 1000\n",
        "DEBUG = False\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 512\n",
        "TRAIN_SNR_DB = 2.0\n",
        "VAL_SNR_DB = 2.0\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# CRC Generator Polynomial (CRC-8)\n",
        "CRC_POLY = 0x07  # x^8 + x^2 + x + 1\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# Polar Reliability Sequence (5G-based for N=128)\n",
        "polar_reliability_sequence = [\n",
        "    0, 1, 2, 4, 8, 16, 32, 3, 5, 6, 9, 10, 12, 17, 18, 20,\n",
        "    24, 33, 34, 36, 40, 7, 11, 13, 14, 19, 21, 22, 25, 26,\n",
        "    28, 35, 37, 38, 41, 42, 44, 48, 15, 23, 27, 29, 30, 39,\n",
        "    43, 45, 46, 49, 50, 52, 56, 31, 47, 51, 53, 54, 57, 58,\n",
        "    60, 61, 62, 63, 55, 59, 64, 65, 66, 67, 68, 69, 70, 71,\n",
        "    72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
        "    86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n",
        "    100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
        "    111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
        "    122, 123, 124, 125, 126, 127\n",
        "]\n",
        "\n",
        "info_indices = sorted(polar_reliability_sequence[:total_bits])\n",
        "frozen_indices = sorted(set(range(N)) - set(info_indices))\n",
        "\n",
        "# Polar Transform\n",
        "\n",
        "def polar_transform(u):\n",
        "    N = len(u)\n",
        "    n = int(np.log2(N))\n",
        "    u = u.copy()\n",
        "    for d in range(n):\n",
        "        step = 2 ** d\n",
        "        for i in range(0, N, 2 * step):\n",
        "            for j in range(step):\n",
        "                u[i + j] ^= u[i + j + step]\n",
        "    return u\n",
        "\n",
        "# Encoder\n",
        "\n",
        "def polar_encode(info_bits):\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    u[info_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# Channel and Modulation\n",
        "\n",
        "def bpsk(x):\n",
        "    return 1 - 2 * x\n",
        "\n",
        "def awgn(y, snr_db):\n",
        "    snr = 10 ** (snr_db / 10)\n",
        "    sigma = np.sqrt(1 / (2 * snr))\n",
        "    noise = sigma * np.random.randn(*y.shape)\n",
        "    return y + noise, sigma\n",
        "\n",
        "def llr_calc(y, sigma):\n",
        "    return 2 * y / (sigma ** 2)\n",
        "\n",
        "# SC Decoder\n",
        "\n",
        "def sc_decode(llr, frozen_indices):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    def f(a, b):\n",
        "        return np.sign(a) * np.sign(b) * np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "    def g(a, b, c):\n",
        "        return b + (1 - 2 * c) * a\n",
        "\n",
        "    def recurse(llr, depth, offset):\n",
        "        if depth == 0:\n",
        "            return np.array([0]) if offset in frozen_indices else np.array([int(llr[0] < 0)])\n",
        "        half = 2 ** (depth - 1)\n",
        "        l0 = f(llr[:half], llr[half:])\n",
        "        u0 = recurse(l0, depth - 1, offset)\n",
        "        l1 = g(llr[:half], llr[half:], u0)\n",
        "        u1 = recurse(l1, depth - 1, offset + half)\n",
        "        return np.concatenate([u0, u1])\n",
        "\n",
        "    return recurse(llr, n, 0)\n",
        "\n",
        "# SCL Decoder\n",
        "\n",
        "def scl_decode(llr, frozen_indices, L=8):\n",
        "    paths = [([], 0.0)]\n",
        "    for i in range(len(llr)):\n",
        "        new_paths = []\n",
        "        for path, metric in paths:\n",
        "            if i in frozen_indices:\n",
        "                bit = 0\n",
        "                new_paths.append((path + [bit], metric + (0 if llr[i] >= 0 else abs(llr[i]))))\n",
        "            else:\n",
        "                for bit in [0, 1]:\n",
        "                    m = metric + (0 if bit == (llr[i] < 0) else abs(llr[i]))\n",
        "                    new_paths.append((path + [bit], m))\n",
        "        new_paths.sort(key=lambda x: x[1])\n",
        "        paths = new_paths[:L]\n",
        "\n",
        "    for path, _ in paths:\n",
        "        u_hat = np.array(path)\n",
        "        info_bits = polar_transform(u_hat)[info_indices]\n",
        "        if crc_check(info_bits):\n",
        "            return u_hat\n",
        "    return np.array(paths[0][0])\n",
        "\n",
        "# Main\n",
        "\n",
        "def main():\n",
        "    print(\"Device: CPU or CUDA not used explicitly\")\n",
        "\n",
        "    ber_sc = []\n",
        "    ber_scl = []\n",
        "    bler_sc = []\n",
        "    bler_scl = []\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        total_bit_errors_sc = 0\n",
        "        total_bit_errors_scl = 0\n",
        "        total_block_errors_sc = 0\n",
        "        total_block_errors_scl = 0\n",
        "\n",
        "        for _ in range(NUM_FRAMES):\n",
        "            info = np.random.randint(0, 2, K)\n",
        "            x = polar_encode(info)\n",
        "            y = bpsk(x)\n",
        "            y_noisy, sigma = awgn(y, snr_db)\n",
        "            llr = llr_calc(y_noisy, sigma)\n",
        "\n",
        "            # SC\n",
        "            sc_u = sc_decode(llr, frozen_indices)\n",
        "            sc_u_hat = polar_transform(sc_u)\n",
        "           # sc_u_hat = polar_transform(sc_u)\n",
        "            sc_info = sc_u_hat[info_indices][:K]\n",
        "            bit_errs = np.sum(sc_info != info)\n",
        "            #sc_info = sc_u_hat[info_indices][:K]\n",
        "           # bit_errs = np.sum(sc_info != info)\n",
        "            total_bit_errors_sc += bit_errs\n",
        "            if bit_errs > 0:\n",
        "                total_block_errors_sc += 1\n",
        "\n",
        "            # SCL\n",
        "            scl_u = scl_decode(llr, frozen_indices, L)\n",
        "            scl_u_hat = polar_transform(scl_u)\n",
        "           # scl_u_hat = polar_transform(scl_u)\n",
        "            scl_info = scl_u_hat[info_indices][:K]\n",
        "            bit_errs = np.sum(scl_info != info)\n",
        "           # scl_info = scl_u_hat[info_indices][:K]\n",
        "          #  bit_errs = np.sum(scl_info != info)\n",
        "            total_bit_errors_scl += bit_errs\n",
        "            if bit_errs > 0:\n",
        "                total_block_errors_scl += 1\n",
        "\n",
        "        ber_sc.append(total_bit_errors_sc / (NUM_FRAMES * K))\n",
        "        ber_scl.append(total_bit_errors_scl / (NUM_FRAMES * K))\n",
        "        bler_sc.append(total_block_errors_sc / NUM_FRAMES)\n",
        "        bler_scl.append(total_block_errors_scl / NUM_FRAMES)\n",
        "\n",
        "        print(f\"SNR={snr_db:.1f} dB | BER SC={ber_sc[-1]:.4e}, BER SCL={ber_scl[-1]:.4e} | BLER SC={bler_sc[-1]:.4e}, BLER SCL={bler_scl[-1]:.4e}\")\n",
        "\n",
        "    # Plot\n",
        "def plot_results(snr_range, ber_sc, ber_scl, bler_sc, bler_scl):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(snr_range, ber_sc, 'o-', label='SC BER')\n",
        "    plt.plot(snr_range, ber_scl, 's-', label='SCL BER')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Bit Error Rate (BER)')\n",
        "    plt.title('BER vs SNR')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(snr_range, bler_sc, 'o-', label='SC BLER')\n",
        "    plt.plot(snr_range, bler_scl, 's-', label='SCL BLER')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Block Error Rate (BLER)')\n",
        "    plt.title('BLER vs SNR')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UjhXS-aEvZbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unified Polar Code Simulation Script\n",
        "# Includes: SC, CRC-aided SCL, RNN Decoder (GPU-enabled), BER/BLER + MI Plots\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "N = 128                      # Block length\n",
        "K = 64                       # Info bits\n",
        "CRC_LEN = 8                  # CRC bits\n",
        "L_list = [1, 4, 8, 16]       # SCL list sizes\n",
        "TOTAL_BITS = K + CRC_LEN\n",
        "SNR_DB_RANGE = np.arange(0.0, 4.5, 0.5)\n",
        "NUM_FRAMES = 50000\n",
        "\n",
        "# RNN Training Config\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 128\n",
        "TRAIN_SNR_DB = 2.0\n",
        "VAL_SNR_DB = 2.0\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- CRC-8 Polynomial: x^8 + x^2 + x + 1 ---\n",
        "CRC_POLY = 0x07\n",
        "\n",
        "def crc_encode(info_bits):\n",
        "    data = np.concatenate([info_bits, np.zeros(CRC_LEN, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.concatenate([info_bits, data[-CRC_LEN:]])\n",
        "\n",
        "def crc_check(codeword):\n",
        "    data = codeword.copy()\n",
        "    for i in range(len(codeword) - CRC_LEN):\n",
        "        if data[i] == 1:\n",
        "            for j in range(CRC_LEN + 1):\n",
        "                if ((CRC_POLY >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-CRC_LEN:] == 0)\n",
        "\n",
        "# --- Polar Reliability (5G 128-bit) ---\n",
        "polar_reliability_sequence = list(range(128))  # placeholder; replace with actual 5G sequence\n",
        "info_indices = sorted(polar_reliability_sequence[:TOTAL_BITS])\n",
        "frozen_indices = sorted(set(range(N)) - set(info_indices))\n",
        "\n",
        "# --- Polar Transform ---\n",
        "def polar_transform(u):\n",
        "    u = u.copy()\n",
        "    n = int(np.log2(len(u)))\n",
        "    for d in range(n):\n",
        "        step = 2 ** d\n",
        "        for i in range(0, len(u), 2 * step):\n",
        "            for j in range(step):\n",
        "                u[i + j] ^= u[i + j + step]\n",
        "    return u\n",
        "\n",
        "# --- Encoder ---\n",
        "def polar_encode(info_bits):\n",
        "    u = np.zeros(N, dtype=int)\n",
        "    info_crc = crc_encode(info_bits)\n",
        "    u[info_indices] = info_crc\n",
        "    return polar_transform(u)\n",
        "\n",
        "# --- Channel + LLR ---\n",
        "def bpsk(x): return 1 - 2 * x\n",
        "\n",
        "def awgn(y, snr_db):\n",
        "    snr = 10 ** (snr_db / 10)\n",
        "    sigma = np.sqrt(1 / (2 * snr))\n",
        "    noise = sigma * np.random.randn(*y.shape)\n",
        "    return y + noise, sigma\n",
        "\n",
        "def llr_calc(y, sigma):\n",
        "    return 2 * y / (sigma ** 2)\n",
        "\n",
        "def compute_mutual_information(llrs, bits):\n",
        "    # Clip llrs for numerical stability\n",
        "    llrs = np.clip(llrs, -50, 50)\n",
        "    # Calculate MI per bit, then average over all bits\n",
        "    mi = 1 - np.mean(np.log2(1 + np.exp(-llrs * (1 - 2 * bits))))\n",
        "    return mi\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def generate_dataset(num_frames, snr_db):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    for _ in range(num_frames):\n",
        "        info_bits = np.random.randint(0, 2, K)\n",
        "        encoded = polar_encode(info_bits)\n",
        "        tx_signal = bpsk(encoded)\n",
        "        rx_signal, sigma = awgn(tx_signal, snr_db)\n",
        "        llrs = llr_calc(rx_signal, sigma)\n",
        "\n",
        "        inputs.append(llrs)\n",
        "        targets.append(info_bits)\n",
        "    inputs = torch.tensor(np.array(inputs), dtype=torch.float32)\n",
        "    targets = torch.tensor(np.array(targets), dtype=torch.float32)\n",
        "    return TensorDataset(inputs, targets)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# --- SC Decoder ---\n",
        "def sc_decode(llr, frozen_indices):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "    def f(a, b): return np.sign(a) * np.sign(b) * np.minimum(np.abs(a), np.abs(b))\n",
        "    def g(a, b, c): return b + (1 - 2 * c) * a\n",
        "\n",
        "    def recurse(llr, depth, offset):\n",
        "        if depth == 0:\n",
        "            return np.array([0]) if offset in frozen_indices else np.array([int(llr[0] < 0)])\n",
        "        half = 2 ** (depth - 1)\n",
        "        l0 = f(llr[:half], llr[half:])\n",
        "        u0 = recurse(l0, depth - 1, offset)\n",
        "        l1 = g(llr[:half], llr[half:], u0)\n",
        "        u1 = recurse(l1, depth - 1, offset + half)\n",
        "        return np.concatenate([u0, u1])\n",
        "\n",
        "    return recurse(llr, n, 0)\n",
        "#############################################################\n",
        "#Latest SCL decoder\n",
        "\n",
        "def f_func(a, b):\n",
        "    # min-sum approximation for f function\n",
        "    s = np.sign(a) * np.sign(b)\n",
        "    return s * np.minimum(np.abs(a), np.abs(b))\n",
        "\n",
        "def g_func(a, b, c):\n",
        "    # g function using previously decoded bit c\n",
        "    return b + ((1 - 2 * c) * a)\n",
        "\n",
        "def crc_check_bits(info_bits, crc_poly=0x07, crc_len=8):\n",
        "    # CRC check as before\n",
        "    data = np.concatenate([info_bits, np.zeros(crc_len, dtype=int)])\n",
        "    for i in range(len(info_bits)):\n",
        "        if data[i] == 1:\n",
        "            for j in range(crc_len + 1):\n",
        "                if ((crc_poly >> j) & 1):\n",
        "                    data[i + j] ^= 1\n",
        "    return np.all(data[-crc_len:] == 0)\n",
        "\n",
        "def scl_decode_advanced(llr, frozen_indices, L, info_indices, crc_poly=0x07, crc_len=8):\n",
        "    N = len(llr)\n",
        "    n = int(np.log2(N))\n",
        "\n",
        "    # Initialize list paths: each path stores (partial bit decisions, path metric)\n",
        "    paths = [([], 0.0)]\n",
        "\n",
        "    # Preallocate arrays to store intermediate LLR computations for each path\n",
        "    # For simplicity, use list of numpy arrays per path\n",
        "    # More memory efficient implementations use trees or stacks\n",
        "\n",
        "    # Recursive LLR calculation function\n",
        "    def recur_llr(llr_arr, path_bits, depth=0):\n",
        "        # Base case depth==n means bit decoding level\n",
        "        # Returns new list of paths after this bit's decisions\n",
        "\n",
        "        if depth == n:\n",
        "            return [(path_bits, 0.0, llr_arr)]  # path, pm (0 for now), llr_arr for info\n",
        "\n",
        "        step = 2 ** (n - depth -1)\n",
        "\n",
        "        # Compute f and g LLR vectors\n",
        "        llr_left = f_func(llr_arr[:step], llr_arr[step:2*step])\n",
        "        left_paths = recur_llr(llr_left, path_bits, depth + 1)\n",
        "\n",
        "        updated_paths = []\n",
        "        for bits, pm, llr_left_child in left_paths:\n",
        "            # Calculate g for right child\n",
        "            g_llr = g_func(llr_arr[:step], llr_arr[step:2*step], bits[-step:] if bits else np.zeros(step, dtype=int))\n",
        "            right_paths = recur_llr(g_llr, bits, depth + 1)\n",
        "            updated_paths.extend(right_paths)\n",
        "\n",
        "        return updated_paths\n",
        "\n",
        "        # But the above is too complex for path management.\n",
        "    # Instead, we'll implement iterative version using path splitting per bit\n",
        "\n",
        "    # Initialize arrays to store LLRs and partial sums per path per stage\n",
        "    # For each bit index i, we:\n",
        "    # - For frozen bits: extend paths with bit=0 only\n",
        "    # - For info bits: extend paths with both bit=0 and bit=1\n",
        "    # Then prune to top L paths by path metric\n",
        "\n",
        "    # Initialize LLR arrays for each path (shape: paths x N)\n",
        "    llr_paths = np.tile(llr, (L,1))  # Initially all identical\n",
        "    # Partial sums (decoded bits) per path\n",
        "    ps_paths = np.zeros((L,N), dtype=int)\n",
        "    # Number of active paths\n",
        "    num_paths = 1\n",
        "\n",
        "    # Path metrics: smaller is better (log domain)\n",
        "    pm = np.zeros(L)\n",
        "    pm[:] = np.inf\n",
        "    pm[0] = 0.0\n",
        "\n",
        "    for bit_idx in range(N):\n",
        "        # Prepare candidate paths and metrics\n",
        "        cand_paths = []\n",
        "        cand_pms = []\n",
        "        cand_ps = []\n",
        "        for path_i in range(num_paths):\n",
        "            # Get LLR of current bit\n",
        "            llr_val = llr_paths[path_i, bit_idx]\n",
        "            # Frozen bit check\n",
        "            if bit_idx in frozen_indices:\n",
        "                # Forced bit = 0\n",
        "                bit_val = 0\n",
        "                # Update path metric (penalty if bit doesn't match sign of LLR)\n",
        "                pm_new = pm[path_i] + np.log1p(np.exp(-llr_val)) if bit_val == 1 else pm[path_i] + np.log1p(np.exp(llr_val))\n",
        "                cand_paths.append(path_i)\n",
        "                cand_pms.append(pm_new)\n",
        "                new_ps = ps_paths[path_i].copy()\n",
        "                new_ps[bit_idx] = bit_val\n",
        "                cand_ps.append(new_ps)\n",
        "            else:\n",
        "                # Info bit: try bit=0 and bit=1\n",
        "                for bit_val in [0,1]:\n",
        "                    pm_new = pm[path_i] + np.log1p(np.exp(-llr_val)) if bit_val == 1 else pm[path_i] + np.log1p(np.exp(llr_val))\n",
        "                    cand_paths.append(path_i)\n",
        "                    cand_pms.append(pm_new)\n",
        "                    new_ps = ps_paths[path_i].copy()\n",
        "                    new_ps[bit_idx] = bit_val\n",
        "                    cand_ps.append(new_ps)\n",
        "\n",
        "        # Prune paths to keep top L by pm (lower better)\n",
        "        cand_pms = np.array(cand_pms)\n",
        "        best_indices = np.argsort(cand_pms)[:L]\n",
        "\n",
        "        # Update active paths\n",
        "        num_paths = len(best_indices)\n",
        "        pm = cand_pms[best_indices]\n",
        "        ps_paths = np.array(cand_ps)[best_indices]\n",
        "\n",
        "        # TODO: update llr_paths for new partial sums (this requires f,g recursion per path)\n",
        "        # For now, assume fixed LLRs (approximate) or implement recursive LLR update here\n",
        "\n",
        "        # In practice:\n",
        "        # Implement recursive LLR update functions for each new path partial sums here\n",
        "        # This part is complex and needs careful implementation for exact Polar SCL decoding\n",
        "\n",
        "    # After all bits decoded:\n",
        "    # Select candidate paths passing CRC check\n",
        "    for path_i in range(num_paths):\n",
        "        info_bits = ps_paths[path_i][info_indices][:TOTAL_BITS]\n",
        "        if crc_check_bits(info_bits, crc_poly, crc_len):\n",
        "            return ps_paths[path_i]\n",
        "    # If none pass CRC, return best PM path\n",
        "    best_path_idx = np.argmin(pm)\n",
        "    return ps_paths[best_path_idx]\n",
        "##################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- RNN Decoder (Simple GRU) ---\n",
        "class PolarRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size=N, hidden_size=256, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(input_size=1, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, K)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)  # shape: (batch, N, 1)\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "# --- Training Data Generation ---\n",
        "def generate_data(num_samples, snr_db):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        info = np.random.randint(0, 2, K)\n",
        "        x = polar_encode(info)\n",
        "        y = bpsk(x)\n",
        "        y_noisy, sigma = awgn(y, snr_db)\n",
        "        llr = llr_calc(y_noisy, sigma)\n",
        "        X.append(llr)\n",
        "        Y.append(info)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "# --- Training Function ---\n",
        "def train_rnn(model, train_loader, val_loader, criterion, optimizer):\n",
        "    train_losses, val_losses = [], []\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                outputs = model(xb)\n",
        "                val_loss += criterion(outputs, yb).item()\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_losses[-1]:.4f}, Val Loss = {val_losses[-1]:.4f}\")\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# --- Plotting Functions ---\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('RNN Training/Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_sc_decoder(snr_range, ber_sc, bler_sc):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.semilogy(snr_range, ber_sc, 'o-', label='SC BER')\n",
        "    plt.semilogy(snr_range, bler_sc, 's--', label='SC BLER')\n",
        "    plt.ylim(1e-5, 1e0)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('SC Decoder: BER and BLER vs SNR')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scl_decoder(snr_range, ber_scl_dict, bler_scl_dict):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for L in ber_scl_dict:\n",
        "        plt.semilogy(snr_range, ber_scl_dict[L], marker='o', label=f'SCL L={L} BER')\n",
        "    for L in bler_scl_dict:\n",
        "        plt.semilogy(snr_range, bler_scl_dict[L], marker='s', linestyle='--', label=f'SCL L={L} BLER')\n",
        "    plt.ylim(1e-5, 1e0)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('SCL Decoder: BER and BLER vs SNR')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_rnn_decoder(snr_range, ber_rnn, bler_rnn):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.semilogy(snr_range, ber_rnn, 'o-', label='RNN BER')\n",
        "    plt.semilogy(snr_range, bler_rnn, 's--', label='RNN BLER')\n",
        "    plt.ylim(1e-5, 1e0)\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('RNN Decoder: BER and BLER vs SNR')\n",
        "    plt.grid(True, which='both')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#######################################################################################\n",
        "def main():\n",
        "    print(f\"Running on device: {DEVICE}\")\n",
        "\n",
        "    # --- Prepare RNN model, optimizer, loss ---\n",
        "    rnn_model = PolarRNNDecoder().to(DEVICE)  # Replace with your actual RNN model class\n",
        "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --- Generate training + validation dataset at fixed training SNR ---\n",
        "    NUM_FRAMES_TRAINVAL = 40000\n",
        "    full_trainval_dataset = generate_dataset(NUM_FRAMES_TRAINVAL, TRAIN_SNR_DB)\n",
        "\n",
        "    train_size = int(0.8 * len(full_trainval_dataset))\n",
        "    val_size = len(full_trainval_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(full_trainval_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # --- RNN Training Loop ---\n",
        "    for epoch in range(EPOCHS):\n",
        "        rnn_model.train()\n",
        "        total_train_loss = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = rnn_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * inputs.size(0)\n",
        "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        rnn_model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "                outputs = rnn_model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                total_val_loss += loss.item() * inputs.size(0)\n",
        "        avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # --- Plot training & validation loss ---\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, EPOCHS+1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('RNN Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Testing phase: evaluate BER and BLER over SNR range ---\n",
        "    ber_sc, bler_sc = [], []\n",
        "    ber_rnn, bler_rnn = [], []\n",
        "    ber_scl_dict = {L: [] for L in L_list}\n",
        "    bler_scl_dict = {L: [] for L in L_list}\n",
        "\n",
        "    for snr_db in SNR_DB_RANGE:\n",
        "        print(f\"Simulating at SNR = {snr_db:.1f} dB...\")\n",
        "\n",
        "        bit_errors_sc = 0\n",
        "        block_errors_sc = 0\n",
        "        bit_errors_rnn = 0\n",
        "        block_errors_rnn = 0\n",
        "        bit_errors_scl = {L: 0 for L in L_list}\n",
        "        block_errors_scl = {L: 0 for L in L_list}\n",
        "\n",
        "        for _ in range(NUM_FRAMES):\n",
        "            info_bits = np.random.randint(0, 2, K)\n",
        "            encoded = polar_encode(info_bits)\n",
        "            tx_signal = bpsk(encoded)\n",
        "            rx_signal, sigma = awgn(tx_signal, snr_db)\n",
        "            llrs = llr_calc(rx_signal, sigma)\n",
        "\n",
        "            # SC decode\n",
        "            sc_u_hat = sc_decode(llrs, frozen_indices)\n",
        "            sc_bits_hat = polar_transform(sc_u_hat)[info_indices][:TOTAL_BITS]\n",
        "            sc_info_hat = sc_bits_hat[:K]\n",
        "            err_bits_sc = np.sum(sc_info_hat != info_bits)\n",
        "            bit_errors_sc += err_bits_sc\n",
        "            if err_bits_sc > 0:\n",
        "                block_errors_sc += 1\n",
        "\n",
        "            # RNN decode\n",
        "            llr_tensor = torch.tensor(llrs, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "            rnn_model.eval()\n",
        "            with torch.no_grad():\n",
        "                rnn_output = rnn_model(llr_tensor).cpu().numpy().flatten()\n",
        "            rnn_info_hat = (rnn_output > 0.5).astype(int)\n",
        "            err_bits_rnn = np.sum(rnn_info_hat != info_bits)\n",
        "            bit_errors_rnn += err_bits_rnn\n",
        "            if err_bits_rnn > 0:\n",
        "                block_errors_rnn += 1\n",
        "\n",
        "            # SCL decode for all list sizes\n",
        "            for L in L_list:\n",
        "                scl_u_hat = scl_decode_advanced(llrs, frozen_indices, L, info_indices, CRC_POLY, CRC_LEN)\n",
        "                scl_bits_hat = polar_transform(scl_u_hat)[info_indices][:TOTAL_BITS]\n",
        "                scl_info_hat = scl_bits_hat[:K]\n",
        "                err_bits_scl = np.sum(scl_info_hat != info_bits)\n",
        "                bit_errors_scl[L] += err_bits_scl\n",
        "                if err_bits_scl > 0:\n",
        "                    block_errors_scl[L] += 1\n",
        "\n",
        "        # Compute BER and BLER\n",
        "        ber_sc.append(bit_errors_sc / (NUM_FRAMES * K))\n",
        "        bler_sc.append(block_errors_sc / NUM_FRAMES)\n",
        "        ber_rnn.append(bit_errors_rnn / (NUM_FRAMES * K))\n",
        "        bler_rnn.append(block_errors_rnn / NUM_FRAMES)\n",
        "        for L in L_list:\n",
        "            ber_scl_dict[L].append(bit_errors_scl[L] / (NUM_FRAMES * K))\n",
        "            bler_scl_dict[L].append(block_errors_scl[L] / NUM_FRAMES)\n",
        "\n",
        "        print(f\"SNR={snr_db:.1f} | SC BER={ber_sc[-1]:.2e}, BLER={bler_sc[-1]:.2e} | \"\n",
        "              f\"RNN BER={ber_rnn[-1]:.2e}, BLER={bler_rnn[-1]:.2e} | \" +\n",
        "              \" | \".join([f\"SCL L={L} BER={ber_scl_dict[L][-1]:.2e}, BLER={bler_scl_dict[L][-1]:.2e}\" for L in L_list])\n",
        "        )\n",
        "\n",
        "    # --- Plotting error rates separately ---\n",
        "    plot_sc_decoder(SNR_DB_RANGE, ber_sc, bler_sc)\n",
        "    plot_rnn_decoder(SNR_DB_RANGE, ber_rnn, bler_rnn)\n",
        "    plot_scl_decoder(SNR_DB_RANGE, ber_scl_dict, bler_scl_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kQeoG5hJRjyF",
        "outputId": "c2eefbf2-9432-4b5e-ad03-e67bc75fe38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Running on device: cuda\n",
            "Epoch 1/40 - Train Loss: 0.6938, Val Loss: 0.6932\n",
            "Epoch 2/40 - Train Loss: 0.6932, Val Loss: 0.6932\n",
            "Epoch 3/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 4/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 5/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 6/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 7/40 - Train Loss: 0.6932, Val Loss: 0.6932\n",
            "Epoch 8/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 9/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 10/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 11/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 12/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 13/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 14/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 15/40 - Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch 16/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 17/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 18/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 19/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 20/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 21/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 22/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 23/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 24/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 25/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 26/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 27/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 28/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 29/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 30/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 31/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 32/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 33/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 34/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 35/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 36/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 37/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 38/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 39/40 - Train Loss: 0.6931, Val Loss: 0.6931\n",
            "Epoch 40/40 - Train Loss: 0.6931, Val Loss: 0.6931\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAf+VJREFUeJzt3Xl4U1X6B/DvzdokXShdQ6kUKIWCLLJacFiGUsAFFRQURlkEFYpsP0fEUVpE0AFlGEVBGbZhBBdcQEBKZZNdpgyLsgmyU5YC3dIlaXJ/f6S5bWgLbW/SdPl+nidPk3PPvffk9LbN2/PecwRRFEUQERERERHJoPB0A4iIiIiIqOZjYEFERERERLIxsCAiIiIiItkYWBARERERkWwMLIiIiIiISDYGFkREREREJBsDCyIiIiIiko2BBRERERERycbAgoiIiIiIZGNgQURUw/Ts2RM9e/as1L4jRoxARESES9tT3Wzfvh2CIGD79u1Vet5z585BEAQsX75cKktMTIQgCOXaXxAEJCYmurRNcq4VIqKKYmBBRDXC8uXLIQiC9FCpVAgLC8OIESNw+fLlEvV79uwJQRDw2GOPldjm+AD4/vvvS2WOD6OCICAlJaXEPiNGjIC3t3eZ7XMcszyPc+fOVa4TyGUGDBgAvV6PrKysMusMGzYMGo0GN2/erMKWVdyxY8eQmJhYra4rx8/TmjVrPN0UIqpCKk83gIioIt5++200btwYeXl52LdvH5YvX45du3bh119/hZeXV4n669evR0pKCjp06FDucyQmJuKHH36oULuCgoKwcuVKp7IPPvgAly5dwj/+8Y8SdeXYvHlzpfddvHgxbDabrPPXBsOGDcMPP/yA7777Ds8//3yJ7Tk5OVi7di369euHgICASp/nzTffxOuvvy6nqfd07NgxzJgxAz179iwxGiXnWiEiqigGFkRUo/Tv3x8dO3YEAIwePRqBgYH4+9//jnXr1mHw4MFOde+77z5kZWVhxowZWLduXbmO365dO6xfvx4HDx5E+/bty90ug8GAv/zlL05lX3zxBW7fvl2ivDhRFJGXlwedTlfuc2k0mnLXvZNara70vrXJgAED4OPjg1WrVpUaWKxduxYmkwnDhg2TdR6VSgWVynN/auVcK0REFcVUKCKq0f70pz8BAM6cOVNim4+PDyZPnowffvgBBw8eLNfxXnnlFfj7+7s8190hIiICjz76KJKSktCxY0fodDp8+umnAIBly5bhz3/+M4KDg6HVatGyZUssXLiwxDHuzJt3pJ189dVXmDVrFho2bAgvLy/07t0bp0+fdtr3znssiqeFffbZZ2jatCm0Wi06deqEAwcOlDj3119/jZYtW8LLywv3338/vvvuu3Lft7F27Vo88sgjaNCgAbRaLZo2bYqZM2fCarWWeH/3338/jh07hl69ekGv1yMsLAxz5swpccxLly7hiSeegMFgQHBwMCZPnoz8/Px7tkWn02HgwIHYsmULrl+/XmL7qlWr4OPjgwEDBuDWrVt49dVX0bp1a3h7e8PX1xf9+/fH4cOH73me0u6xyM/Px+TJkxEUFCSd49KlSyX2PX/+PMaNG4fmzZtDp9MhICAATz/9tFPK0/Lly/H0008DAHr16iWl2znuLyntHovr16/jhRdeQEhICLy8vNC2bVusWLHCqU5Fr4vK+uOPP/D000+jfv360Ov1ePDBB7Fhw4YS9T766CO0atUKer0e/v7+6NixI1atWiVtz8rKwqRJkxAREQGtVovg4GD06dOn3D/3ROQaHLEgohrN8SHL39+/1O0TJ07EP/7xDyQmJpZr1MLX1xeTJ0/G9OnTKzxqUV4nT57Es88+i5deegljxoxB8+bNAQALFy5Eq1atMGDAAKhUKvzwww8YN24cbDYb4uPj73nc9957DwqFAq+++ioyMjIwZ84cDBs2DPv377/nvqtWrUJWVhZeeuklCIKAOXPmYODAgfjjjz+kUY4NGzZgyJAhaN26Nd59913cvn0bL7zwAsLCwsr1vpcvXw5vb29MmTIF3t7e2Lp1K6ZPn47MzEzMnTvXqe7t27fRr18/DBw4EIMHD8aaNWswdepUtG7dGv379wcA5Obmonfv3rhw4QImTJiABg0aYOXKldi6dWu52jNs2DCsWLECX331FcaPHy+V37p1C0lJSXj22Weh0+nw22+/4fvvv8fTTz+Nxo0b49q1a/j000/Ro0cPHDt2DA0aNCjX+RxGjx6N//znPxg6dCi6du2KrVu34pFHHilR78CBA9izZw+eeeYZNGzYEOfOncPChQvRs2dPHDt2DHq9Ht27d8eECRPw4Ycf4o033kB0dDQASF/vlJubi549e+L06dMYP348GjdujK+//hojRoxAeno6Jk6c6FS/PNdFZV27dg1du3ZFTk4OJkyYgICAAKxYsQIDBgzAmjVr8OSTTwKwp+9NmDABTz31FCZOnIi8vDwcOXIE+/fvx9ChQwEAL7/8MtasWYPx48ejZcuWuHnzJnbt2oXjx4+75WeYiMogEhHVAMuWLRMBiD/99JN448YN8eLFi+KaNWvEoKAgUavVihcvXnSq36NHD7FVq1aiKIrijBkzRABiSkqKKIqiePbsWRGAOHfuXKn+tm3bRADi119/Laanp4v+/v7igAEDpO3Dhw8XDQZDhdr8yCOPiI0aNXIqa9SokQhA3LRpU4n6OTk5Jcr69u0rNmnSpMR769GjR4m2R0dHi/n5+VL5P//5TxGAePToUaf3UbxNjr4ICAgQb926JZWvXbtWBCD+8MMPUlnr1q3Fhg0billZWVLZ9u3bRQAl3mdpSnt/L730kqjX68W8vDyn9wdA/Pe//y2V5efni6GhoeKgQYOksvnz54sAxK+++koqM5lMYmRkpAhA3LZt213bU1BQIBqNRjEmJsapfNGiRSIAMSkpSRRFUczLyxOtVqtTnbNnz4parVZ8++23ncoAiMuWLZPKEhISxOJ/ag8dOiQCEMeNG+d0vKFDh4oAxISEBKmstP7au3dvib75+uuvy3y/d14rjj77z3/+I5WZzWYxJiZG9Pb2FjMzM53eS3mui9IU/3kqy6RJk0QA4s6dO6WyrKwssXHjxmJERITU548//rj0s1wWPz8/MT4+/q51iMj9mApFRDVKbGwsgoKCEB4ejqeeegoGgwHr1q1Dw4YNy9xn4sSJ8Pf3x4wZM8p1Dj8/P0yaNAnr1q3D//73P1c1XdK4cWP07du3RHnx+ywyMjKQlpaGHj164I8//kBGRsY9jzty5EinnHpHmtgff/xxz32HDBniNOpz575XrlzB0aNH8fzzzzvNjtWjRw+0bt36nscHnN9fVlYW0tLS8Kc//Qk5OTk4ceKEU11vb2+ne1M0Gg06d+7s9F42btwIo9GIp556SirT6/V48cUXy9UepVKJZ555Bnv37nVKL1q1ahVCQkLQu3dvAIBWq4VCYf9zabVacfPmTXh7e6N58+YVTrXZuHEjAGDChAlO5ZMmTSpRt3h/WSwW3Lx5E5GRkahXr16lU3w2btyI0NBQPPvss1KZWq3GhAkTkJ2djR07djjVv9d1IcfGjRvRuXNnPPTQQ1KZt7c3XnzxRZw7dw7Hjh0DANSrVw+XLl26awpWvXr1sH//fly5ckV2u4io8hhYEFGN8vHHHyM5ORlr1qzBww8/jLS0NGi12rvuU5lAYeLEiahXr55b7rVo3LhxqeW7d+9GbGwsDAYD6tWrh6CgILzxxhsAUK7A4r777nN67fhAePv2bdn7nj9/HgAQGRlZYt/Sykrz22+/4cknn4Sfnx98fX0RFBQkBQ93vr+GDRuWuDfB39/f6b2cP38ekZGRJeo5UsvKw3FztiNf/9KlS9i5cyeeeeYZKJVKAIDNZsM//vEPNGvWDFqtFoGBgQgKCsKRI0fK9X0p7vz581AoFGjatOk925ybm4vp06cjPDzc6bzp6ekVPm/x8zdr1kwKlBwcqVOO77ODnGuqPG0p7X3f2ZapU6fC29sbnTt3RrNmzRAfH4/du3c77TNnzhz8+uuvCA8PR+fOnZGYmOiS4IeIKoaBBRHVKJ07d0ZsbCwGDRqEdevW4f7778fQoUORnZ191/0cgUJ1GLUobQaoM2fOoHfv3khLS8O8efOwYcMGJCcnY/LkyQBQriliHR+E7ySKolv3LY/09HT06NEDhw8fxttvv40ffvgBycnJ+Pvf/w6g5Ptzd3scOnTogBYtWmD16tUAgNWrV0MURafZoGbPno0pU6age/fu+M9//oOkpCQkJyejVatWbp2695VXXsGsWbMwePBgfPXVV9i8eTOSk5MREBBQZVMGV9X34W6io6Nx8uRJfPHFF3jooYfwzTff4KGHHkJCQoJUZ/Dgwfjjjz/w0UcfoUGDBpg7dy5atWqFH3/8scraSUS8eZuIajClUol3330XvXr1woIFC+66XoAjUEhMTMTw4cPLdfxJkyZh/vz5mDFjBurVq+eiVpfuhx9+QH5+PtatW+f0X+Jt27a59bzl1ahRIwAoMctUWWV32r59O27evIlvv/0W3bt3l8rPnj0rq02//vorRFF0GrU4efJkhY4zbNgwvPXWWzhy5AhWrVqFZs2aoVOnTtL2NWvWoFevXliyZInTfunp6QgMDKxwm202G86cOeP03/rS2rxmzRoMHz4cH3zwgVSWl5eH9PR0p3rlXdnbcf4jR47AZrM5jVo4UtEc3+eq0KhRo1Lfd2ltMRgMGDJkCIYMGQKz2YyBAwdi1qxZmDZtmrR+jdFoxLhx4zBu3Dhcv34d7du3x6xZs6Sb/YnI/ThiQUQ1Ws+ePdG5c2fMnz8feXl5d607adIk1KtXD2+//Xa5ju0IRtauXYtDhw65oLVlc/xnuPh/gjMyMrBs2TK3nre8GjRogPvvvx///ve/nUaHduzYgaNHj95z/9Len9lsxieffFLpNj388MO4cuWK0+rOOTk5+Oyzzyp0HMfoxPTp03Ho0KESa1colcoS/6H/+uuvS13x/V4cH3I//PBDp/L58+eXqFvaeT/66KMS0/MaDAYAKBFwlObhhx/G1atX8eWXX0plBQUF+Oijj+Dt7Y0ePXqU5224xMMPP4xffvkFe/fulcpMJhM+++wzREREoGXLlgBQYuVzjUaDli1bQhRFWCwWWK3WEqlhwcHBaNCgQbmmHiYi1+GIBRHVeH/961/x9NNPY/ny5Xj55ZfLrOfn54eJEyeWOx0KKJqu9vDhw9IHOHeIi4uDRqPBY489hpdeegnZ2dlYvHgxgoODkZqa6rbzVsTs2bPx+OOPo1u3bhg5ciRu376NBQsW4P77779nKlrXrl3h7++P4cOHY8KECRAEAStXrpSVUjNmzBgsWLAAzz//PFJSUmA0GrFy5Uro9foKHadx48bo2rUr1q5dCwAlAotHH30Ub7/9NkaOHImuXbvi6NGj+Pzzz9GkSZMKt7ldu3Z49tln8cknnyAjIwNdu3bFli1bSh31efTRR7Fy5Ur4+fmhZcuW2Lt3L3766acSK4G3a9cOSqUSf//735GRkQGtViuth3KnF198EZ9++ilGjBiBlJQUREREYM2aNdi9ezfmz58PHx+fCr+nu/nmm29K3JgPAMOHD8frr7+O1atXo3///pgwYQLq16+PFStW4OzZs/jmm2+kEZW4uDiEhoaiW7duCAkJwfHjx7FgwQI88sgj8PHxQXp6Oho2bIinnnoKbdu2hbe3N3766SccOHDAabSHiNyPgQUR1XgDBw5E06ZN8f7772PMmDFl5oUDRelN5b35tV69epg0aVKFgpHKaN68OdasWYM333wTr776KkJDQzF27FgEBQVh1KhRbj13eT322GNYvXo1EhMT8frrr6NZs2ZYvnw5VqxYgd9+++2u+wYEBGD9+vX4v//7P7z55pvw9/fHX/7yF/Tu3bvUGbLKQ6/XY8uWLXjllVfw0UcfQa/XY9iwYejfvz/69etXoWMNGzYMe/bsQefOnUvcjP7GG2/AZDJh1apV+PLLL9G+fXts2LDhrql3d7N06VIEBQXh888/x/fff48///nP2LBhA8LDw53q/fOf/4RSqcTnn3+OvLw8dOvWDT/99FOJ/goNDcWiRYvw7rvv4oUXXoDVasW2bdtKDSx0Oh22b9+O119/HStWrEBmZiaaN2+OZcuWYcSIEZV6P3fzxRdflFres2dPPPTQQ9izZw+mTp2Kjz76CHl5eWjTpg1++OEHp3U9XnrpJXz++eeYN28esrOz0bBhQ0yYMAFvvvkmAPt1MG7cOGzevBnffvstbDYbIiMj8cknn2Ds2LEuf09EVDZBrMo7sIiIqNZp164dgoKCkJyc7OmmEBGRB/EeCyIiKheLxYKCggKnsu3bt+Pw4cPo2bOnZxpFRETVBkcsiIioXM6dO4fY2Fj85S9/QYMGDXDixAksWrQIfn5++PXXX0vk/hMRUd3CeyyIiKhc/P390aFDB/zrX//CjRs3YDAY8Mgjj+C9995jUEFERByxICIiIiIi+XiPBRERERERycbAgoiIiIiIZOM9Fm5ks9lw5coV+Pj4QBAETzeHiIiIiKhCRFFEVlYWGjRoIC1cWRYGFm505cqVEgseERERERHVNBcvXkTDhg3vWoeBhRv5+PgAsH8jfH19K7SvxWLB5s2bERcXB7Va7Y7m1XrsQ3nYf/KxD+VjH8rD/pOPfSgf+1A+T/ZhZmYmwsPDpc+1d8PAwo0c6U++vr6VCiz0ej18fX35Q1hJ7EN52H/ysQ/lYx/Kw/6Tj30oH/tQvurQh+VJ6+fN20REREREJBsDCyIiIiIiko2BBRERERERycZ7LIiIiIhqAJvNBrPZ7OlmVJjFYoFKpUJeXh6sVqunm1MjubMP1Wo1lEqlS47FwIKIiIiomjObzTh79ixsNpunm1JhoigiNDQUFy9e5LpeleTuPqxXrx5CQ0NlH5uBBREREVE1JooiUlNToVQqER4efs9Fyqobm82G7OxseHt717i2Vxfu6kNRFJGTk4Pr168DAIxGo6zjMbAgIiIiqsYKCgqQk5ODBg0aQK/Xe7o5FeZI4fLy8mJgUUnu7EOdTgcAuH79OoKDg2WlRfG7S0RERFSNOXLqNRqNh1tCtZUjYLVYLLKOw8CCiIiIqAbg/QnkLq66thhYEBERERGRbAwsiIiIiKhGiIiIwPz58z3dDCoDAwsiIiIicilBEKSHUqmEv78/lEqlVJaYmFip4x44cAAvvviirLb17NkTkyZNknUMKh1nhSIiIiIil0pNTZWef/HFF5g+fTpOnDghzWjk7e0tbRdFEVarFSrVvT+WBgUFub6x5DIcsSAiIiIilwoNDZUevr6+EARBen3ixAn4+Pjgxx9/RIcOHaDVarFr1y6cOXMGjz/+OEJCQuDt7Y1OnTrhp59+cjrunalQgiDgX//6F5588kno9Xo0a9YM69atk9X2b775Bq1atYJWq0VERAQ++OADp+2ffPIJmjVrBi8vL4SEhOCpp56Stq1ZswatW7eGTqdDQEAAYmNjYTKZZLWnJuGIRS2150wa0rLNeLBJfQT7eHm6OUREROQioigi12L1yLl1aqXLZhB6/fXX8f7776NJkybw9/fHxYsX8fDDD2PWrFnQarX497//jcceewwnT57EfffdV+ZxZsyYgTlz5mDu3Ln46KOPMGzYMJw/fx7169evcJtSUlIwePBgJCYmYsiQIdizZw/GjRuHgIAAjBgxAv/9738xYcIErFy5El27dsWtW7ewc+dOAPZRmmeffRZz5szBk08+iaysLOzcuROiKFa6j2oaBha11Mz1x3E8NRMrRnVmYEFERFSL5FqsaDk9ySPnPvZ2X+g1rvn4+Pbbb6NPnz7S6/r166Nt27bS65kzZ+K7777DunXrMH78+DKPM2LECDz77LMAgNmzZ+PDDz/EL7/8gn79+lW4TfPmzUPv3r3x1ltvAQCioqJw7NgxzJ07FyNGjMCFCxdgMBjw6KOPwsfHB40aNcIDDzwAwB5YFBQUYODAgWjUqBEAoHXr1hVuQ03GVKhaSq+xr5qYay7wcEuIiIiISurYsaPT6+zsbLz66quIjo5GvXr14O3tjePHj+PChQt3PU6bNm2k5waDAb6+vrh+/Xql2nT8+HF069bNqaxbt274/fffYbVa0adPHzRq1AhNmjTBc889h88//xw5OTkAgLZt26J3795o3bo1nn76aSxevBi3b9+uVDtqKo5Y1FKOwCLH7JmhUiIiInIPnVqJY2/39di5XcVgMDi9fvXVV5GcnIz3338fkZGR0Ol0eOqpp2A2m+96HLVa7fRaEATYbDaXtbM4Hx8fHDx4ENu3b8fmzZsxffp0JCYm4sCBA6hXrx6Sk5OxZ88ebN68GR999BH+9re/Yf/+/WjcuLFb2lPdMLCopRyBhYmBBRERUa0iCILL0pGqk927d2PEiBF48sknAdhHMM6dO1elbYiOjsbu3btLtCsqKgpKpf2zlUqlQmxsLGJjY5GQkIB69eph69atGDhwIARBQLdu3dCtWzdMnz4djRo1wnfffYcpU6ZU6fvwlNp3VRIASL9wmApFRERENUGzZs3w7bff4rHHHoMgCHjrrbfcNvJw48YNHDp0yKnMaDTi//7v/9CpUyfMnDkTQ4YMwd69e7FgwQJ88sknAID169fjjz/+QPfu3eHv74+NGzfCZrOhefPm2L9/P7Zs2YK4uDgEBwdj//79uHHjBqKjo93yHqojBha1FFOhiIiIqCaZN28eRo0aha5duyIwMBBTp05FZmamW861atUqrFq1yqls5syZePPNN/HVV19h+vTpmDlzJoxGI95++22MGDECAFCvXj18++23SExMRF5eHpo1a4bVq1ejVatWOH78OH7++WfMnz8fmZmZaNSoET744AP079/fLe+hOmJgUUsxsCAiIqLqYMSIERg4cKD0umfPnqVOwRoREYGtW7c6lcXHxzu9vjM1qrTjpKen37U927dvv+v2QYMGYdCgQaVue+ihh8rcPzo6Gps2bbrrsWs7zgpVS+kKU6FymApFRERERFWAgUUtZeCIBRERERFVIQYWtZSUCpXPwIKIiIiI3I+BRS0lpUJZGFgQERERkfsxsKiluPI2EREREVUlBha1FGeFIiIiIqKqxMCiltJLs0IxsCAiIiIi92NgUUsVjVgwFYqIiIiI3I+BRS3FVCgiIiIiqkoMLGqp4qlQpa1KSURERFTd9ezZE5MmTZJeR0REYP78+XfdRxAEfP/997LP7arj1CUMLGopXeGIhdUmwmy1ebg1REREVJc89thj6NevX6nbdu7cCUEQcOTIkQof98CBA3jxxRflNs9JYmIi2rVrV6I8NTUV/fv3d+m57rR8+XLUq1fPreeoSgwsailHKhQA5DIdioiIiKrQCy+8gOTkZFy6dKnEtmXLlqFjx45o06ZNhY8bFBQEvV7viibeU2hoKLRabZWcq7ZgYFFLqZUKaJT2b6+JgQURERFVoUcffRRBQUFYvny5U3l2dja+/vprvPDCC7h58yaeffZZhIWFQa/Xo3Xr1li9evVdj3tnKtTvv/+O7t27w8vLCy1btkRycnKJfaZOnYqoqCjo9Xo0adIEb731FiwWCwD7iMGMGTNw+PBhCIIAQRCkNt+ZCnX06FH8+c9/hk6nQ0BAAF588UVkZ2dL20eMGIEnnngC77//PoxGIwICAhAfHy+dqzIuXLiAxx9/HL6+vrjvvvswZMgQXLt2Tdp++PBh9OrVCz4+PvD19UWHDh3w3//+FwBw/vx5PPbYY/D394fBYECrVq2wcePGSrelPFRuPTp5lE6jhDnXxkXyiIiIahNRBCw5njm3Wg8Iwj2rqVQqPP/881i+fDmmTZsmlX/99dewWq149tlnkZ2djQ4dOmDq1Knw9fXFhg0b8Nxzz6Fp06bo3LnzPc9hs9kwcOBAhISEYP/+/cjIyHC6H8PBx8cHy5cvR4MGDXD06FGMGTMGPj4+eO211zBkyBD8+uuv2LRpE3766ScAgJ+fX4ljmEwm9O3bFzExMThw4ACuX7+O0aNHY/z48U7B07Zt22A0GrFt2zacPn0aQ4YMQbt27TBmzJh7vp/S3t/jjz8Ob29vbNu2DRkZGXj99dcxZMgQbN++HQAwbNgwPPDAA1i4cCGUSiUOHToEtVoNAIiPj4fZbMbPP/8Mg8GAY8eOwdvbu8LtqAgGFrWYQaNERq6FM0MRERHVJpYcYHYDz5z7jSuAxlCuqqNGjcLcuXOxY8cOtG/fHoA9DWrQoEHw8/ODn58fXn31Van+K6+8gqSkJHz11VflCix++uknnDhxAklJSWjQwN4fs2fPLnFfxJtvvik9j4iIwKuvvoovvvgCr732GnQ6Hby9vaFSqRAaGlrmuVatWoW8vDz8+9//hsFgf/8LFizAY489hr///e8ICQkBAPj7+2PBggVQKpVo0aIFHnnkEWzZsqVSgcWWLVtw9OhRnD17FmFhYcjMzMTy5cvRunVrHDhwAJ06dcKFCxfw17/+FS1atAAANGvWTNr/woULGDRoEFq3bg0AaNKkSYXbUFFMharFHDdwm/IZWBAREVHVatGiBbp27Yply5YBAE6fPo2dO3fihRdeAABYrVbMnDkTrVu3Rv369eHt7Y2kpCRcuHChXMc/fvw4wsPDpaACAGJiYkrU+/LLL9GtWzeEhobC29sbb775ZrnPUfxcbdu2lYIKAOjWrRtsNhtOnjwplbVq1QpKZdF9rkajEdevX6/QuYqfMzw8HOHh4VJZy5YtUa9ePRw/fhwAMGXKFIwePRqxsbF47733cObMGanuhAkT8M4776Bbt25ISEio1M3yFcURi1rMMeVsroWpUERERLWGWm8fOfDUuSvghRdewCuvvILZs2dj+fLlaNq0KXr06AEAmDt3Lv75z39i/vz5aN26NQwGAyZNmgSz2eyy5u7duxfDhg3DjBkz0LdvX/j5+eGLL77ABx984LJzFOdIQ3IQBAE2m/tm50xMTMTQoUOxYcMG/Pjjj0hISMAXX3yBJ598EqNHj0bfvn2xYcMGbN68Ge+++y4++OADvPLKK25rD0csajEukkdERFQLCYI9HckTj3LcX1Hc4MGDoVAosGbNGqxcuRKjRo2CUHiM3bt34/HHH8df/vIXtG3bFk2aNMGpU6fKfezo6GhcvHgRqampUtm+ffuc6uzZsweNGjXC3/72N3Ts2BHNmjXD+fPnnepoNBpYrXf/rBQdHY3Dhw/DZDJJZbt374ZCoUDz5s3L3eaKcLy/ixcvSmXHjh1Deno6WrZsKZVFRUVh8uTJ2Lx5MwYOHCiNEAFAeHg4Xn75ZXz77bf4v//7PyxevNgtbXVgYFGLSYEFU6GIiIjIA7y9vTF48GC8/fbbSE1NxYgRI6RtzZo1Q3JyMvbs2YPjx4/jpZdecprx6F5iY2MRFRWF4cOH4/Dhw9i5cyf+9re/OdVp1qwZLly4gC+++AJnzpzBhx9+iO+++86pTkREBM6ePYtDhw4hLS0N+fn5Jc41bNgweHl5Yfjw4fj111+xbds2vPLKK3juueek+ysqy2q14tChQ06P48ePIzY2Fq1bt8awYcNw8OBBpKSkYMSIEejRowc6duyI3NxcjB8/Htu3b8f58+exe/duHDhwANHR0QCASZMmISkpCWfPnsXBgwexbds2aZu7MLCoxYpW32YqFBEREXnGqFGjkJ6ejri4OKf7Id588020b98effv2Rc+ePREaGoonnnii3MdVKBT47rvvkJubi86dO2P06NGYNWuWU50BAwZg8uTJGD9+PNq1a4c9e/bgrbfecqozaNAg9OvXD7169UJQUFCpU97q9XokJSXh1q1b6NSpE5566in07t0bCxYsqFhnlCI7OxsPPPCA0+Oxxx6DIAhYu3Yt/P390bNnTzz55JNo3LgxvvzySwCAUqnEzZs38fzzzyMqKgqDBw9G//79MWPGDAD2gCU+Ph7R0dHo168foqKi8Mknn8hu793wHotaTBqxsHDEgoiIiDwjJiYGt2/fhq+vr1N5/fr1ndaJKI1jWlWHc+fOOb2OiorCzp07ncpEUXR6PWfOHMyZM8eprPi0tFqtFmvWrClx7juP07p1a2zdurXMtt65ZgcApzU3SjNixAinUZw73XfffVi7di1sNhsyMzPh6+sLhcI+LqDRaO667sdHH31013O7A0csajGmQhERERFRVWFgUYvppFQoBhZERERE5F4MLGoxx4gFp5slIiIiInerFoHFxx9/jIiICHh5eaFLly745Zdf7lo/PT0d8fHxMBqN0Gq1iIqKwsaNG6XtWVlZmDRpEho1agSdToeuXbviwIEDTsdITExEixYtYDAY4O/vj9jYWOzfv1/avn37dgiCUOrjzmNVV5xuloiIiIiqiscDiy+//BJTpkxBQkICDh48iLZt26Jv375lrlJoNpvRp08fnDt3DmvWrMHJkyexePFihIWFSXVGjx6N5ORkrFy5EkePHkVcXBxiY2Nx+fJlqU5UVBQWLFiAo0ePYteuXYiIiEBcXBxu3LgBAOjatStSU1OdHqNHj0bjxo3RsWNH93aKizhmheLK20RERETkbh4PLObNm4cxY8Zg5MiRaNmyJRYtWgS9Xo+lS5eWWn/p0qW4desWvv/+e3Tr1g0RERHo0aMH2rZtCwDIzc3FN998gzlz5qB79+6IjIxEYmIiIiMjsXDhQuk4Q4cORWxsLJo0aYJWrVph3rx5yMzMlJY712g0CA0NlR4BAQFYu3YtRo4cKS3sUt0xFYqIiKj2uHOWIiJXcdXq4B6dbtZsNiMlJQXTpk2TyhQKBWJjY7F3795S91m3bh1iYmIQHx+PtWvXIigoCEOHDsXUqVOhVCpRUFAAq9UKLy8vp/10Oh127dpVZjs+++wz+Pn5SQFKaee9efMmRo4cWcl3W/WYCkVERFTzqdVqCIKAGzduICgoqMb8g9PBZrPBbDYjLy9PmiqVKsZdfSiKIsxmM27cuAGFQgGNRiPreB4NLNLS0mC1WkusWBgSEoITJ06Uus8ff/yBrVu3YtiwYdi4cSNOnz6NcePGwWKxICEhAT4+PoiJicHMmTMRHR2NkJAQrF69Gnv37kVkZKTTsdavX49nnnkGOTk5MBqNSE5ORmBgYKnnXbJkCfr27YuGDRuW+X7y8/OdVmvMzMwEAFgsFlgslnL1iYOjfkX3K64wroApr0DWcWoqV/RhXcb+k499KB/7UB72n3zVpQ9DQ0ORmpqK7Oxsj7ajMkRRRF5eHry8vGpcUFRduLsPdTodGjRoAKvVCqvV+R/SFbn2BdGD42pXrlxBWFgY9uzZg5iYGKn8tddew44dO5xupnaIiopCXl4ezp49C6XS/sl53rx5mDt3LlJTUwEAZ86cwahRo/Dzzz9DqVSiffv2iIqKQkpKCo4fPy4dy2QyITU1FWlpaVi8eDG2bt2K/fv3Izg42Omcly5dQqNGjfDVV19h0KBBZb6fxMREabXD4latWgW9Xl+xznGBs1nA/F9VCNCKmN6eoxZEREQ1mSAI0mcfIlex2Wx3TYXKycnB0KFDkZGRUWKRwzt5dMQiMDAQSqUS165dcyq/du0aQkNDS93HaDRCrVY7/WBFR0fj6tWrMJvN0Gg0aNq0KXbs2AGTyYTMzEwYjUYMGTIETZo0cTqWwWBAZGQkIiMj8eCDD6JZs2ZYsmSJU2oWACxbtgwBAQEYMGDAXd/PtGnTMGXKFOl1ZmYmwsPDERcXd89vxJ0sFguSk5PRp08fqNXqCu3rcPJqFub/uhdQafHwwz0rdYyazBV9WJex/+RjH8rHPpSH/Scf+1A+9qF8nuxDRwZOeXg0sNBoNOjQoQO2bNmCJ554AoA9atqyZQvGjx9f6j7dunXDqlWrYLPZpByzU6dOwWg0lsgLMxgMMBgMuH37NpKSkkos534nm83mlMoE2Ieeli1bhueff/6e30itVgutVluiXK1WV/oikLOvr95+n0mO2Vqnf5Dl9CGx/1yBfSgf+1Ae9p987EP52IfyeaIPK3I+j99BM2XKFCxevBgrVqzA8ePHMXbsWJhMJukm6eeff95pBGHs2LG4desWJk6ciFOnTmHDhg2YPXs24uPjpTpJSUnYtGkTzp49i+TkZPTq1QstWrSQjmkymfDGG29g3759OH/+PFJSUjBq1ChcvnwZTz/9tFP7tm7dirNnz2L06NFV0BuupZNmhbLCZuNMEkRERETkPh4dsQCAIUOG4MaNG5g+fTquXr2Kdu3aYdOmTdIN3RcuXHC6+z08PBxJSUmYPHky2rRpg7CwMEycOBFTp06V6mRkZGDatGm4dOkS6tevj0GDBmHWrFlSxKVUKnHixAmsWLECaWlpCAgIQKdOnbBz5060atXKqX1LlixB165d0aJFiyroDdcyaIvSxfIKrNK6FkRERERErlYtPmmOHz++zNSn7du3lyiLiYnBvn37yjze4MGDMXjw4DK3e3l54dtvvy1X21atWlWuetWRl6oosDDlM7AgIiIiIvfxeCoUuY9CIUCnLkyH4loWRERERORGDCxqOUc6VA5X3yYiIiIiN2JgUcs5buA25XPEgoiIiIjch4FFLadX2++rYCoUEREREbkTA4tazjFikWNmKhQRERERuQ8Di1pOuseCIxZERERE5EYMLGo5XWEqFAMLIiIiInInBha1nJ6pUERERERUBRhY1HKOVCjevE1ERERE7sTAopZzpEKZGFgQERERkRsxsKjlHKlQuUyFIiIiIiI3YmBRy+k5KxQRERERVQEGFrWcXs3AgoiIiIjcj4FFLafXOKabZSoUEREREbkPA4tajqlQRERERFQVGFjUckXrWDCwICIiIiL3YWBRyxWtvM1UKCIiIiJyHwYWtRwXyCMiIiKiqsDAopZzpEJxgTwiIiIicicGFrWcrnBWKI5YEBEREZE7MbCo5QyFIxZmqw0Wq83DrSEiIiKi2oqBRS2nKwwsAM4MRURERETuw8CiltMoFVAqBABMhyIiIiIi92FgUcsJggC92rGWBaecJSIiIiL3YGBRB3D1bSIiIiJyNwYWdYBe41gkj4EFEREREbkHA4s6QMdUKCIiIiJyMwYWdQBX3yYiIiIid2NgUQc4Fsnj6ttERERE5C4MLOoAx6xQuUyFIiIiIiI3YWBRB3BWKCIiIiJyNwYWdYC+cPVtpkIRERERkbswsKgDHNPNMhWKiIiIiNyFgUUd4BixYCoUEREREbkLA4s6gIEFEREREbkbA4s6QCetvM1UKCIiIiJyDwYWdYCBIxZERERE5GYMLOoApkIRERERkbsxsKgDilKhGFgQERERkXswsKgDHKlQnG6WiIiIiNyFgUUdoOMCeURERETkZgws6oCiBfIYWBARERGRezCwqAOKbt4ugCiKHm4NEREREdVGDCzqAEdgYROB/AKbh1tDRERERLURA4s6wJEKBXBmKCIiIiJyDwYWdYBSIUCjsn+rufo2EREREbkDA4s6gqtvExEREZE7MbCoI/RcJI+IiIiI3IiBRR2hKzYzFBERERGRq3k8sPj4448REREBLy8vdOnSBb/88std66enpyM+Ph5GoxFarRZRUVHYuHGjtD0rKwuTJk1Co0aNoNPp0LVrVxw4cMDpGImJiWjRogUMBgP8/f0RGxuL/fv3lzjXhg0b0KVLF+h0Ovj7++OJJ55wyXv2hKLVtzliQURERESu59HA4ssvv8SUKVOQkJCAgwcPom3btujbty+uX79ean2z2Yw+ffrg3LlzWLNmDU6ePInFixcjLCxMqjN69GgkJydj5cqVOHr0KOLi4hAbG4vLly9LdaKiorBgwQIcPXoUu3btQkREBOLi4nDjxg2pzjfffIPnnnsOI0eOxOHDh7F7924MHTrUfZ3hZlx9m4iIiIjcSXXvKu4zb948jBkzBiNHjgQALFq0CBs2bMDSpUvx+uuvl6i/dOlS3Lp1C3v27IFarQYARERESNtzc3PxzTffYO3atejevTsA++jEDz/8gIULF+Kdd94BgBIBwrx587BkyRIcOXIEvXv3RkFBASZOnIi5c+fihRdekOq1bNnSpe+/KhWtvs1UKCIiIiJyPY+NWJjNZqSkpCA2NraoMQoFYmNjsXfv3lL3WbduHWJiYhAfH4+QkBDcf//9mD17NqxW+3/hCwoKYLVa4eXl5bSfTqfDrl27ymzHZ599Bj8/P7Rt2xYAcPDgQVy+fBkKhQIPPPAAjEYj+vfvj19//dUVb90j9JwVioiIiIjcyGMjFmlpabBarQgJCXEqDwkJwYkTJ0rd548//sDWrVsxbNgwbNy4EadPn8a4ceNgsViQkJAAHx8fxMTEYObMmYiOjkZISAhWr16NvXv3IjIy0ulY69evxzPPPIOcnBwYjUYkJycjMDBQOg9gH+2YN28eIiIi8MEHH6Bnz544deoU6tevX2r78vPzkZ+fL73OzMwEAFgsFlgslgr1j6N+Rfcri1fhOhZZuWaXHbO6c3Uf1jXsP/nYh/KxD+Vh/8nHPpSPfSifJ/uwIucURFEU3diWMl25cgVhYWHYs2cPYmJipPLXXnsNO3bsKPVm6qioKOTl5eHs2bNQKu3/gZ83bx7mzp2L1NRUAMCZM2cwatQo/Pzzz1AqlWjfvj2ioqKQkpKC48ePS8cymUxITU1FWloaFi9ejK1bt2L//v0IDg7GqlWrMGzYMHz66ad48cUXAdiDhoYNG+Kdd97BSy+9VOp7SkxMxIwZM0qUr1q1Cnq9vvKd5QLfnFXg56sK9Amz4dH7bB5tCxERERHVDDk5ORg6dCgyMjLg6+t717oeG7EIDAyEUqnEtWvXnMqvXbuG0NDQUvcxGo1Qq9VSUAEA0dHRuHr1KsxmMzQaDZo2bYodO3bAZDIhMzMTRqMRQ4YMQZMmTZyOZTAYEBkZicjISDz44INo1qwZlixZgmnTpsFoNAJwvqdCq9WiSZMmuHDhQpnvadq0aZgyZYr0OjMzE+Hh4YiLi7vnN+JOFosFycnJ6NOnj3Q/iRzHk3/Hz1fPosF9EXj44Rayj1cTuLoP6xr2n3zsQ/nYh/Kw/+RjH8rHPpTPk33oyMApD48FFhqNBh06dMCWLVukaVxtNhu2bNmC8ePHl7pPt27dsGrVKthsNigU9tSeU6dOwWg0QqPRONU1GAwwGAy4ffs2kpKSMGfOnLu2x2azSWlMHTp0gFarxcmTJ/HQQw8BsH9Dz507h0aNGpV5DK1WC61WW6JcrVZX+iKQs29x3l72Y+RZxDr3Q+2qPqyr2H/ysQ/lYx/Kw/6Tj30oH/tQPk/0YUXO59HpZqdMmYLFixdjxYoVOH78OMaOHQuTySTNEvX8889j2rRpUv2xY8fi1q1bmDhxIk6dOoUNGzZg9uzZiI+Pl+okJSVh06ZNOHv2LJKTk9GrVy+0aNFCOqbJZMIbb7yBffv24fz580hJScGoUaNw+fJlPP300wAAX19fvPzyy0hISMDmzZtx8uRJjB07FgCkOjWNzrHytoU3bxMRERGR63l0utkhQ4bgxo0bmD59Oq5evYp27dph06ZN0g3dFy5ckEYmACA8PBxJSUmYPHky2rRpg7CwMEycOBFTp06V6mRkZGDatGm4dOkS6tevj0GDBmHWrFlStKVUKnHixAmsWLECaWlpCAgIQKdOnbBz5060atVKOs7cuXOhUqnw3HPPITc3F126dMHWrVvh7+9fRb3jWnppgTxON0tERERErufRwAIAxo8fX2bq0/bt20uUxcTEYN++fWUeb/DgwRg8eHCZ2728vPDtt9/es11qtRrvv/8+3n///XvWrQkcgYUpnyMWREREROR6Hk2FoqqjZyoUEREREbkRA4s6gqlQRERERORODCzqCKZCEREREZE7MbCoIxypULlMhSIiIiIiN2BgUUc4RixymApFRERERG7AwKKOcAQWeRYbrDbRw60hIiIiotqGgUUd4UiFApgORURERESux8CijvBSKyAI9udMhyIiIiIiV2NgUUcIggC92jHlLEcsiIiIiMi1GFjUIbrCdChOOUtERERErsbAog6RFsmzMBWKiIiIiFyLgUUdUjTlLEcsiIiIiMi1GFjUIVx9m4iIiIjchYFFHVK0+jZToYiIiIjItRhY1CFMhSIiIiIid2FgUYdIgQVToYiIiIjIxRhY1CGO6WY5YkFERERErsbAog6RRix4jwURERERuRgDizrEwFQoIiIiInITBhZ1CFOhiIiIiMhdGFjUIVx5m4iIiIjchYFFHcIF8oiIiIjIXRhY1CHSAnlMhSIiIiIiF2NgUYdwVigiIiIichcGFnUIF8gjIiIiIndhYFGH6DkrFBERERG5CQOLOkTnGLEwMxWKiIiIiFyLgUUdYtA6ppvliAURERERuRYDizpEr7anQlmsIswFNg+3hoiIiIhqEwYWdYgjFQrglLNERERE5FoMLOoQjUoBtVIAwClniYiIiMi1GFjUMTo1V98mIiIiItdjYFHHcPVtIiIiInIHBhZ1jF7LKWeJiIiIyPUYWNQx0urbHLEgIiIiIhdiYFHHOKacZWBBRERERK7EwKKO4erbREREROQODCzqGIOWqVBERERE5HoMLOoYHVOhiIiIiMgNGFjUMY6bt3OZCkVERERELsTAoo5xTDdr4ogFEREREbkQA4s6hrNCEREREZE7MLCoY5gKRURERETuwMCijmEqFBERERG5AwOLOqZoxIKBBRERERG5DgOLOqZoulmmQhERERGR6zCwqGO4QB4RERERuQMDizrGkQrFwIKIiIiIXImBRR3DlbeJiIiIyB2qRWDx8ccfIyIiAl5eXujSpQt++eWXu9ZPT09HfHw8jEYjtFotoqKisHHjRml7VlYWJk2ahEaNGkGn06Fr1644cOCA0zESExPRokULGAwG+Pv7IzY2Fvv373eqExERAUEQnB7vvfee6964BzhSoTjdLBERERG5ksrTDfjyyy8xZcoULFq0CF26dMH8+fPRt29fnDx5EsHBwSXqm81m9OnTB8HBwVizZg3CwsJw/vx51KtXT6ozevRo/Prrr1i5ciUaNGiA//znP4iNjcWxY8cQFhYGAIiKisKCBQvQpEkT5Obm4h//+Afi4uJw+vRpBAUFScd6++23MWbMGOm1j4+P+zqjCugcqVAWK0RRhCAIHm4REREREdUGHh+xmDdvHsaMGYORI0eiZcuWWLRoEfR6PZYuXVpq/aVLl+LWrVv4/vvv0a1bN0RERKBHjx5o27YtACA3NxfffPMN5syZg+7duyMyMhKJiYmIjIzEwoULpeMMHToUsbGxaNKkCVq1aoV58+YhMzMTR44ccTqfj48PQkNDpYfBYHBfZ1QBvcYeS4oikGexebg1RERERFRbeDSwMJvNSElJQWxsrFSmUCgQGxuLvXv3lrrPunXrEBMTg/j4eISEhOD+++/H7NmzYbXa7xkoKCiA1WqFl5eX0346nQ67du0qsx2fffYZ/Pz8pADF4b333kNAQAAeeOABzJ07FwUFNTuFSKdWSs855SwRERERuYpHU6HS0tJgtVoREhLiVB4SEoITJ06Uus8ff/yBrVu3YtiwYdi4cSNOnz6NcePGwWKxICEhAT4+PoiJicHMmTMRHR2NkJAQrF69Gnv37kVkZKTTsdavX49nnnkGOTk5MBqNSE5ORmBgoLR9woQJaN++PerXr489e/Zg2rRpSE1Nxbx580ptW35+PvLz86XXmZmZAACLxQKLxVKhvnHUr+h+5eGlViDPYkNGTh58tR4ftHIbd/ZhXcD+k499KB/7UB72n3zsQ/nYh/J5sg8rck5BFEXRjW25qytXriAsLAx79uxBTEyMVP7aa69hx44dJW6mBuz3RuTl5eHs2bNQKu3/fZ83bx7mzp2L1NRUAMCZM2cwatQo/Pzzz1AqlWjfvj2ioqKQkpKC48ePS8cymUxITU1FWloaFi9ejK1bt2L//v2l3tsB2NOwXnrpJWRnZ0Or1ZbYnpiYiBkzZpQoX7VqFfR6fcU6x43eOKCEqUDA1LYFaFB9mkVERERE1UxOTg6GDh2KjIwM+Pr63rWuR0csAgMDoVQqce3aNafya9euITQ0tNR9jEYj1Gq1FFQAQHR0NK5evQqz2QyNRoOmTZtix44dMJlMyMzMhNFoxJAhQ9CkSROnYxkMBkRGRiIyMhIPPvggmjVrhiVLlmDatGmlnrtLly4oKCjAuXPn0Lx58xLbp02bhilTpkivMzMzER4ejri4uHt+I+5ksViQnJyMPn36QK1WV2jfe5lz/GeY0vPQsUtXtAuv59JjVyfu7MO6gP0nH/tQPvahPOw/+diH8rEP5fNkHzoycMrDo4GFRqNBhw4dsGXLFjzxxBMAAJvNhi1btmD8+PGl7tOtWzesWrUKNpsNCoU9jefUqVMwGo3QaDROdQ0GAwwGA27fvo2kpCTMmTPnru2x2WxOqUx3OnToEBQKRZkjGlqtttSRDLVaXemLQM6+ZTFo7d92s02oEz/g7ujDuoT9Jx/7UD72oTzsP/nYh/KxD+XzRB9W5Hwen252ypQpGD58ODp27IjOnTtj/vz5MJlMGDlyJADg+eefR1hYGN59910AwNixY7FgwQJMnDgRr7zyCn7//XfMnj0bEyZMkI6ZlJQEURTRvHlznD59Gn/961/RokUL6ZgmkwmzZs3CgAEDYDQakZaWho8//hiXL1/G008/DQDYu3cv9u/fj169esHHxwd79+7F5MmT8Ze//AX+/v5V3EuupdNwkTwiIiIici2PBxZDhgzBjRs3MH36dFy9ehXt2rXDpk2bpBu6L1y4II1MAEB4eDiSkpIwefJktGnTBmFhYZg4cSKmTp0q1cnIyMC0adNw6dIl1K9fH4MGDcKsWbOkiEupVOLEiRNYsWIF0tLSEBAQgE6dOmHnzp1o1aoVAPvowxdffIHExETk5+ejcePGmDx5slOqU02lL5wZirNCEREREZGreDywAIDx48eXmfq0ffv2EmUxMTHYt29fmccbPHgwBg8eXOZ2Ly8vfPvtt3dtU/v27e96jprMsfo2RyyIiIiIyFVq71yjVCamQhERERGRqzGwqIMcqVC5TIUiIiIiIhdhYFEH6QtToUwcsSAiIiIiF2FgUQfpNY4RCwYWREREROQaDCzqIL10jwVToYiIiIjINRhY1EGOEQvevE1ERERErsLAog5iYEFERERErsbAog7SMRWKiIiIiFyMgUUdZODN20RERETkYgws6iCdhtPNEhEREZFrMbCogxyzQnHEgoiIiIhcpVKBxcWLF3Hp0iXp9S+//IJJkybhs88+c1nDyH2Kbt7mPRZERERE5BqVCiyGDh2Kbdu2AQCuXr2KPn364JdffsHf/vY3vP322y5tILmenqlQRERERORilQosfv31V3Tu3BkA8NVXX+H+++/Hnj178Pnnn2P58uWubB+5gSMVylxgg9Umerg1RERERFQbVCqwsFgs0Gq1AICffvoJAwYMAAC0aNECqamprmsduYVjxAJgOhQRERERuUalAotWrVph0aJF2LlzJ5KTk9GvXz8AwJUrVxAQEODSBpLraVUKKAT7cy6SR0RERESuUKnA4u9//zs+/fRT9OzZE88++yzatm0LAFi3bp2UIkXVlyAIUjoUAwsiIiIicgVVZXbq2bMn0tLSkJmZCX9/f6n8xRdfhF6vd1njyH10GiWy8wuYCkVERERELlGpEYvc3Fzk5+dLQcX58+cxf/58nDx5EsHBwS5tILmHQZpyliMWRERERCRfpQKLxx9/HP/+978BAOnp6ejSpQs++OADPPHEE1i4cKFLG0juoWMqFBERERG5UKUCi4MHD+JPf/oTAGDNmjUICQnB+fPn8e9//xsffvihSxtI7uGYGSqXqVBERERE5AKVCixycnLg4+MDANi8eTMGDhwIhUKBBx98EOfPn3dpA8k9pEXy8jliQURERETyVSqwiIyMxPfff4+LFy8iKSkJcXFxAIDr16/D19fXpQ0k93AEFjkWBhZEREREJF+lAovp06fj1VdfRUREBDp37oyYmBgA9tGLBx54wKUNJPdwTDfLVCgiIiIicoVKTTf71FNP4aGHHkJqaqq0hgUA9O7dG08++aTLGkfuo+esUERERETkQpUKLAAgNDQUoaGhuHTpEgCgYcOGXByvBmFgQURERESuVKlUKJvNhrfffht+fn5o1KgRGjVqhHr16mHmzJmw2WyubiO5QdF0s0yFIiIiIiL5KjVi8be//Q1LlizBe++9h27dugEAdu3ahcTEROTl5WHWrFkubSS5HhfIIyIiIiJXqlRgsWLFCvzrX//CgAEDpLI2bdogLCwM48aNY2BRA0ipUJxuloiIiIhcoFKpULdu3UKLFi1KlLdo0QK3bt2S3ShyPykVitPNEhEREZELVCqwaNu2LRYsWFCifMGCBWjTpo3sRpH7ceVtIiIiInKlSqVCzZkzB4888gh++uknaQ2LvXv34uLFi9i4caNLG0juwZW3iYiIiMiVKjVi0aNHD5w6dQpPPvkk0tPTkZ6ejoEDB+K3337DypUrXd1GcgNpgTymQhERERGRC1R6HYsGDRqUuEn78OHDWLJkCT777DPZDSP3KlrHgqlQRERERCRfpUYsqObjrFBERERE5EoMLOoofbFZoURR9HBriIiIiKimY2BRR+kKRyysNhFmK1dLJyIiIiJ5KnSPxcCBA++6PT09XU5bqAo5UqEAezqUVqW8S20iIiIiorurUGDh5+d3z+3PP/+8rAZR1VArFdAoFTBbbcixWOHv6QYRERERUY1WocBi2bJl7moHeYBOo4Q518ZF8oiIiIhINt5jUYcZuEgeEREREbkIA4s6TCetZcHAgoiIiIjkYWBRhxWtvs1UKCIiIiKSh4FFHabniAURERERuQgDizqMq28TERERkaswsKjDpNW3OSsUEREREcnEwKIOk0YsLByxICIiIiJ5GFjUYUyFIiIiIiJXYWBRh+mkVCgGFkREREQkT7UILD7++GNERETAy8sLXbp0wS+//HLX+unp6YiPj4fRaIRWq0VUVBQ2btwobc/KysKkSZPQqFEj6HQ6dO3aFQcOHHA6RmJiIlq0aAGDwQB/f3/ExsZi//79pZ4vPz8f7dq1gyAIOHTokOz3W104Riw43SwRERERyeXxwOLLL7/ElClTkJCQgIMHD6Jt27bo27cvrl+/Xmp9s9mMPn364Ny5c1izZg1OnjyJxYsXIywsTKozevRoJCcnY+XKlTh69Cji4uIQGxuLy5cvS3WioqKwYMECHD16FLt27UJERATi4uJw48aNEud87bXX0KBBA9e/eQ/Tc+VtIiIiInIRjwcW8+bNw5gxYzBy5Ei0bNkSixYtgl6vx9KlS0utv3TpUty6dQvff/89unXrhoiICPTo0QNt27YFAOTm5uKbb77BnDlz0L17d0RGRiIxMRGRkZFYuHChdJyhQ4ciNjYWTZo0QatWrTBv3jxkZmbiyJEjTuf78ccfsXnzZrz//vvu6wQP0TMVioiIiIhcxKOBhdlsRkpKCmJjY6UyhUKB2NhY7N27t9R91q1bh5iYGMTHxyMkJAT3338/Zs+eDavV/uG4oKAAVqsVXl5eTvvpdDrs2rWrzHZ89tln8PPzkwIUALh27RrGjBmDlStXQq/Xy3271Q5ToYiIiIjIVVSePHlaWhqsVitCQkKcykNCQnDixIlS9/njjz+wdetWDBs2DBs3bsTp06cxbtw4WCwWJCQkwMfHBzExMZg5cyaio6MREhKC1atXY+/evYiMjHQ61vr16/HMM88gJycHRqMRycnJCAwMBACIoogRI0bg5ZdfRseOHXHu3Ll7vp/8/Hzk5+dLrzMzMwEAFosFFoulIl0j1a/ofhWhtccVyM4rcOt5PKUq+rA2Y//Jxz6Uj30oD/tPPvahfOxD+TzZhxU5pyCKoujGttzVlStXEBYWhj179iAmJkYqf+2117Bjx45Sb6aOiopCXl4ezp49C6XS/sl43rx5mDt3LlJTUwEAZ86cwahRo/Dzzz9DqVSiffv2iIqKQkpKCo4fPy4dy2QyITU1FWlpaVi8eDG2bt2K/fv3Izg4GB9++CG++uor7NixA0qlEufOnUPjxo3xv//9D+3atSv1/SQmJmLGjBklyletWlUtRzxOpgv45LgSRp2I19sxHYqIiIiInOXk5GDo0KHIyMiAr6/vXet6dMQiMDAQSqUS165dcyq/du0aQkNDS93HaDRCrVZLQQUAREdH4+rVqzCbzdBoNGjatCl27NgBk8mEzMxMGI1GDBkyBE2aNHE6lsFgQGRkJCIjI/Hggw+iWbNmWLJkCaZNm4atW7di79690Gq1Tvt07NgRw4YNw4oVK0q0bdq0aZgyZYr0OjMzE+Hh4YiLi7vnN+JOFosFycnJ6NOnD9RqdYX2LS/jhXR8cvwXKL30ePjhP7nlHJ5UFX1Ym7H/5GMfysc+lIf9Jx/7UD72oXye7ENHBk55eDSw0Gg06NChA7Zs2YInnngCAGCz2bBlyxaMHz++1H26deuGVatWwWazQaGw3yJy6tQpGI1GaDQap7oGgwEGgwG3b99GUlIS5syZc9f22Gw2KZXpww8/xDvvvCNtu3LlCvr27Ysvv/wSXbp0KXV/rVZbIhABALVaXemLQM6+9+JrsLc112yt1T/o7uzDuoD9Jx/7UD72oTzsP/nYh/KxD+XzRB9W5HweDSwAYMqUKRg+fDg6duyIzp07Y/78+TCZTBg5ciQA4Pnnn0dYWBjeffddAMDYsWOxYMECTJw4Ea+88gp+//13zJ49GxMmTJCOmZSUBFEU0bx5c5w+fRp//etf0aJFC+mYJpMJs2bNwoABA2A0GpGWloaPP/4Yly9fxtNPPw0AuO+++5za6e3tDQBo2rQpGjZs6PZ+qQp6NWeFIiIiIiLX8HhgMWTIENy4cQPTp0/H1atX0a5dO2zatEm6ofvChQvSyAQAhIeHIykpCZMnT0abNm0QFhaGiRMnYurUqVKdjIwMTJs2DZcuXUL9+vUxaNAgzJo1S4q4lEolTpw4gRUrViAtLQ0BAQHo1KkTdu7ciVatWlVtB3iQTpoVygqbTYRCIXi4RURERERUU3k8sACA8ePHl5n6tH379hJlMTEx2LdvX5nHGzx4MAYPHlzmdi8vL3z77bcVamNERAQ8eJ+7Wxi0Rfep5FqsMGirxeVARERERDWQxxfII8/xUhUFFkyHIiIiIiI5GFjUYQqFAJ26MB2KgQURERERycDAoo5zpEPlcPVtIiIiIpKBgUUd57iB25TPEQsiIiIiqjwGFnWcY8pZpkIRERERkRwMLOo4vSMVysxUKCIiIiKqPAYWdZxe4wgsOGJBRERERJXHwKKO03H1bSIiIiJyAQYWdVzRiAVToYiIiIio8hhY1HHSdLMcsSAiIiIiGRhY1HFMhSIiIiIiV2BgUcc5UqFymQpFRERERDIwsKjjHNPNmjhiQUREREQyMLCo4/Rqx4gFAwsiIiIiqjwGFnWcXuO4x4KpUERERERUeQws6jimQhERERGRKzCwqOOKbt5mYEFERERElcfAoo4rmm6WqVBEREREVHkMLOo4LpBHRERERK7AwKKOc6RCMbAgIiIiIjkYWNRxusJZoXiPBRERERHJwcCijjMUjliYrTZYrDYPt4aIiIiIaioGFnWcrjCwAJgORURERESVx8CijtMoFVAqBABMhyIiIiKiymNgUccJggC92nEDN6ecJSIiIqLKYWBB0urbTIUiIiIiospiYEHQaxyL5DGwICIiIqLKYWBB0DEVioiIiIhkYmBBXH2biIiIiGRjYEHSInkMLIiIiIioshhYkDQrVC5ToYiIiIiokhhYkDQrlIkjFkRERERUSQwsCHoN77EgIiIiInkYWJA03SxToYiIiIioshhYkDRiwVQoIiIiIqosBhYkBRa5DCyIiIiIqJIYWFCx6WaZCkVERERElcPAgmDgzdtEREREJBMDC+KsUEREREQkGwML4srbRERERCQbAwuSUqE43SwRERERVRYDC4KO080SERERkUwMLKjYAnkMLIiIiIiochhYULGbtwsgiqKHW0NERERENREDC5ICC5sI5BfYPNwaIiIiIqqJGFiQlAoFcGYoIiIiIqocBhYEpUKARmW/FLj6NhERERFVBgMLAsDVt4mIiIhIHgYWBKAoHYqBBRERERFVBgMLAlC0lgVToYiIiIioMqpFYPHxxx8jIiICXl5e6NKlC3755Ze71k9PT0d8fDyMRiO0Wi2ioqKwceNGaXtWVhYmTZqERo0aQafToWvXrjhw4IDTMRITE9GiRQsYDAb4+/sjNjYW+/fvd6ozYMAA3HffffDy8oLRaMRzzz2HK1euuO6NVyNSKlQ+RyyIiIiIqOI8Hlh8+eWXmDJlChISEnDw4EG0bdsWffv2xfXr10utbzab0adPH5w7dw5r1qzByZMnsXjxYoSFhUl1Ro8ejeTkZKxcuRJHjx5FXFwcYmNjcfnyZalOVFQUFixYgKNHj2LXrl2IiIhAXFwcbty4IdXp1asXvvrqK5w8eRLffPMNzpw5g6eeesp9neFB0oiFhYEFEREREVWc6t5V3GvevHkYM2YMRo4cCQBYtGgRNmzYgKVLl+L1118vUX/p0qW4desW9uzZA7VaDQCIiIiQtufm5uKbb77B2rVr0b17dwD20YkffvgBCxcuxDvvvAMAGDp0aIl2LFmyBEeOHEHv3r0BAJMnT5a2N2rUCK+//jqeeOIJWCwW6dy1RdHq20yFIiIiIqKK82hgYTabkZKSgmnTpkllCoUCsbGx2Lt3b6n7rFu3DjExMYiPj8fatWsRFBSEoUOHYurUqVAqlSgoKIDVaoWXl5fTfjqdDrt27SqzHZ999hn8/PzQtm3bUuvcunULn3/+Obp27VpmUJGfn4/8/HzpdWZmJgDAYrHAYrGU3RGlcNSv6H6VpSucbjYz11xl53S3qu7D2ob9Jx/7UD72oTzsP/nYh/KxD+XzZB9W5JweDSzS0tJgtVoREhLiVB4SEoITJ06Uus8ff/yBrVu3YtiwYdi4cSNOnz6NcePGwWKxICEhAT4+PoiJicHMmTMRHR2NkJAQrF69Gnv37kVkZKTTsdavX49nnnkGOTk5MBqNSE5ORmBgoFOdqVOnYsGCBcjJycGDDz6I9evXl/l+3n33XcyYMaNE+ebNm6HX68vbLU6Sk5MrtV9FpV1TAFDg0NFj2Hj7tyo5Z1Wpqj6srdh/8rEP5WMfysP+k499KB/7UD5P9GFOTk656wqiKIpubMtdXblyBWFhYdizZw9iYmKk8tdeew07duwocTM1YL83Ii8vD2fPnoVSab8vYN68eZg7dy5SU1MBAGfOnMGoUaPw888/Q6lUon379oiKikJKSgqOHz8uHctkMiE1NRVpaWlYvHgxtm7div379yM4OFiqk5aWhlu3buH8+fOYMWMG/Pz8sH79egiCUKJtpY1YhIeHIy0tDb6+vhXqG4vFguTkZPTp06dK0q7e3nACK/ddwNjujTGlTzO3n68qVHUf1jbsP/nYh/KxD+Vh/8nHPpSPfSifJ/swMzMTgYGByMjIuOfnWY+OWAQGBkKpVOLatWtO5deuXUNoaGip+xiNRqjVaimoAIDo6GhcvXoVZrMZGo0GTZs2xY4dO2AymZCZmQmj0YghQ4agSZMmTscyGAyIjIxEZGQkHnzwQTRr1gxLlixxSs0KDAxEYGAgoqKiEB0djfDwcOzbt88pEHLQarXQarUlytVqdaUvAjn7VoSPl/0cuQVirfuhr6o+rK3Yf/KxD+VjH8rD/pOPfSgf+1A+T/RhRc7n0VmhNBoNOnTogC1btkhlNpsNW7ZsKfWDOwB069YNp0+fhs1mk8pOnToFo9EIjUbjVNdgMMBoNOL27dtISkrC448/ftf22Gw2pxGH0rYDuGudmkpfOCtULhfIIyIiIqJK8Ph0s1OmTMHixYuxYsUKHD9+HGPHjoXJZJJmiXr++eedRhDGjh2LW7duYeLEiTh16hQ2bNiA2bNnIz4+XqqTlJSETZs24ezZs0hOTkavXr3QokUL6ZgmkwlvvPEG9u3bh/PnzyMlJQWjRo3C5cuX8fTTTwMA9u/fjwULFuDQoUM4f/48tm7dimeffRZNmzYtM+ipyXSOlbc53SwRERERVYLHp5sdMmQIbty4genTp+Pq1ato164dNm3aJN3QfeHCBSgURfFPeHg4kpKSMHnyZLRp0wZhYWGYOHEipk6dKtXJyMjAtGnTcOnSJdSvXx+DBg3CrFmzpKEcpVKJEydOYMWKFUhLS0NAQAA6deqEnTt3olWrVgAAvV6Pb7/9FgkJCTCZTDAajejXrx/efPPNUtOdajqDNGLB6WaJiIiIqOI8HlgAwPjx4zF+/PhSt23fvr1EWUxMDPbt21fm8QYPHozBgweXud3LywvffvvtXdvUunVrbN269a51ahPHAnkmrrxNRERERJXg8VQoqh70TIUiIiIiIhkYWBCA4jdvMxWKiIiIiCqOgQUBKAosmApFRERERJXBwIIAFKVC5TIVioiIiIgqgYEFASgaschhKhQRERERVQIDCwJQFFjkWWyw2kQPt4aIiIiIahoGFgSgKBUKYDoUEREREVUcAwsCAHipFRAE+3OmQxERERFRRTGwIACAIAjQqwvvs+DMUERERERUQQwsSKJzLJJnZmBBRERERBXDwIIk0iJ5FqZCEREREVHFMLAgCRfJIyIiIqLKYmBBkqK1LBhYEBEREVHFMLAgSdHq20yFIiIiIqKKYWBBEqZCEREREVFlMbAgiXTzNlOhiIiIiKiCGFiQhNPNEhEREVFlMbAgiXTzNu+xICIiIqIKYmBBEoOGK28TERERUeUwsCAJU6GIiIiIqLIYWJCEK28TERERUWUxsCAJp5slIiIiospiYEESaYE8pkIRERERUQUxsCAJZ4UiIiIiospiYEESPWeFIiIiIqJKYmBBEj1nhSIiIiKiSmJgQRKdY8TCzFQoIiIiIqoYBhYkMWgdgQVHLIiIiIioYhhYkESvtqdCFdhEmAtsHm4NEREREdUkDCxI4kiFAjjlLBERERFVDAMLkmhUCqiVAgDAxPssiIiIiKgCGFiQE52a91kQERERUcUxsCAnXH3bdc6mmXA8NdPTzSAiIiKqEgwsyIm+cGYopkLJk2exYuAnu/HEx7txLTPP080hIiIicjsGFuTEsfo2Ryzk2fl7Gm7nWJBfYMPm3656ujlEREREbsfAgpw4ppzlPRbyJBULJpJ+u+bBlhARERFVDQYW5ISrb8tXYLVhy/GiYGLfHzeRkWPxYIuIiIiI3I+BBTnh6tvyHTh3G7dzLKinVyMy2BsFNhFbT3LUgoiIiGo3BhbkRMdUKNkcaVC9W4Sg//2h9rJfGVgQERFR7cbAgpwU3bzNVKjKEEURycfsQUTfViHo28oeWOw4dQN5FgZrREREVHsxsCAnRdPN8kNwZfx2JROX03OhUyvRPSoIrRr4IqyeDrkWK3b+nubp5hERERG5DQMLcsJZoeRxpEF1jwqEl1oJQRDQp2WI0zYiIiKi2oiBBTlhKpQ8m39zpEGFSmWO51uOX0OB1eaRdhERERG5GwMLcsJUqMo7l2bCyWtZUCoE9G4RIpV3ivCHv16N2zkWHDh324MtJCIiInIfBhbkhCtvV54j1enBJvXhp1dL5SqlAr2jmQ5FREREtRsDC3JSNN0sU6EqavOxkmlQDo6y5GPXIIpilbaLiIiIqCowsCAnXCCvcq5n5eHgBXuak+Nm7eL+1CwQeo0Sl9Nz8evlzKpuHhEREZHbMbAgJ45UKAYWFWMfiQDaNvSD0U9XYruXWokeUUEAgM3HmA5FREREtQ8DC3LClbcrxzEbVFwpaVAOca14nwURERHVXtUisPj4448REREBLy8vdOnSBb/88std66enpyM+Ph5GoxFarRZRUVHYuHGjtD0rKwuTJk1Co0aNoNPp0LVrVxw4cMDpGImJiWjRogUMBgP8/f0RGxuL/fv3S9vPnTuHF154AY0bN4ZOp0PTpk2RkJAAs9ns2jdfzRSlQvEei/LKzLNgzxn74nel3V/h8OfmIVApBJy6lo2zaaaqah4RERFRlfB4YPHll19iypQpSEhIwMGDB9G2bVv07dsX169fL7W+2WxGnz59cO7cOaxZswYnT57E4sWLERYWJtUZPXo0kpOTsXLlShw9ehRxcXGIjY3F5cuXpTpRUVFYsGABjh49il27diEiIgJxcXG4ceMGAODEiROw2Wz49NNP8dtvv+Ef//gHFi1ahDfeeMO9HeJhOsesUBYrbzIup20nrsNiFdEkyIDIYO8y6/np1YhpGgAA2MxRCyIiIqplPB5YzJs3D2PGjMHIkSPRsmVLLFq0CHq9HkuXLi21/tKlS3Hr1i18//336NatGyIiItCjRw+0bdsWAJCbm4tvvvkGc+bMQffu3REZGYnExERERkZi4cKF0nGGDh2K2NhYNGnSBK1atcK8efOQmZmJI0eOAAD69euHZcuWIS4uDk2aNMGAAQPw6quv4ttvv3V/p3iQXmNPhRJFIM/CxdzK426zQd0pjqtwExERUS2l8uTJzWYzUlJSMG3aNKlMoVAgNjYWe/fuLXWfdevWISYmBvHx8Vi7di2CgoIwdOhQTJ06FUqlEgUFBbBarfDy8nLaT6fTYdeuXWW247PPPoOfn58UoJQmIyMD9evXL3N7fn4+8vPzpdeZmfbZfywWCywWS5n7lcZRv6L7yaVC0ShFhikXKkFbped3parow3yLFdtP2EfXejcPvOe5ekbZRywOXkjH5VvZCPapvv3rqWuwNmEfysc+lIf9Jx/7UD72oXye7MOKnNOjgUVaWhqsVitCQpyn5wwJCcGJEydK3eePP/7A1q1bMWzYMGzcuBGnT5/GuHHjYLFYkJCQAB8fH8TExGDmzJmIjo5GSEgIVq9ejb179yIyMtLpWOvXr8czzzyDnJwcGI1GJCcnIzAwsNTznj59Gh999BHef//9Mt/Pu+++ixkzZpQo37x5M/R6/b26o1TJycmV2k8OtUIJi03Axs1bEOB17/rVnTv78LfbAkxmJfw0Ii4e3o3LR+69TyNvJc5nC5j/9VY8FFr90808cQ3WNuxD+diH8rD/5GMfysc+lM8TfZiTk1Puuh4NLCrDZrMhODgYn332GZRKJTp06IDLly9j7ty5SEhIAACsXLkSo0aNQlhYGJRKJdq3b49nn30WKSkpTsfq1asXDh06hLS0NCxevBiDBw/G/v37ERwc7FTv8uXL6NevH55++mmMGTOmzLZNmzYNU6ZMkV5nZmYiPDwccXFx8PX1rdD7tFgsSE5ORp8+faBWq++9gwslHt6G2zkWdOn2J0SF+FTpuV2pKvpw9/e/AbiMR9vdh0cfiS7XPhe9z+L95N9xVRmMhx/u4JZ2uYInr8Hagn0oH/tQHvaffOxD+diH8nmyDx0ZOOXh0cAiMDAQSqUS165dcyq/du0aQkNLz1c3Go1Qq9VQKpVSWXR0NK5evQqz2QyNRoOmTZtix44dMJlMyMzMhNFoxJAhQ9CkSROnYxkMBkRGRiIyMhIPPvggmjVrhiVLljilZl25cgW9evVC165d8dlnn931/Wi1Wmi1JVNb1Gp1pS8COftWll6jwu0cC8w2oVb8AnBXH1ptIracsN/s3791g3Kfo3+bBng/+XfsO3sLuVbA16t697EnrsHahn0oH/tQHvaffOxD+diH8nmiDytyPo/evK3RaNChQwds2bJFKrPZbNiyZQtiYmJK3adbt244ffo0bLaiG4tPnToFo9EIjUbjVNdgMMBoNOL27dtISkrC448/ftf22Gw2p3skLl++jJ49e6JDhw5YtmwZFAqP3+teJbj6dvmknL+NmyYzfL1U6NKk7Htv7tQ0yBuRwd6wWEVsO1H67GdERERENY3HPylPmTIFixcvxooVK3D8+HGMHTsWJpMJI0eOBAA8//zzTiMIY8eOxa1btzBx4kScOnUKGzZswOzZsxEfHy/VSUpKwqZNm3D27FkkJyejV69eaNGihXRMk8mEN954A/v27cP58+eRkpKCUaNG4fLly3j66acBFAUV9913H95//33cuHEDV69exdWrtX82H52Gi+SVh2Nmp97RIVArK/aj1LdwsTzHwnpERERENZ3H77EYMmQIbty4genTp+Pq1ato164dNm3aJN3QfeHCBaeRgvDwcCQlJWHy5Mlo06YNwsLCMHHiREydOlWqk5GRgWnTpuHSpUuoX78+Bg0ahFmzZklDOUqlEidOnMCKFSuQlpaGgIAAdOrUCTt37kSrVq0A2G+OOX36NE6fPo2GDRs6tbm2r++gV3ORvHsRRRGbj9kDC0eQUBFxLUPx8bYz2H7yOvIsVniplffeiYiIiKga83hgAQDjx4/H+PHjS922ffv2EmUxMTHYt29fmccbPHgwBg8eXOZ2Ly+ve65HMWLECIwYMeKudWorpkLd2/HULFy8lQutSoHuUUEV3r9NQz8Y/byQmpGH3afT0Du64sEJERERUXXi8VQoqn6YCnVvjjSoPzULkhYVrAhBELhYHhEREdUqDCyoBEcqVC5TocpUtNp25Uca4gpX6v7p+HVYbbU7vY6IiIhqPwYWVIK+MBXKxBGLUl28lYPjqZlQKgTEykhh6ty4Pvx0atwymfHfc7dc2EIiIiKiqsfAgkrQaxwjFgwsSuNIXeocUR/+Bs09apdNrVSgd3Rw4TE5OxQRERHVbAwsqAS9dI8FU6FK45giNk5GGpRD38J0qKTfrtb62caIiIiodmNgQSU4RiyYClVSWnY+Dpy3py057pGQo3uzIHipFbicnotjqZmyj0dERETkKQwsqASmQpXtp2PXIIpA6zA/hNXTyT6eTqNE92b26WqZDkVEREQ1GQMLKkHHVKgyOWaDckwV6wqOdKjNnHaWiIiIajAGFlSCQcMF8kqTnV+AXb+nAQD63i8/Dcqhd3QwlAoBJ65m4fxNk8uOS0RERFSVGFhQCToGFqXafvI6zFYbGgca0CzY22XHrafXoEvj+gCKbgwnIiIiqmkYWFAJjlmheI+FM2k2qJYhEATBpccuPjsUERERUU3EwIJKMEizQvEeCwdzgQ3bTlwH4JrZoO7Up/CejZQLt3EjK9/lxyciIiJyNwYWVAJToUracyYNWfkFCPbR4oHwei4/foN6OrRp6AdRBH46znQoIiIiqnkYWFAJjlQoc4ENVhsXbQOKZoPq0zIECoVr06AcmA5FRERENRkDCyrBsY4FwClnAcBmE5HsmGbWDWlQDn0LV/Lec/omsvIsbjsPERERkTswsKAStCoFHP+UZzoU8L+L9vsefLxUiGkS4LbzNA3yRpNAA8xWG7afvOG28xARERG5AwOL2urCfuDyQaDAXOFdBUGQ0qEYWBStiP3nFsHQqNz3IyMIgjQiwnQoIiIiqmlUnm4AuclPCcCFvYBSA4TcD4S1Bxo8ADRoDwQ1BxTKu+6u0yiRnV9Q51OhRFGUPuTHtXRfGpRD31YhWLTjDLafvIH8Aiu0qrt/n4iIiIiqCwYWtZUhEND5A7m3gSsH7Q8HtQEwti0WbDwA1G8CFFubwaBR4gY4YnHqWjbO38yBRqVAz+ZBbj9f24b1EOKrxbXMfOw5fRO9WgS7/ZxERERErsDAorYa8h9AFIHb5+xBxeWDwJVDQOohwJwNXNhjfzh41SsKMsLaI1xVgHNQV9/AwmwCsq8B2TcA0/U7ntsfKtMN/ClfAaUtCQi9HwiOtj+8Q5yCqLtxjFb8KTIQBq37f1wUCgF9WobgP/suYPOxqwwsiIiIqMZgYFGbCQJQv7H9cf8ge5nNCqT9XjiK8T97wHH1KJCXDvyxzf4AsBLALa03tOsCAV9/QOMNaH0BrQ+g9S786gNofIqeS+W+9voaAyBaAasFsJoLH5ZiX0sptxUrL8gHcm4WBgrXANONogDCYrr32wdQHwAOnwEOF9ug8weCWwJBLYqCjeCWgL5+iWNsPlaYBlU4Y1NV6NsqFP/ZdwHJx67hnSdEKN00vW2tZLPZr2VTmv16yUkDVDrAtwHgF2YPoF28ajoRERHZMbCoaxRKILiF/dFuqL2swAxcP1Ys2PgfrNd+Q30hG8jOBrLPebTJZVLpAO/gwkcIYAgqem0IRoG2Hv63cxPaN9RBefMkcP0EcOuMPT3s/G77ozjvkMJgoyUQ3ALXdU2Qe+UEWivM6OfjDZz+HbDk2h8FhV8tOUVlljvKCnIBawGgUABC8Yey2HPB/lVRVNYNAv7pdQ35ecDNL9YguJ4foNICKi9ApSn86lWs7C5flZqS/SaWtTbJHeUFBfAy3wTyMgFVfc98IBdFIC/DHmCabhQ+0uyPnLRiZYXbc27ag9myqPX2IMO3AeDbsNjzMHvg4RtmDzwr+l5F0R4Mm03277/ZBJhNEHIzEZh1DMLlEEDvZz+/xmD/qtYxyCEiolqFgQXZP6w2aGd/FJqycjdOHTsMb+TCW8iFN3IRqDYjWGtGoNqM+qp81FPmw1eRCwPyoBdzoLWaoC7IhrLABCE/CxBtRedQagofavtXhbroefFypdr5uT4AMAQ7BQzSc433XT+YiRYLrvjfRrseD0OpVtsLLXlA2ingxgl7MHX9uP2Rfr5wNOQacHYHACAYwBZt4cG+cGmP35UCwOOA/afzVNWd905qAH0B4LfJ9qDHy8/+H39dvfJ/1foCBXn24CQ/s/Brxh2v7/xabHt+FmCrxAQCWj/7fUaGQPsH/cwr9qDDkgPcPG1/lMUxwuEIONS6omDBkgOYHc9N9ueObaUENCoA3QDg9HulnEgoCjI0evv17HiuNti3OZU7yrzv/ryyAYutcHRRGjUs9rwg746gOq+wLKfwebHA+s66Bfn2wEuhdA6wpdfKYq+FEmUKEWieeh2KlGtAvTDAOxTwCbH/LlCVEjjLZbPZ//ngCFpz0uzfXwCAUNi3hf3reF6i7M5tsP8+FEX7V5u18HVpj8I6YrE6Nqv956Cs749jm9V8R70CKAvy0f32TSjTPrFfTyodoPYq9tXLfs2U+lVfVFehLHo/xf8pAgEl/lFSWj3H91WhLPx65+ti5dWZzWa/rs05zr8DHL8bSi3LsX9vpD7VFfWt9FpX9Fx152svz/WLzQZY8+0/14LC/rdbobL/fXbnP0Zs1qJsBumaLgAgFv2MOD3HHeWFP0vFn4tW+z/7bAUlf3ZslpK/A20FztuBYr9zvQszOUp5rdbX6X8aMbCgUj3TtQXmZgFXMvNxIzsf5gIbkA/7oxy8tUoYDYCXRgutRgOdVgW9Rgm9RgUvtbLwuRI6jRJ6tb1c5yhTF5ZrVFAq7NOwCgAUggBBsH+FCVDk5jmVCwIgQIBCsO9jLSiAyQLcNJmhVNogiiJsImDTNYMtPBJiw0dhE0X775v8bKhunYLm1kmob56E5tZJ5F/5FQprPjReehgMPqX8ASjlj8KdfzgUyrI/LBT/0CBtt9c5cSUD3//vIgL0CgxoFQDBmg+FNR9CQT4Utnz764L8ovJSvtofZkgfeIo9Ewv7tCShWCXAZrNA6Whz7m3743blrilZND6AIcA+KqUvDBgMQUVf9QFFr/WBpX/gtOTaAwzpcbnwcaXoq+mG/UPDrTP2R2UoNVIgIKp1yDLlwkergOAIQAryCiuK9vudzNnAvTP7yk2EAFFtgE2th6g2QFR5AaIVgtUCwWaBYCuAYLP/0XR8hdUC4c4Rq2pCCaAFAGz6vuRGfYB9pNE7BPAJLfY8pDAAKSwDIJpuwJp1HZas67BlXYct+wbE7BsQTDcg5KRBmXsTytw0qPNvQ7jbqFcNowDgDwA5f3i4JeUjQrgj2LAHmKJCA5tSA5tCA6tCgwJBgwJBDYuggVnQwAwV8kU18kUVckU18kQVcmwq5FhVMNmUEEUBeqUVekUB9MoCeAlFD61QAA0KoIYFGpihEi1QiRYobWYobRYorPnom5sF1dEC++8HD8iH/f1aBTWsggpWhRo2QQ1RoYZNaf/q/E86DQSVBoJSA4VaA6VSA4XNAoXNDIWt+N8Ls/T3QlH4N0MoyAMK/94Ijg/UpRAFpf18CiWgcLRBVRR8KFQQlfbngqDEQ+npEC7PgdXpd48ZsDpeFwXN1fX3UXmIEGBTG2BVGWBV62FVG2BTGWBTGyCqtBCUWkClgaDSSg+F2gsKtf25Uu0FpcYLCpW2MANBCyi1EKCAIf+ap9/ePQmiWGZeBMmUmZkJPz8/ZGRkwNfXt0L7WiwWbNy4EQ8//DDUjv+2e4goisjMK0Badj7SsuyBRlpWPtKyzUjLzseNrHz7tmxzURBSi+x8rRfC6+ur9Jw55gI88HYy8qtBX2phhh9M8BNM8EN24dfC14XPfYuXFfvqJVhQICqQBT2yRJ39K/TIEvXIgg7Zha+zRR2yBXu5oywL9ufpgg/M0ECAUPTP4MK2CcUDpGLbhMKKFf2nkUY0Iwi3EYKb0kMLC/KgRR68kCd4IVfwQp6gRb6gQz60yBO8kK/wQr5gf9gU6qIAWBSRnZ0Nnd4AqwhYbSJsVgvUtnyobbnQ2vKgseVCK+ZBa8uDDnnQIR96IR865MGAfOiFPOiRD4Ng32ZAHvRC4TbkwSDkFX4tZ9RfAfmiCgVQIg8a+0PUOD3PLXyef8drx/N8aJAPNUQIUEKEWiFCJYhQK1D41QaVAKgVIpSCCLVg365SiFDB/lUJK5SmGwjR5KCe9Zb9YbsNFdz74T9dNOCm6Is0+CFHtA9dStedPXyT6jpeKxUClAKgVAAqQYBSYb8OFIIIq6iAFQKsYvEHUFDsdYEIFIgK2CAUPhT2DymiAAuUKIAKFqgKn9sf5sLvUQFUMEMllVtEJSyFr61QQIMCeMEML8Fs/woLvAQztLC/1jltMxfbZoEXzFDABoVgf88KqWUiFLD/V1hR+CitzP6ORChhg0rw/O80V8kVNciBFrnQIhdehT8bXsgVin5f5Ata5AteMItKKKz5UFrzoBPM8EK+1O86Id/e/8gv3GYv1wplf6iva2yiAGvhlYTCnw/HT6Gt8Iq7s1wsfO34CbVCgQJRKf38WFH03AIVCkTHc/vPk+O5tfDnCYD0+9bb8XsXefAWcu2/o5En/Yy4yzZtbzz06pdV/rmwIp9nOWJB9yQIAvx0avjp1Gga5H3XusWDkFsmM0z5Bcg1W5FjtiLHYkWuuQC5ZhtyLEXluWYrci1W5JiL1TVbkWexwiqKsNlE+y8J0X58ESgaaRABEfaRCMeIROnvwfEHHtIHVMdraSREIRTVKfzA2qdlSJUHFQCg16gwoXczrP7lQolbIor/L0CUyoptL/aBxyaW7Debzd53tuJljjpi0WuHfGhwHRpcF/2dT1oOahTAgsIUClmq6sOIgOuoj99QH0CzSuxvLnw4HxO5OXeUKQF4Fz4q0DqhKHASpNf2QgVs0AlmGAqDEENhsKGFGQWiAvmi/Y+jWVTALCphdvyBFVXF/pg6fxiV/327g5xYoFgXCrChHrIRLKTbH0hHkOO5UPgctxEkZMBbsI8Q5Yoa3IQv0kRf3BT9cAu+SFfUQ4bCD5mKeshW+SNbWQ8mdX3kqetBqdJCq1ZAo7R/aLnz95Pjd1aexb3XpkIANCoFvNRKaAu/eqmU0KoV0letSgmvYl8NxeqqFcCpk8cRGdUCZiuQa7H/zr1e+DtW+t1rsSHPbC383WxDXmF5Wb9T5RBgg7LwoSj2/M4yhVBUpoIV3soC+Kpt8FXZ4KsugI/KBm+VFd5KKwzKAugVVuiUBdALBfBSFBQGRwXQwP4fcDPUyId9VCPPpkJu4dccqxI5NiVMViVMBUpkWZXILlAi06JAlkVAhkWJfKjtQYSoRQ60yIMGoow1hjVKBXy8VPD2Utm/alXw8VLDR6uSyn21CtRTW+GrssBbUYACSz4s5nwUmPNgMefDajGjwJIHq8UMqyUPNosZtgIzxIJ8iFb78+ITpthHdewjO3lQI0+0P/JFFfJEtTTSkwc1cm2FI0BQI98+jgMF7IG+GlaoCh9qFEAlFL1WSdsLoC4sd+xjg1AYHCthKfZ7xyJ9iFc5lUtlUMHmxvWclQqh8J8CAlQKAUql/aui2GulYH99t1+JgmiDFmboxFzokQudmAe9mAsdcqET7a8VNjNUNgsUohkqmxkqsWiETC1aoBHs16u28OF4rSm8jtOEkpPMVDcMLMilnIMQz7TB8QE532zGpk2b8MjD/aHRuCEX283ie0Uivlekx85vNpuxYeOP6NevH1RqtRTEOYKY4q8dQYqU0lpYbi+z7yAW28dRUDwwcjo2ir6PxRVtd66LO85TVFeE/A/HjvdYFNBKgW1hUFsU6DoHuZYCC/bv/wXdYh6EVqO2/5FSCFAV/uFSKRTSa2Xx1456hV+Fig69lJPNJsImirAWtt9a+NomOm9zjAuVNmLk/NqxvVhFEbCKIgqsNlhshV+tIqw2ERarDQXFygpsNhRYi5XbROSbLTh8+DA6PNAOGrXaqV/ufO7oQ4UCMCsUuKoQoCrIgVopQK3zho9KhQCVAhqVwmWzrdlsYuGHc/sH8Zxi/zCxf2C3wlxgg0ZlD1I0hedXO54X+6p2vC5WT247LRYLNmYew8N/alzh/3KKogiz1YY8s83pHxZAse9xUYHzy7tvLuFe17ijTzwhP9+MHzb+iD5xcVAoVfbbDkRR+keNVbRfz45yx8+R1Vb0XIDgFER4qav/4qeO32OO9yCHxWJBUlIS+vXtC5XM/7bf+Xeg+N8Asdh23PF3BYAUNEi/K4R7X3tVpfjvREuBDZZivw8tVhF5+Wbk7N3p6WbeEwMLqnWEwhEIlbJ6/dKoaYTC0RuV0v4hiCrOYrHg9gkRnSL8PZ7SWBqFQoACQrX+Q2CxWKC5cggPtzFWsg8rNipUUQqFAINWVbjOjfae9WsSQRCgVSmhVVX/D8HupFAIUCvsI8nV8efYXQTBkdon/2+oEjaoFYBWrYS6BgRVnmD/50hh35Tyq8RiseBMDfgVw08LREREREQkGwMLIiIiIiKSjYEFERERERHJxsCCiIiIiIhkY2BBRERERESyMbAgIiIiIiLZGFgQEREREZFsDCyIiIiIiEg2BhZERERERCQbAwsiIiIiIpKNgQUREREREcnGwIKIiIiIiGRjYEFERERERLIxsCAiIiIiItkYWBARERERkWwqTzegNhNFEQCQmZlZ4X0tFgtycnKQmZkJtVrt6qbVCexDedh/8rEP5WMfysP+k499KB/7UD5P9qHjc6zjc+3dMLBwo6ysLABAeHi4h1tCRERERFR5WVlZ8PPzu2sdQSxP+EGVYrPZcOXKFfj4+EAQhArtm5mZifDwcFy8eBG+vr5uamHtxj6Uh/0nH/tQPvahPOw/+diH8rEP5fNkH4qiiKysLDRo0AAKxd3vouCIhRspFAo0bNhQ1jF8fX35QygT+1Ae9p987EP52IfysP/kYx/Kxz6Uz1N9eK+RCgfevE1ERERERLIxsCAiIiIiItkYWFRTWq0WCQkJ0Gq1nm5KjcU+lIf9Jx/7UD72oTzsP/nYh/KxD+WrKX3Im7eJiIiIiEg2jlgQEREREZFsDCyIiIiIiEg2BhZERERERCQbA4tq6uOPP0ZERAS8vLzQpUsX/PLLL55uUo2QmJgIQRCcHi1atPB0s6q1n3/+GY899hgaNGgAQRDw/fffO20XRRHTp0+H0WiETqdDbGwsfv/9d880tpq6Vx+OGDGixHXZr18/zzS2Gnr33XfRqVMn+Pj4IDg4GE888QROnjzpVCcvLw/x8fEICAiAt7c3Bg0ahGvXrnmoxdVPefqwZ8+eJa7Dl19+2UMtrl4WLlyINm3aSGsExMTE4Mcff5S28/q7t3v1Ia+/innvvfcgCAImTZokldWE65CBRTX05ZdfYsqUKUhISMDBgwfRtm1b9O3bF9evX/d002qEVq1aITU1VXrs2rXL002q1kwmE9q2bYuPP/641O1z5szBhx9+iEWLFmH//v0wGAzo27cv8vLyqril1de9+hAA+vXr53Rdrl69ugpbWL3t2LED8fHx2LdvH5KTk2GxWBAXFweTySTVmTx5Mn744Qd8/fXX2LFjB65cuYKBAwd6sNXVS3n6EADGjBnjdB3OmTPHQy2uXho2bIj33nsPKSkp+O9//4s///nPePzxx/Hbb78B4PVXHvfqQ4DXX3kdOHAAn376Kdq0aeNUXiOuQ5Gqnc6dO4vx8fHSa6vVKjZo0EB89913PdiqmiEhIUFs27atp5tRYwEQv/vuO+m1zWYTQ0NDxblz50pl6enpolarFVevXu2BFlZ/d/ahKIri8OHDxccff9wj7amJrl+/LgIQd+zYIYqi/ZpTq9Xi119/LdU5fvy4CEDcu3evp5pZrd3Zh6Ioij169BAnTpzouUbVMP7+/uK//vUvXn8yOPpQFHn9lVdWVpbYrFkzMTk52anPasp1yBGLasZsNiMlJQWxsbFSmUKhQGxsLPbu3evBltUcv//+Oxo0aIAmTZpg2LBhuHDhgqebVGOdPXsWV69edboe/fz80KVLF16PFbR9+3YEBwejefPmGDt2LG7evOnpJlVbGRkZAID69esDAFJSUmCxWJyuwxYtWuC+++7jdViGO/vQ4fPPP0dgYCDuv/9+TJs2DTk5OZ5oXrVmtVrxxRdfwGQyISYmhtdfJdzZhw68/u4tPj4ejzzyiNP1BtSc34MqTzeAnKWlpcFqtSIkJMSpPCQkBCdOnPBQq2qOLl26YPny5WjevDlSU1MxY8YM/OlPf8Kvv/4KHx8fTzevxrl69SoAlHo9OrbRvfXr1w8DBw5E48aNcebMGbzxxhvo378/9u7dC6VS6enmVSs2mw2TJk1Ct27dcP/99wOwX4cajQb16tVzqsvrsHSl9SEADB06FI0aNUKDBg1w5MgRTJ06FSdPnsS3337rwdZWH0ePHkVMTAzy8vLg7e2N7777Di1btsShQ4d4/ZVTWX0I8Porjy+++AIHDx7EgQMHSmyrKb8HGVhQrdK/f3/peZs2bdClSxc0atQIX331FV544QUPtozqsmeeeUZ63rp1a7Rp0wZNmzbF9u3b0bt3bw+2rPqJj4/Hr7/+ynujZCirD1988UXpeevWrWE0GtG7d2+cOXMGTZs2repmVjvNmzfHoUOHkJGRgTVr1mD48OHYsWOHp5tVo5TVhy1btuT1dw8XL17ExIkTkZycDC8vL083p9KYClXNBAYGQqlUlrjL/9q1awgNDfVQq2quevXqISoqCqdPn/Z0U2okxzXH69G1mjRpgsDAQF6Xdxg/fjzWr1+Pbdu2oWHDhlJ5aGgozGYz0tPTnerzOiyprD4sTZcuXQCA12EhjUaDyMhIdOjQAe+++y7atm2Lf/7zn7z+KqCsPiwNrz9nKSkpuH79Otq3bw+VSgWVSoUdO3bgww8/hEqlQkhISI24DhlYVDMajQYdOnTAli1bpDKbzYYtW7Y45SlS+WRnZ+PMmTMwGo2ebkqN1LhxY4SGhjpdj5mZmdi/fz+vRxkuXbqEmzdv8rosJIoixo8fj++++w5bt25F48aNnbZ36NABarXa6To8efIkLly4wOuw0L36sDSHDh0CAF6HZbDZbMjPz+f1J4OjD0vD689Z7969cfToURw6dEh6dOzYEcOGDZOe14TrkKlQ1dCUKVMwfPhwdOzYEZ07d8b8+fNhMpkwcuRITzet2nv11Vfx2GOPoVGjRrhy5QoSEhKgVCrx7LPPerpp1VZ2drbTf4zOnj2LQ4cOoX79+rjvvvswadIkvPPOO2jWrBkaN26Mt956Cw0aNMATTzzhuUZXM3frw/r162PGjBkYNGgQQkNDcebMGbz22muIjIxE3759Pdjq6iM+Ph6rVq3C2rVr4ePjI+UL+/n5QafTwc/PDy+88AKmTJmC+vXrw9fXF6+88gpiYmLw4IMPerj11cO9+vDMmTNYtWoVHn74YQQEBODIkSOYPHkyunfvXmJKy7po2rRp6N+/P+677z5kZWVh1apV2L59O5KSknj9ldPd+pDX3735+Pg43RMFAAaDAQEBAVJ5jbgOPT0tFZXuo48+Eu+77z5Ro9GInTt3Fvft2+fpJtUIQ4YMEY1Go6jRaMSwsDBxyJAh4unTpz3drGpt27ZtIoASj+HDh4uiaJ9y9q233hJDQkJErVYr9u7dWzx58qRnG13N3K0Pc3JyxLi4ODEoKEhUq9Vio0aNxDFjxohXr171dLOrjdL6DoC4bNkyqU5ubq44btw40d/fX9Tr9eKTTz4ppqameq7R1cy9+vDChQti9+7dxfr164tarVaMjIwU//rXv4oZGRmebXg1MWrUKLFRo0aiRqMRg4KCxN69e4ubN2+WtvP6u7e79SGvv8q5c4remnAdCqIoilUZyBARERERUe3DeyyIiIiIiEg2BhZERERERCQbAwsiIiIiIpKNgQUREREREcnGwIKIiIiIiGRjYEFERERERLIxsCAiIiIiItkYWBARERERkWwMLIiIqM4RBAHff/+9p5tBRFSrMLAgIqIqNWLECAiCUOLRr18/TzeNiIhkUHm6AUREVPf069cPy5YtcyrTarUeag0REbkCRyyIiKjKabVahIaGOj38/f0B2NOUFi5ciP79+0On06FJkyZYs2aN0/5Hjx7Fn//8Z+h0OgQEBODFF19Edna2U52lS5eiVatW0Gq1MBqNGD9+vNP2tLQ0PPnkk9Dr9WjWrBnWrVvn3jdNRFTLMbAgIqJq56233sKgQYNw+PBhDBs2DM888wyOHz8OADCZTOjbty/8/f1x4MABfP311/jpp5+cAoeFCxciPj4eL774Io4ePYp169YhMjLS6RwzZszA4MGDceTIETz88MMYNmwYbt26VaXvk4ioNhFEURQ93QgiIqo7RowYgf/85z/w8vJyKn/jjTfwxhtvQBAEvPzyy1i4cKG07cEHH0T79u3xySefYPHixZg6dSouXrwIg8EAANi4cSMee+wxXLlyBSEhIQgLC8PIkSPxzjvvlNoGQRDw5ptvYubMmQDswYq3tzd+/PFH3utBRFRJvMeCiIiqXK9evZwCBwCoX7++9DwmJsZpW0xMDA4dOgQAOH78ONq2bSsFFQDQrVs32Gw2nDx5EoIg4MqVK+jdu/dd29CmTRvpucFggK+vL65fv17Zt0REVOcxsCAioipnMBhKpCa5ik6nK1c9tVrt9FoQBNhsNnc0iYioTuA9FkREVO3s27evxOvo6GgAQHR0NA4fPgyTySRt3717NxQKBZo3bw4fHx9ERERgy5YtVdpmIqK6jiMWRERU5fLz83H16lWnMpVKhcDAQADA119/jY4dO+Khhx7C559/jl9++QVLliwBAAwbNgwJCQkYPnw4EhMTcePGDbzyyit47rnnEBISAgBITEzEyy+/jODgYPTv3x9ZWVnYvXs3Xnnllap9o0REdQgDCyIiqnKbNm2C0Wh0KmvevDlOnDgBwD5j0xdffIFx48bBaDRi9erVaNmyJQBAr9cjKSkJEydORKdOnaDX6zFo0CDMmzdPOtbw4cORl5eHf/zjH3j11VcRGBiIp556qureIBFRHcRZoYiIqFoRBAHfffcdnnjiCU83hYiIKoD3WBARERERkWwMLIiIiIiISDbeY0FERNUKM3SJiGomjlgQEREREZFsDCyIiIiIiEg2BhZERERERCQbAwsiIiIiIpKNgQUREREREcnGwIKIiIiIiGRjYEFERERERLIxsCAiIiIiItkYWBARERERkWz/D0bL/aclnzxlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating at SNR = 0.0 dB...\n",
            "SNR=0.0 | SC BER=4.95e-01, BLER=1.00e+00 | RNN BER=4.99e-01, BLER=1.00e+00 | SCL L=1 BER=3.71e-01, BLER=1.00e+00 | SCL L=4 BER=3.73e-01, BLER=1.00e+00 | SCL L=8 BER=3.74e-01, BLER=1.00e+00 | SCL L=16 BER=3.74e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 0.5 dB...\n",
            "SNR=0.5 | SC BER=4.94e-01, BLER=1.00e+00 | RNN BER=5.00e-01, BLER=1.00e+00 | SCL L=1 BER=3.50e-01, BLER=1.00e+00 | SCL L=4 BER=3.50e-01, BLER=1.00e+00 | SCL L=8 BER=3.51e-01, BLER=1.00e+00 | SCL L=16 BER=3.51e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 1.0 dB...\n",
            "SNR=1.0 | SC BER=4.94e-01, BLER=1.00e+00 | RNN BER=5.00e-01, BLER=1.00e+00 | SCL L=1 BER=3.24e-01, BLER=1.00e+00 | SCL L=4 BER=3.24e-01, BLER=1.00e+00 | SCL L=8 BER=3.26e-01, BLER=1.00e+00 | SCL L=16 BER=3.26e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 1.5 dB...\n",
            "SNR=1.5 | SC BER=4.93e-01, BLER=1.00e+00 | RNN BER=5.00e-01, BLER=1.00e+00 | SCL L=1 BER=2.99e-01, BLER=1.00e+00 | SCL L=4 BER=2.98e-01, BLER=1.00e+00 | SCL L=8 BER=2.99e-01, BLER=1.00e+00 | SCL L=16 BER=3.00e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 2.0 dB...\n",
            "SNR=2.0 | SC BER=4.94e-01, BLER=1.00e+00 | RNN BER=5.00e-01, BLER=1.00e+00 | SCL L=1 BER=2.70e-01, BLER=1.00e+00 | SCL L=4 BER=2.66e-01, BLER=1.00e+00 | SCL L=8 BER=2.67e-01, BLER=1.00e+00 | SCL L=16 BER=2.68e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 2.5 dB...\n",
            "SNR=2.5 | SC BER=4.93e-01, BLER=1.00e+00 | RNN BER=5.00e-01, BLER=1.00e+00 | SCL L=1 BER=2.38e-01, BLER=1.00e+00 | SCL L=4 BER=2.28e-01, BLER=1.00e+00 | SCL L=8 BER=2.29e-01, BLER=1.00e+00 | SCL L=16 BER=2.29e-01, BLER=1.00e+00\n",
            "Simulating at SNR = 3.0 dB...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZFMGymCQTNVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}