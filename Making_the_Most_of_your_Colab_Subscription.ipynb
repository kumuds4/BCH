{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFBua2Csaq03",
        "outputId": "b30e493d-6f3d-4205-93f0-8354b0dc6559"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "iyB7i06xcV2O",
        "outputId": "887d0a23-717e-4767-e28d-ce0a6bb3d545"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5cc59c2-3db9-453f-92c7-0b7974261e22\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5cc59c2-3db9-453f-92c7-0b7974261e22\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving making_the_most_of_your_colab_subscription (14).py to making_the_most_of_your_colab_subscription (14).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cyQW1fN5fhJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "#######################################################################\n",
        "#latest version\n",
        "# Logging Configuration\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(levelname)s]: %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "# Polar Code Generator Class\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {\n",
        "                'polynomial': [1, 1, 1, 0, 0, 1, 1],\n",
        "                'length': 7\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(info_bits)] = info_bits\n",
        "        return codeword\n",
        "\n",
        "# Channel Simulator Class\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        # Convert bits {0,1} to BPSK: {+1, -1}\n",
        "        bpsk_signal = 1 - 2 * encoded_signal\n",
        "\n",
        "        # Convert SNR from dB to linear scale\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "\n",
        "        # Compute signal power\n",
        "        signal_power = np.mean(bpsk_signal**2)\n",
        "\n",
        "        # Noise power calculation\n",
        "        noise_power = signal_power / snr_linear\n",
        "        noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "        # Channel-specific simulation\n",
        "        if self.channel_type == 'AWGN':\n",
        "            noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "            received_signal = bpsk_signal + noise\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "            noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "            received_signal = fading * bpsk_signal + noise\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "        # Convert back to binary representation\n",
        "        return (received_signal > 0).astype(float)\n",
        "\n",
        "# Dataset Preparation Function\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type=\"AWGN\"):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate information bits\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "        # Encode polar code\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "        # Channel simulation\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "\n",
        "        # Store features and labels\n",
        "        X.append(received_signal)\n",
        "\n",
        "        # Binary classification label\n",
        "        y.append(1 if np.mean(info_bits) > 0.5 else 0)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Neural Network Decoder\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, device=None):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        ).to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "        return self.model(x).squeeze(-1)\n",
        "\n",
        "# Decoder Trainer\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='min', factor=0.5, patience=5\n",
        "        )\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        # Ensure inputs are tensors\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if not isinstance(y, torch.Tensor):\n",
        "            y = torch.FloatTensor(y)\n",
        "\n",
        "        # Move to device\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        # Reshape y if needed\n",
        "        y = y.view(-1, 1)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X))\n",
        "        X_train, X_val = X[:train_size], X[train_size:]\n",
        "        y_train, y_val = y[:train_size], y[train_size:]\n",
        "\n",
        "        # Create data loaders\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        val_dataset = TensorDataset(X_val, y_val)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, \"\n",
        "                  f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "            outputs = torch.sigmoid(self.model(X))\n",
        "        return outputs.cpu().numpy().flatten()\n",
        "\n",
        "# Performance Metrics Function\n",
        "def compute_performance_metrics(y_true, y_pred):\n",
        "    y_true_binary = (y_true > 0.5).astype(int)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    ber = np.mean(y_true_binary != y_pred_binary)\n",
        "    bler = 1 - np.mean(y_true_binary == y_pred_binary)\n",
        "\n",
        "    cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
        "    class_report = classification_report(y_true_binary, y_pred_binary)\n",
        "\n",
        "    return {\n",
        "        'BER': ber,\n",
        "        'BLER': bler,\n",
        "        'Confusion Matrix': cm,\n",
        "        'Classification Report': class_report\n",
        "    }\n",
        "\n",
        "# Visualization Function for Training/Validation Loss\n",
        "def plot_training_validation_loss(train_losses, val_losses, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#########################################################################\n",
        "\n",
        "\n",
        "\n",
        "# polar_code_generator.py\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        \"\"\"\n",
        "        Polar Code Generator with CRC support\n",
        "\n",
        "        Args:\n",
        "            N (int): Total code length\n",
        "            K (int): Information bit length\n",
        "            crc_type (str): CRC polynomial type\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "\n",
        "        # CRC Polynomials\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {\n",
        "                'polynomial': [1, 1, 1, 0, 0, 1, 1],\n",
        "                'length': 7\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        \"\"\"\n",
        "        Generate random information bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Random information bits\n",
        "        \"\"\"\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        \"\"\"\n",
        "        Compute CRC checksum using polynomial division\n",
        "\n",
        "        Args:\n",
        "            bits (np.ndarray): Input bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: CRC checksum bits\n",
        "        \"\"\"\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "\n",
        "        # Convert input to list and pad\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "\n",
        "        # Polynomial long division\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        # Return the last 'crc_length' bits\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Polar Code Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Append CRC\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Basic polar encoding (placeholder)\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "\n",
        "        return codeword\n",
        "\n",
        "\n",
        "#part three\n",
        "######################################################\n",
        "\n",
        "\n",
        "\n",
        "######################################################\n",
        "\n",
        "\n",
        "\n",
        "#part 4\n",
        "\n",
        "# dataset_preparation.py\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type=\"AWGN\"):\n",
        "    \"\"\"\n",
        "    Prepare dataset for Polar Code simulation\n",
        "\n",
        "    Args:\n",
        "        polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "        num_samples (int): Number of samples to generate\n",
        "        snr_db (float): Signal-to-Noise Ratio in dB\n",
        "        channel_type (str): Channel type\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input features and corresponding labels\n",
        "    \"\"\"\n",
        "    # Create channel simulator\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "\n",
        "    # Initialize storage\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate information bits\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "        # Encode polar code\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "        # Channel simulation\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "\n",
        "        # Store features and labels\n",
        "        X.append(received_signal)\n",
        "\n",
        "        # Binary classification label (based on mean of info_bits)\n",
        "        y.append(1 if np.mean(info_bits) > 0.5 else 0)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part 5\n",
        "\n",
        "# neural_decoder.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_performance_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute comprehensive performance metrics\n",
        "\n",
        "    Args:\n",
        "        y_true (np.ndarray): True labels\n",
        "        y_pred (np.ndarray): Predicted labels\n",
        "\n",
        "    Returns:\n",
        "        dict: Performance metrics\n",
        "    \"\"\"\n",
        "    # Convert to binary labels if not already\n",
        "    y_true_binary = (y_true > 0.5).astype(int)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Bit Error Rate (BER)\n",
        "    ber = np.mean(y_true_binary != y_pred_binary)\n",
        "\n",
        "    # Block Error Rate (BLER)\n",
        "    bler = 1 - np.mean(y_true_binary == y_pred_binary)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
        "\n",
        "    # Classification Report\n",
        "    class_report = classification_report(y_true_binary, y_pred_binary)\n",
        "\n",
        "    return {\n",
        "        'BER': ber,\n",
        "        'BLER': bler,\n",
        "        'Confusion Matrix': cm,\n",
        "        'Classification Report': class_report\n",
        "    }\n",
        "\n",
        "def plot_performance_metrics(metrics):\n",
        "    \"\"\"\n",
        "    Create comprehensive performance visualization\n",
        "\n",
        "    Args:\n",
        "        metrics (dict): Performance metrics\n",
        "    \"\"\"\n",
        "    # Create a figure with multiple subplots\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Confusion Matrix Heatmap\n",
        "    sns.heatmap(\n",
        "        metrics['Confusion Matrix'],\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        ax=axs[0]\n",
        "    )\n",
        "    axs[0].set_title('Confusion Matrix')\n",
        "    axs[0].set_xlabel('Predicted Label')\n",
        "    axs[0].set_ylabel('True Label')\n",
        "\n",
        "    # Performance Metrics Bar Plot\n",
        "    performance_data = {\n",
        "        'Bit Error Rate (BER)': metrics['BER'],\n",
        "        'Block Error Rate (BLER)': metrics['BLER']\n",
        "    }\n",
        "\n",
        "    axs[1].bar(performance_data.keys(), performance_data.values())\n",
        "    axs[1].set_title('Error Rate Performance')\n",
        "    axs[1].set_ylabel('Error Rate')\n",
        "    axs[1].set_ylim(0, 1)\n",
        "\n",
        "    # Add text annotations to bar plot\n",
        "    for i, (key, value) in enumerate(performance_data.items()):\n",
        "        axs[1].text(i, value, f'{value:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "####################################################\n",
        "#Enhanced BER, BLER plot_performance_metrics\n",
        "class PerformanceVisualizer:\n",
        "    @staticmethod\n",
        "    def plot_ber_bler_performance(performance_results, channel_type):\n",
        "        \"\"\"\n",
        "        Create comprehensive BER and BLER performance plots\n",
        "\n",
        "        Args:\n",
        "            performance_results (dict): Performance metrics from simulation\n",
        "            channel_type (str): Channel type (AWGN or Rayleigh)\n",
        "        \"\"\"\n",
        "        # Extract list sizes and SNR range\n",
        "        list_sizes = performance_results['List Sizes']\n",
        "        snr_range = performance_results['SNR']\n",
        "\n",
        "        # Create figure with two subplots\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        fig.suptitle(f'Performance Analysis for {channel_type} Channel')\n",
        "\n",
        "        # BER Plot with Logarithmic Scale\n",
        "        ax1.set_title('Bit Error Rate (BER)')\n",
        "        ax1.set_xlabel('SNR (dB)')\n",
        "        ax1.set_ylabel('BER')\n",
        "        ax1.set_yscale('log')  # Logarithmic y-axis\n",
        "        ax1.set_ylim(1e-4, 1e0)  # Y-axis limit from 10^-4 to 10^0\n",
        "        ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "\n",
        "        # BLER Plot with Logarithmic Scale\n",
        "        ax2.set_title('Block Error Rate (BLER)')\n",
        "        ax2.set_xlabel('SNR (dB)')\n",
        "        ax2.set_ylabel('BLER')\n",
        "        ax2.set_yscale('log')  # Logarithmic y-axis\n",
        "        ax2.set_ylim(1e-4, 1e0)  # Y-axis limit from 10^-4 to 10^0\n",
        "        ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "\n",
        "        # Color and marker cycles for different list sizes\n",
        "        colors = ['blue', 'red', 'green']\n",
        "        markers = ['o', 's', '^']\n",
        "\n",
        "        # Plot BER for each list size\n",
        "        for i, list_size in enumerate(list_sizes):\n",
        "            ber_values = performance_results['BER'][list_size]\n",
        "            ax1.plot(\n",
        "                snr_range,\n",
        "                ber_values,\n",
        "                label=f'List Size {list_size}',\n",
        "                color=colors[i],\n",
        "                marker=markers[i],\n",
        "                markersize=8\n",
        "            )\n",
        "\n",
        "        # Plot BLER for each list size\n",
        "        for i, list_size in enumerate(list_sizes):\n",
        "            bler_values = performance_results['BLER'][list_size]\n",
        "            ax2.plot(\n",
        "                snr_range,\n",
        "                bler_values,\n",
        "                label=f'List Size {list_size}',\n",
        "                color=colors[i],\n",
        "                marker=markers[i],\n",
        "                markersize=8\n",
        "            )\n",
        "\n",
        "        # Add legends\n",
        "        ax1.legend()\n",
        "        ax2.legend()\n",
        "\n",
        "        # Adjust layout and display\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "###################################################\n",
        "#part 6 main() function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_training_validation_loss(train_losses, val_losses, channel_type, list_size, snr):\n",
        "    \"\"\"\n",
        "    Plot training and validation losses\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'Training and Validation Losses\\n{channel_type} Channel, List Size {list_size}, SNR {snr} dB')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, channel_type, list_size, snr):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix with enhanced visualization\n",
        "    \"\"\"\n",
        "    # Convert to binary labels\n",
        "    y_true_binary = (y_true > 0.5).astype(int)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=['Negative', 'Positive'],\n",
        "        yticklabels=['Negative', 'Positive']\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix\\n{channel_type} Channel, List Size {list_size}, SNR {snr} dB')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#########################################################################################\n",
        "# Main Simulation Function\n",
        "def main():\n",
        "    # Simulation Configuration\n",
        "    BLOCK_LENGTH = 32\n",
        "    INFO_BITS = 16\n",
        "    NUM_SAMPLES = 5000\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32\n",
        "    VALIDATION_SPLIT = 0.2\n",
        "\n",
        "    # Polar Code Generator\n",
        "    polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "\n",
        "    # Prepare dataset\n",
        "    X, y = prepare_polar_dataset(\n",
        "        polar_code_gen,\n",
        "        num_samples=NUM_SAMPLES,\n",
        "        snr_db=5,  # You can adjust SNR\n",
        "        channel_type=\"AWGN\"\n",
        "    )\n",
        "\n",
        "    # Flatten input features\n",
        "    X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_flattened, y,\n",
        "        test_size=VALIDATION_SPLIT,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Create model and trainer\n",
        "    input_size = X_train.shape[1]\n",
        "    model = EnhancedRNNDecoder(input_size)\n",
        "    trainer = DecoderTrainer(model)\n",
        "\n",
        "    # Train the model\n",
        "    train_losses, val_losses = trainer.train(X_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Plot training and validation losses\n",
        "    plot_training_validation_loss(\n",
        "        train_losses,\n",
        "        val_losses,\n",
        "        'Training and Validation Losses'\n",
        "    )\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = trainer.predict(X_test)\n",
        "\n",
        "    # Compute and print performance metrics\n",
        "    metrics = compute_performance_metrics(y_test, y_pred)\n",
        "    print(\"Performance Metrics:\")\n",
        "    print(f\"BER: {metrics['BER']}\")\n",
        "    print(f\"BLER: {metrics['BLER']}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(metrics['Classification Report'])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Run the simulation\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "nCFlZp9Sv0cD",
        "outputId": "f75a6c9a-123c-4a6c-ed11-dcd95c109531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Using Device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ef7c9daea780>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;31m# Run the simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;31m#########################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ef7c9daea780>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;31m# Plot training and validation losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ef7c9daea780>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, batch_size, validation_split)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ef7c9daea780>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         return F.binary_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m    822\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3639\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3640\u001b[0m             \u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3641\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32]))"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}