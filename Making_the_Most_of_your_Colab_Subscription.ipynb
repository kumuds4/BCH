{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P_55iJViIE8",
        "outputId": "9266746d-4d11-4721-a3ff-c175a9b88b06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0GOZnIVMiXuk",
        "outputId": "616c9d85-c943-404b-fd9f-d71652b07599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-821a25df-e3a1-4b8f-8817-35089c79e32a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-821a25df-e3a1-4b8f-8817-35089c79e32a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving making_the_most_of_your_colab_subscription (14).py to making_the_most_of_your_colab_subscription (14).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "!pip install torch numpy matplotlib scikit-learn seaborn scipy\n",
        "# Essential Scientific and Deep Learning Libraries\n",
        "!pip install torch numpy matplotlib scikit-learn seaborn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "##############################################\n",
        "\n",
        "#ADD ON\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        \"\"\"\n",
        "        Polar Code Generator with Rate Calculation\n",
        "\n",
        "        Args:\n",
        "            N (int): Total code length\n",
        "            K (int): Information bit length\n",
        "            crc_type (str): CRC polynomial type\n",
        "        \"\"\"\n",
        "        self.N = N  # Total code length\n",
        "        self.K = K  # Information bit length\n",
        "        self.crc_type = crc_type\n",
        "\n",
        "        # Rate Calculation\n",
        "        self.rate = K / N  # Coding Rate R = K/N\n",
        "\n",
        "        # CRC Polynomials\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {\n",
        "                'polynomial': [1, 1, 1, 0, 0, 1, 1],\n",
        "                'length': 7\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Print Rate Information\n",
        "        print(f\"ðŸ”¢ Polar Code Parameters:\")\n",
        "        print(f\"- Total Length (N): {N}\")\n",
        "        print(f\"- Information Bits (K): {K}\")\n",
        "        print(f\"- Coding Rate (R = K/N): {self.rate:.4f}\")\n",
        "        print(f\"- CRC Type: {crc_type}\")\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        \"\"\"Generate random information bits\"\"\"\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    # ... (rest of the methods remain the same)\n",
        "##################################################\n",
        "\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"Simple polar encoding\"\"\"\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(info_bits)] = info_bits\n",
        "        return codeword\n",
        "\n",
        "class ChannelSimulator:\n",
        "    @staticmethod\n",
        "    def awgn_channel(signal, snr_db):\n",
        "        \"\"\"\n",
        "        Simulate Additive White Gaussian Noise (AWGN) channel\n",
        "\n",
        "        Args:\n",
        "            signal (np.ndarray): Input signal\n",
        "            snr_db (float): Signal-to-Noise Ratio in dB\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Received signal after noise addition\n",
        "        \"\"\"\n",
        "        # Convert bits {0,1} to BPSK: {-1, +1}\n",
        "        bpsk_signal = 1 - 2 * signal\n",
        "\n",
        "        # Convert SNR from dB to linear scale\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "\n",
        "        # Compute signal power\n",
        "        signal_power = np.mean(bpsk_signal**2)\n",
        "\n",
        "        # Noise power calculation\n",
        "        noise_power = signal_power / snr_linear\n",
        "        noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "        received_signal = bpsk_signal + noise\n",
        "\n",
        "        # Convert back to binary\n",
        "        return (received_signal > 0).astype(float)\n",
        "##############################################################\n",
        "#Latest dataset\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type=\"AWGN\", list_size=1):\n",
        "    \"\"\"\n",
        "    Prepare dataset for Polar Code simulation with list decoding\n",
        "\n",
        "    Args:\n",
        "        polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "        num_samples (int): Number of samples to generate\n",
        "        snr_db (float): Signal-to-Noise Ratio in dB\n",
        "        channel_type (str): Channel type\n",
        "        list_size (int): List decoding size\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input features and corresponding labels\n",
        "    \"\"\"\n",
        "    # Create channel simulator\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "\n",
        "    # Initialize storage\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate information bits\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "        # Encode polar code\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "        # List decoding simulation\n",
        "        received_signals = []\n",
        "        for _ in range(list_size):\n",
        "            # Simulate channel\n",
        "            if channel_type == 'AWGN':\n",
        "                received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "            elif channel_type == 'Rayleigh':\n",
        "                received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {channel_type}\")\n",
        "\n",
        "            received_signals.append(received_signal)\n",
        "\n",
        "        # Majority voting for list decoding\n",
        "        final_received_signal = np.mean(received_signals, axis=0) > 0.5\n",
        "\n",
        "        # Store features and labels\n",
        "        X.append(final_received_signal)\n",
        "        y.append(info_bits)  # Use original info_bits as target\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "##############################################################\n",
        "\n",
        "class PolarCodeDecoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PolarCodeDecoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n",
        "\n",
        "class TrainingEngine:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "#############################\n",
        "#new def train\n",
        "def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    Enhanced training method with comprehensive tensor handling\n",
        "    \"\"\"\n",
        "    # Diagnostic print of input tensors\n",
        "    print(\"\\nðŸ” Initial Input Tensor Diagnostics:\")\n",
        "    print(f\"X type: {type(X)}\")\n",
        "    if isinstance(X, torch.Tensor):\n",
        "        print(f\"X shape: {X.shape}\")\n",
        "        print(f\"X dtype: {X.dtype}\")\n",
        "    elif isinstance(X, np.ndarray):\n",
        "        print(f\"X shape: {X.shape}\")\n",
        "        print(f\"X dtype: {X.dtype}\")\n",
        "\n",
        "    print(f\"y type: {type(y)}\")\n",
        "    if isinstance(y, torch.Tensor):\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "        print(f\"y dtype: {y.dtype}\")\n",
        "    elif isinstance(y, np.ndarray):\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "        print(f\"y dtype: {y.dtype}\")\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    try:\n",
        "        # Convert X to float tensor and flatten if needed\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "\n",
        "        # Flatten X if multi-dimensional\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "\n",
        "        # Convert y to float tensor\n",
        "        if not isinstance(y, torch.Tensor):\n",
        "            y = torch.FloatTensor(y)\n",
        "\n",
        "        # Ensure y is 2D tensor with shape [batch_size, 1]\n",
        "        y = y.view(-1, 1).float()\n",
        "\n",
        "    except Exception as conversion_error:\n",
        "        print(f\"âŒ Tensor Conversion Error: {conversion_error}\")\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "    # Move to device\n",
        "    X = X.to(self.device)\n",
        "    y = y.to(self.device)\n",
        "\n",
        "    # Diagnostic print after conversion\n",
        "    print(\"\\nðŸ”¬ Processed Tensor Diagnostics:\")\n",
        "    print(f\"X shape: {X.shape}\")\n",
        "    print(f\"X dtype: {X.dtype}\")\n",
        "    print(f\"y shape: {y.shape}\")\n",
        "    print(f\"y dtype: {y.dtype}\")\n",
        "\n",
        "    # Split into train and validation\n",
        "    train_size = int((1 - validation_split) * len(X))\n",
        "\n",
        "    try:\n",
        "        X_train, X_val = X[:train_size], X[train_size:]\n",
        "        y_train, y_val = y[:train_size], y[train_size:]\n",
        "    except Exception as split_error:\n",
        "        print(f\"âŒ Dataset Splitting Error: {split_error}\")\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "    # Diagnostic print of split tensors\n",
        "    print(\"\\nðŸ”¬ Split Tensor Diagnostics:\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"X_val shape: {X_val.shape}\")\n",
        "    print(f\"y_val shape: {y_val.shape}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    try:\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        val_dataset = TensorDataset(X_val, y_val)\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False\n",
        "        )\n",
        "    except Exception as dataloader_error:\n",
        "        print(f\"âŒ DataLoader Creation Error: {dataloader_error}\")\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        self.model.train()\n",
        "        train_loss = self._train_epoch(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        self.model.eval()\n",
        "        val_loss = self._validate(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        self.scheduler.step(val_loss)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "              f\"Train Loss: {train_loss:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "#############################\n",
        "\n",
        "#New latest main()\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Comprehensive Polar Code Simulation Framework\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Simulation Configuration\n",
        "        BLOCK_LENGTH = 32    # Total code length (N)\n",
        "        INFO_BITS = 16       # Information bit length (K)\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES = 5000\n",
        "\n",
        "        # SNR Ranges\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 10)\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 10)\n",
        "\n",
        "        # List Sizes Configuration\n",
        "        LIST_SIZES_CONFIG = {\n",
        "            'AWGN': [1, 4, 8],\n",
        "            'Rayleigh': [1, 4, 8]\n",
        "        }\n",
        "\n",
        "        # Channel Configurations\n",
        "        CHANNEL_CONFIGURATIONS = {\n",
        "            'AWGN': {\n",
        "                'snr_range': SNR_RANGE_AWGN,\n",
        "                'description': 'Additive White Gaussian Noise Channel',\n",
        "                'list_sizes': LIST_SIZES_CONFIG['AWGN']\n",
        "            },\n",
        "            'Rayleigh': {\n",
        "                'snr_range': SNR_RANGE_RAYLEIGH,\n",
        "                'description': 'Rayleigh Fading Channel',\n",
        "                'list_sizes': LIST_SIZES_CONFIG['Rayleigh']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Comprehensive results storage\n",
        "        comprehensive_results = {}\n",
        "\n",
        "        # Iterate through channel types\n",
        "        for channel_type, config in CHANNEL_CONFIGURATIONS.items():\n",
        "            print(f\"\\nðŸš€ Simulating {config['description']}\")\n",
        "\n",
        "            # Performance tracking for all list sizes\n",
        "            channel_results = {\n",
        "                'list_sizes': config['list_sizes'],\n",
        "                'snr_range': config['snr_range'],\n",
        "                'ber': [],  # Bit Error Rate\n",
        "                'bler': [],  # Block Error Rate\n",
        "                'train_losses': {},\n",
        "                'val_losses': {}\n",
        "            }\n",
        "\n",
        "            # Iterate through list sizes for this channel\n",
        "            for list_size in config['list_sizes']:\n",
        "                print(f\"\\nðŸ” Analyzing List Size: {list_size}\")\n",
        "\n",
        "                # Performance tracking for this list size\n",
        "                list_size_ber = []\n",
        "                list_size_bler = []\n",
        "                list_size_train_losses = {}\n",
        "                list_size_val_losses = {}\n",
        "\n",
        "                # Iterate through SNR range\n",
        "                for snr_db in config['snr_range']:\n",
        "                    print(f\"Simulating at SNR: {snr_db:.2f} dB with List Size {list_size}\")\n",
        "\n",
        "                    # Create Polar Code Generator with CRC-7\n",
        "                    polar_code_gen = PolarCodeGenerator(\n",
        "                        N=BLOCK_LENGTH,\n",
        "                        K=INFO_BITS,\n",
        "                        crc_type='CRC-7'\n",
        "                    )\n",
        "\n",
        "                    # Prepare Dataset with specific list size\n",
        "                    X, y = prepare_polar_dataset(\n",
        "                        polar_code_gen,\n",
        "                        num_samples=NUM_SAMPLES,\n",
        "                        snr_db=snr_db,\n",
        "                        channel_type=channel_type,\n",
        "                        list_size=list_size\n",
        "                    )\n",
        "\n",
        "                    # Flatten input features\n",
        "                    X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "                    # Convert to PyTorch tensors with explicit shape handling\n",
        "                    X_tensor = torch.FloatTensor(X_flattened)\n",
        "\n",
        "                    # Create binary labels based on mean\n",
        "                    y_binary = (torch.FloatTensor(y).float() > np.mean(y)).float()\n",
        "\n",
        "                    # Reshape labels to 2D tensor with shape [batch_size, 1]\n",
        "                    y_binary = y_binary.view(-1, 1)\n",
        "\n",
        "                    # Split Dataset with explicit tensor handling\n",
        "                    train_size = int(0.8 * len(X_tensor))\n",
        "\n",
        "                    X_train = X_tensor[:train_size]\n",
        "                    X_test = X_tensor[train_size:]\n",
        "                    y_train = y_binary[:train_size]\n",
        "                    y_test = y_binary[train_size:]\n",
        "\n",
        "                    # Create Decoder Model\n",
        "                    input_size = X_train.shape[1]\n",
        "                    model = EnhancedRNNDecoder(input_size)\n",
        "                    trainer = DecoderTrainer(model)\n",
        "\n",
        "                    # Train the model\n",
        "                    train_losses, val_losses = trainer.train(\n",
        "                        X_train,\n",
        "                        y_train,\n",
        "                        epochs=EPOCHS,\n",
        "                        batch_size=BATCH_SIZE\n",
        "                    )\n",
        "\n",
        "                    # Plot Training and Validation Losses\n",
        "                    plt.figure(figsize=(10, 5))\n",
        "                    plt.plot(train_losses, label='Training Loss')\n",
        "                    plt.plot(val_losses, label='Validation Loss')\n",
        "                    plt.title(f'Training and Validation Losses\\n{channel_type} Channel, List Size {list_size}, SNR {snr_db:.2f} dB')\n",
        "                    plt.xlabel('Epoch')\n",
        "                    plt.ylabel('Loss')\n",
        "                    plt.legend()\n",
        "                    plt.show()\n",
        "\n",
        "                    # Predict on test set\n",
        "                    y_pred = trainer.predict(X_test)\n",
        "\n",
        "                    # Compute Confusion Matrix\n",
        "                    y_true_binary = y_test.numpy().flatten()\n",
        "                    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "                    cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
        "                    plt.figure(figsize=(8, 6))\n",
        "                    sns.heatmap(\n",
        "                        cm,\n",
        "                        annot=True,\n",
        "                        fmt='d',\n",
        "                        cmap='Blues',\n",
        "                        xticklabels=['Negative', 'Positive'],\n",
        "                        yticklabels=['Negative', 'Positive']\n",
        "                    )\n",
        "                    plt.title(f'Confusion Matrix\\n{channel_type} Channel, List Size {list_size}, SNR {snr_db:.2f} dB')\n",
        "                    plt.show()\n",
        "\n",
        "                    # Compute Performance Metrics\n",
        "                    ber = np.mean(y_true_binary != y_pred_binary)\n",
        "                    bler = 1 - np.mean(y_true_binary == y_pred_binary)\n",
        "\n",
        "                    # Store losses and performance metrics\n",
        "                    list_size_train_losses[snr_db] = train_losses\n",
        "                    list_size_val_losses[snr_db] = val_losses\n",
        "                    list_size_ber.append(ber)\n",
        "                    list_size_bler.append(bler)\n",
        "\n",
        "                    print(f\"List Size {list_size}, SNR {snr_db:.2f} dB:\")\n",
        "                    print(f\"- Bit Error Rate (BER): {ber:.6f}\")\n",
        "                    print(f\"- Block Error Rate (BLER): {bler:.6f}\")\n",
        "\n",
        "                # Store results for this list size\n",
        "                channel_results['ber'].append(list_size_ber)\n",
        "                channel_results['bler'].append(list_size_bler)\n",
        "                channel_results['train_losses'][list_size] = list_size_train_losses\n",
        "                channel_results['val_losses'][list_size] = list_size_val_losses\n",
        "\n",
        "            # Store channel results\n",
        "            comprehensive_results[channel_type] = channel_results\n",
        "\n",
        "            # Visualize Performance\n",
        "            plt.figure(figsize=(15, 6))\n",
        "\n",
        "            # BER Plot\n",
        "            plt.subplot(1, 2, 1)\n",
        "            for i, list_size in enumerate(config['list_sizes']):\n",
        "                plt.semilogy(\n",
        "                    config['snr_range'],\n",
        "                    channel_results['ber'][i],\n",
        "                    label=f'List Size {list_size}',\n",
        "                    marker='o'\n",
        "                )\n",
        "            plt.title(f'Bit Error Rate\\n{config[\"description\"]}')\n",
        "            plt.xlabel('SNR (dB)')\n",
        "            plt.ylabel('BER (Log Scale)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            # BLER Plot\n",
        "            plt.subplot(1, 2, 2)\n",
        "            for i, list_size in enumerate(config['list_sizes']):\n",
        "                plt.semilogy(\n",
        "                    config['snr_range'],\n",
        "                    channel_results['bler'][i],\n",
        "                    label=f'List Size {list_size}',\n",
        "                    marker='o'\n",
        "                )\n",
        "            plt.title(f'Block Error Rate\\n{config[\"description\"]}')\n",
        "            plt.xlabel('SNR (dB)')\n",
        "            plt.ylabel('BLER (Log Scale)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        return comprehensive_results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Execution\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERIsHQfBkjdV",
        "outputId": "a3545568-7129-4d6c-d087-fa78e66db284"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "ðŸš€ Using Device: cuda\n",
            "\n",
            "ðŸš€ Simulating Additive White Gaussian Noise Channel\n",
            "\n",
            "ðŸ” Analyzing List Size: 1\n",
            "Simulating at SNR: 0.00 dB with List Size 1\n",
            "ðŸ”¢ Polar Code Parameters:\n",
            "- Total Length (N): 32\n",
            "- Information Bits (K): 16\n",
            "- Coding Rate (R = K/N): 0.5000\n",
            "- CRC Type: CRC-7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:ðŸ†˜ Comprehensive Simulation Error: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])) is deprecated. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Tensor Preprocessing:\n",
            "X shape: torch.Size([4000, 32])\n",
            "y shape: torch.Size([4000, 1])\n",
            "X dtype: torch.float32\n",
            "y dtype: torch.float32\n",
            "\n",
            "ðŸ” Training Data Shapes:\n",
            "X_train shape: torch.Size([3200, 32])\n",
            "y_train shape: torch.Size([3200, 1])\n",
            "X_val shape: torch.Size([800, 32])\n",
            "y_val shape: torch.Size([800, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-36-484d61941614>\", line 410, in main\n",
            "    train_losses, val_losses = trainer.train(\n",
            "                               ^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-35-ba63afd5f7e1>\", line 1279, in train\n",
            "    train_loss = self._train_epoch(train_loader)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-35-ba63afd5f7e1>\", line 1314, in _train_epoch\n",
            "    loss = self.criterion(outputs, batch_y)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\", line 699, in forward\n",
            "    return F.binary_cross_entropy(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 3560, in binary_cross_entropy\n",
            "    raise ValueError(\n",
            "ValueError: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])) is deprecated. Please ensure they have the same size.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}