{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XutTqfoHkkjK",
        "outputId": "0562c6b0-f0f2-41a5-dfec-c9bb6681f4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "f5s1Po-IkxpS",
        "outputId": "213efcd7-dabc-42c4-deb6-ed91072a6b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5fcb9c7-fd97-4f76-8fc1-92286c5d8bc5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5fcb9c7-fd97-4f76-8fc1-92286c5d8bc5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving polarML0609ltst.py to polarML0609ltst.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Polar transform\n",
        "#Latest done early morning 06/09/25\n",
        "#no doing during evening 06/08/25\n",
        "#plots need be fixed. They are flat.\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import logging\n",
        "import pandas as pd\n",
        "import traceback # Import the traceback module\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configuration parameters\n",
        "BLOCK_LENGTH = 128\n",
        "INFO_BITS = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "NUM_SAMPLES_TRAIN = 50000\n",
        "NUM_TRIALS_PERF = 1500\n",
        "SNR_RANGE_AWGN = np.linspace(0, 5, 11)\n",
        "LIST_SIZES = [1, 8, 16]\n",
        "\n",
        "#Part 2: Polar Code Generator and Modulation\n",
        "####################################################\n",
        "#Latest Polar Code Generator\n",
        "\n",
        "#latest evening 06/09/25\n",
        "#Latest done early morning 06/09/25\n",
        "#no doing during evening 06/08/25\n",
        "#plots need be fixed. They are flat.\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import logging\n",
        "import pandas as pd\n",
        "import traceback # Import the traceback module\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configuration parameters\n",
        "BLOCK_LENGTH = 128\n",
        "INFO_BITS = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "NUM_SAMPLES_TRAIN = 50000\n",
        "NUM_TRIALS_PERF = 1500\n",
        "SNR_RANGE_AWGN = np.linspace(0, 5, 11)\n",
        "LIST_SIZES = [1, 8, 16]\n",
        "\n",
        "#Part 2: Polar Code Generator and Modulation\n",
        "####################################################\n",
        "#Latest Polar Code Generator\n",
        "\n",
        "#latest evening 06/08/25\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K / N\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {'CRC-7': (np.array([1, 0, 0, 1, 1, 0, 0, 1]), 7)}\n",
        "\n",
        "        if crc_type in self.crc_polynomials:\n",
        "            self._crc_length = self.crc_polynomials[crc_type][1]\n",
        "        else:\n",
        "            self._crc_length = 0\n",
        "\n",
        "        self.K_crc = self.K + self._crc_length\n",
        "\n",
        "        # Determine frozen/info sets using the pre-computed 3GPP reliability sequence\n",
        "        self.frozen_set, self.info_set = self._get_frozen_and_info_sets_from_3gpp_sequence()\n",
        "\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits, verbose=False):\n",
        "        # Append CRC if needed\n",
        "        info_bits_with_crc = self.append_crc(info_bits)\n",
        "\n",
        "        # Check size\n",
        "        if len(info_bits_with_crc) != len(self.info_set):\n",
        "            raise ValueError(\"Length of info_bits_with_crc must match length of info_set\")\n",
        "\n",
        "        # Debug print\n",
        "        if verbose:\n",
        "            print(f\"Debug: Length of info_bits_with_crc = {len(info_bits_with_crc)}, Length of info_set = {len(self.info_set)}\")\n",
        "\n",
        "        # Create u vector\n",
        "        u = np.zeros(self.N, dtype=int)\n",
        "        u[list(self.info_set)] = info_bits_with_crc # Ensure info_set is a list or use list(self.info_set)\n",
        "\n",
        "        # Polar transform\n",
        "        encoded = self._polar_transform(u)\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    def _polar_transform(self, u):\n",
        "        N = len(u)\n",
        "        if N == 1:\n",
        "            return u\n",
        "        else:\n",
        "            half_N = N // 2\n",
        "            x_upper = self._polar_transform(u[:half_N])\n",
        "            x_lower = self._polar_transform(u[half_N:])\n",
        "            codeword = np.concatenate([(x_upper + x_lower) % 2, x_lower])\n",
        "            return codeword\n",
        "\n",
        "    def append_crc(self, info_bits):\n",
        "        if self.crc_type not in self.crc_polynomials:\n",
        "            return info_bits\n",
        "        polynomial, length = self.crc_polynomials[self.crc_type]\n",
        "        data_for_crc = np.copy(info_bits)\n",
        "        crc_bits = self._compute_crc(data_for_crc, polynomial, length)\n",
        "        return np.concatenate((info_bits, crc_bits))\n",
        "\n",
        "    def _compute_crc(self, data, polynomial, length):\n",
        "        data = np.concatenate((data, np.zeros(length, dtype=int)))\n",
        "        for i in range(len(data) - length):\n",
        "            if data[i] == 1:\n",
        "                data[i:i+length+1] ^= polynomial\n",
        "        return data[-length:]\n",
        "\n",
        "    def _get_3gpp_reliability_sequence_128(self):\n",
        "        # The pre-computed reliability sequence for N=128, AWGN (from 3GPP TS 38.212).\n",
        "        # This sequence lists bit indices in increasing order of reliability\n",
        "        # (least reliable first).\n",
        "        return [\n",
        "            0, 1, 2, 4, 8, 16, 3, 5, 9, 6, 17, 10, 18, 32, 12, 33,\n",
        "            20, 24, 34, 36, 40, 7, 11, 19, 21, 13, 22, 25, 26, 28,\n",
        "            48, 35, 37, 38, 41, 42, 44, 56, 14, 15, 23, 27, 29, 30,\n",
        "            31, 39, 43, 45, 46, 49, 50, 52, 57, 58, 60, 63, 47, 51,\n",
        "            53, 54, 59, 61, 62, 65, 66, 67, 68, 70, 72, 73, 74, 75,\n",
        "            76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 77,\n",
        "            79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 102, 103,\n",
        "            104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
        "            116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127\n",
        "        ]\n",
        "\n",
        "    def _get_frozen_and_info_sets_from_3gpp_sequence(self):\n",
        "        reliability_sequence = self._get_3gpp_reliability_sequence_128()\n",
        "        print(f\"Debug: Reliability sequence length: {len(reliability_sequence)}\") # Debug print\n",
        "\n",
        "        if self.N != 128:\n",
        "             raise ValueError(f\"Code length N={self.N} is not supported by the hardcoded 3GPP sequence.\")\n",
        "\n",
        "        # Add debug prints for N, K, _crc_length, and K_crc\n",
        "        print(f\"Debug: self.N = {self.N}, self.K = {self.K}, self._crc_length = {self._crc_length}, self.K_crc = {self.K_crc}\")\n",
        "\n",
        "        # The most reliable channels are used for information bits (including CRC)\n",
        "        # The sequence is ordered from least reliable to most reliable,\n",
        "        # so we take the last K_crc elements for the info set.\n",
        "        # Ensure info_channel_indices has exactly self.K_crc elements\n",
        "        if len(reliability_sequence) >= self.K_crc:\n",
        "            info_channel_indices = sorted(reliability_sequence[-self.K_crc:])\n",
        "        else:\n",
        "             # Handle the case where the reliability sequence is unexpectedly short\n",
        "             logging.error(f\"Reliability sequence (length {len(reliability_sequence)}) is shorter than K_crc ({self.K_crc}). Cannot determine info set correctly.\")\n",
        "             # Fallback: Take the last available indices (will likely lead to poor performance or further errors)\n",
        "             info_channel_indices = sorted(reliability_sequence[-len(reliability_sequence):])\n",
        "\n",
        "\n",
        "        print(f\"Debug: Info channel indices length (after slicing and sorting): {len(info_channel_indices)}\") # Debug print\n",
        "        # print(f\"Debug: Info channel indices: {info_channel_indices}\") # Optional: Print the indices themselves\n",
        "\n",
        "        # The remaining channels are frozen\n",
        "        frozen_channel_indices = sorted(list(set(range(self.N)) - set(info_channel_indices)))\n",
        "        print(f\"Debug: Frozen channel indices length (after set difference and sorting): {len(frozen_channel_indices)}\") # Debug print\n",
        "        # print(f\"Debug: Frozen channel indices: {frozen_channel_indices}\") # Optional: Print the indices themselves\n",
        "\n",
        "\n",
        "        # Double-check sizes - these should now pass if the sequence was long enough\n",
        "        if len(info_channel_indices) != self.K_crc:\n",
        "            print(f\"Mismatch: Expected {self.K_crc} info indices, but got {len(info_channel_indices)}\") # Debug print\n",
        "            # Consider raising an error here if this mismatch happens\n",
        "            # raise ValueError(f\"Mismatch: Expected {self.K_crc} info indices, but got {len(frozen_channel_indices)}\") # Correct variable name here\n",
        "\n",
        "        if len(frozen_channel_indices) != self.N - self.K_crc:\n",
        "             print(f\"Mismatch: Expected {self.N - self.K_crc} frozen indices, but got {len(frozen_channel_indices)}\") # Debug print\n",
        "             # Consider raising an error here\n",
        "             # raise ValueError(f\"Mismatch: Expected {self.N - self.K_crc} frozen indices, but got {len(frozen_channel_indices)}\") # Correct variable name here\n",
        "\n",
        "\n",
        "        return frozen_channel_indices, info_channel_indices # Return info_channel_indices as a list\n",
        "\n",
        "\n",
        "################################################################\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "\n",
        "#############################################\n",
        "\n",
        "# Keep the rest of your code (BPSK modulation, Channel Simulation, RNN Decoder, Trainer, SCL Decoder, Plotting, Performance Comparison, and main function) as is for now\n",
        "####################################################\n",
        "\n",
        "\n",
        "#Part 3: Dataset Preparation and Channel Simulation\n",
        "############################################################\n",
        "#latest add bpsk_modulate\n",
        "def bpsk_modulate(codeword):\n",
        "  \"\"\"\n",
        "  Performs BPSK modulation on a binary codeword.\n",
        "\n",
        "  Args:\n",
        "    codeword: A numpy array of binary bits (0s and 1s).\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of BPSK symbols (+1s and -1s).\n",
        "  \"\"\"\n",
        "  return 1 - 2 * codeword\n",
        "\n",
        "###########################################################\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def simulate(self, signal, snr_db):\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "        noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "        noise = noise_std * np.random.randn(*signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        modulated_signal = bpsk_modulate(encoded_signal)\n",
        "        received_signal = channel_simulator.simulate(modulated_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def save_dataset_to_csv(X, y, filename='dataset.csv'):\n",
        "    data = np.hstack((X, y))\n",
        "    columns = [f'received_{i}' for i in range(X.shape[1])] + [f'bit_{j}' for j in range(y.shape[1])]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.to_csv(filename, index=False)\n",
        "    logging.info(f\"Dataset saved to {filename}\")\n",
        "\n",
        "#Part 4\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size=128, num_layers=2):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers  # Ensure this is defined\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_reshaped = x.unsqueeze(1)  # Assuming sequence_length = 1\n",
        "\n",
        "        # Ensure h0 and c0 are created with the correct device and shape\n",
        "        # Use self.num_layers for multiple RNN layers\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.rnn(x_reshaped, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate):\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=32):\n",
        "        dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            self.model.train()\n",
        "\n",
        "            for X_batch, y_batch in loader:\n",
        "                X_batch = X_batch.view(-1, BLOCK_LENGTH)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(X_batch)\n",
        "                loss = self.criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            train_loss = epoch_loss / len(loader)\n",
        "            train_losses.append(train_loss)\n",
        "            logging.info(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_output = self.model(X_val.view(-1, BLOCK_LENGTH))\n",
        "                    val_loss = self.criterion(val_output, y_val).item()\n",
        "                    val_losses.append(val_loss)\n",
        "                    logging.info(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return train_losses, val_losses if X_val is not None else None\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X_test.view(-1, BLOCK_LENGTH))\n",
        "            predicted = (outputs > 0.5).int()\n",
        "            correct = (predicted == y_test).sum().item()\n",
        "            total = y_test.numel()\n",
        "            accuracy = correct / total\n",
        "            # Calculate BER and BLER\n",
        "            bit_errors = torch.sum(predicted != y_test).item()\n",
        "            block_errors = torch.sum(torch.any(predicted != y_test, dim=1)).item()\n",
        "            ber = bit_errors / total\n",
        "            bler = block_errors / X_test.size(0)\n",
        "\n",
        "        return ber, bler\n",
        "\n",
        "\n",
        "#Part 5 and 6: SCL Decoder\n",
        "#########################################################\n",
        "#latest Polarcode decoder\n",
        "#It's on 06/08/25 evening/night\n",
        "class PolarCodeDecoder:\n",
        "    def __init__(self, N, K, list_size, crc_poly=None):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.list_size = list_size\n",
        "        self._crc_polynomial = None\n",
        "        self._crc_length = 0\n",
        "\n",
        "        if crc_poly is not None and isinstance(crc_poly, tuple) and len(crc_poly) == 2:\n",
        "             self._crc_polynomial = crc_poly[0]\n",
        "             self._crc_length = crc_poly[1]\n",
        "             self.K_crc = self.K + self._crc_length\n",
        "        else:\n",
        "             self.K_crc = self.K\n",
        "\n",
        "        self.frozen_set = self._get_frozen_set()\n",
        "        self.info_set = sorted(list(set(range(N)) - set(self.frozen_set)))\n",
        "\n",
        "\n",
        "    def _get_frozen_set(self):\n",
        "       gen = PolarCodeGenerator(self.N, self.K, crc_type='CRC-7' if self._crc_polynomial is not None else None)\n",
        "    # Ensure this line calls the correct method from the generator\n",
        "       frozen_set, _ = gen._get_frozen_and_info_sets_from_3gpp_sequence()\n",
        "       return set(frozen_set)\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, received_llrs):\n",
        "        active_path_indices = list(range(self.list_size))\n",
        "        self.paths = [[] for _ in range(self.list_size)]\n",
        "        # Using log-likelihood of the path as path metric (lower is better)\n",
        "        self.path_metrics = [0.0] * self.list_size\n",
        "        self.hard_decisions = [np.zeros(self.N, dtype=int) for _ in range(self.list_size)]\n",
        "        self.llrs = [np.copy(received_llrs) for _ in range(self.list_size)]\n",
        "\n",
        "        # Initialize path metrics (sum of LLR magnitudes is a common initialization)\n",
        "        for path_idx in active_path_indices:\n",
        "             self.path_metrics[path_idx] = np.sum(np.abs(self.llrs[path_idx]))\n",
        "\n",
        "\n",
        "        final_active_path_indices = self._recursive_decode(active_path_indices, 0, self.N)\n",
        "\n",
        "        # Select the best path based on path metric (lower is better)\n",
        "        # If CRC is used, validate CRC for each path in final_active_path_indices\n",
        "        # and choose the one with valid CRC and best metric.\n",
        "        if self._crc_polynomial is not None:\n",
        "             valid_paths = []\n",
        "             for path_idx in final_active_path_indices:\n",
        "                 decoded_info_bits_with_crc = self.hard_decisions[path_idx][list(self.info_set)]\n",
        "                 if self._check_crc(decoded_info_bits_with_crc):\n",
        "                     valid_paths.append(path_idx)\n",
        "\n",
        "             if not valid_paths:\n",
        "                 # If no valid path, choose the one with the best metric (could indicate a decoding failure)\n",
        "                 logging.warning(\"No valid CRC path found. Choosing the path with the best metric.\")\n",
        "                 best_path_index_in_final = np.argmin([self.path_metrics[i] for i in final_active_path_indices])\n",
        "                 best_path_index = final_active_path_indices[best_path_index_in_final]\n",
        "             else:\n",
        "                 best_path_index_in_valid = np.argmin([self.path_metrics[i] for i in valid_paths])\n",
        "                 best_path_index = valid_paths[best_path_index_in_valid]\n",
        "\n",
        "        else:\n",
        "            best_path_index_in_final = np.argmin([self.path_metrics[i] for i in final_active_path_indices])\n",
        "            best_path_index = final_active_path_indices[best_path_index_in_final]\n",
        "\n",
        "\n",
        "        return self.hard_decisions[best_path_index][list(self.info_set)[:self.K]] # Return only the information bits\n",
        "\n",
        "\n",
        "    def _recursive_decode(self, active_path_indices, bit_index, block_size):\n",
        "        if block_size == 1:\n",
        "            # Decision step at the leaf nodes\n",
        "            next_active_path_indices = []\n",
        "            for path_idx in active_path_indices:\n",
        "                llr = self.llrs[path_idx][bit_index]\n",
        "                # Make a hard decision\n",
        "                if llr >= 0:\n",
        "                    self.hard_decisions[path_idx][bit_index] = 0\n",
        "                else:\n",
        "                    self.hard_decisions[path_idx][bit_index] = 1\n",
        "\n",
        "                # Update path metric (negative log-likelihood of the decision)\n",
        "                # More accurate path metric update for LLRs:\n",
        "                self.path_metrics[path_idx] += np.log(1 + np.exp(-np.abs(llr))) # Assuming log-likelihood as metric\n",
        "\n",
        "                # For SCL, we potentially branch here if the list size allows\n",
        "                if len(active_path_indices) < self.list_size:\n",
        "                     # If not at list size limit, create a new path for the alternative decision\n",
        "                     new_path_idx = len(self.paths)\n",
        "                     self.paths.append([]) # Add a new path\n",
        "                     self.path_metrics.append(0.0)\n",
        "                     self.hard_decisions.append(np.copy(self.hard_decisions[path_idx]))\n",
        "                     self.llrs.append(np.copy(self.llrs[path_idx]))\n",
        "\n",
        "                     # Make the alternative decision for the new path\n",
        "                     self.hard_decisions[new_path_idx][bit_index] = 1 - self.hard_decisions[path_idx][bit_index]\n",
        "                     # Update path metric for the new path\n",
        "                     self.path_metrics[new_path_idx] = self.path_metrics[path_idx] - np.log(1 + np.exp(-np.abs(llr))) + np.log(1 + np.exp(-np.abs(llr))) # Re-calculate metric for new decision\n",
        "\n",
        "                     active_path_indices.append(new_path_idx)\n",
        "                     next_active_path_indices.extend([path_idx, new_path_idx])\n",
        "                else:\n",
        "                    next_active_path_indices.append(path_idx)\n",
        "\n",
        "            # Prune paths to the list size\n",
        "            if len(next_active_path_indices) > self.list_size:\n",
        "                sorted_indices = sorted(next_active_path_indices, key=lambda i: self.path_metrics[i])\n",
        "                return sorted_indices[:self.list_size]\n",
        "            else:\n",
        "                return next_active_path_indices\n",
        "\n",
        "\n",
        "        else:\n",
        "            half_size = block_size // 2\n",
        "            # Split step - compute LLRs for the first half (u_1)\n",
        "            for path_idx in active_path_indices:\n",
        "                llr_f = self._f(self.llrs[path_idx][bit_index:bit_index + half_size], self.llrs[path_idx][bit_index + half_size:bit_index + block_size])\n",
        "                self.llrs[path_idx][bit_index:bit_index + half_size] = llr_f\n",
        "\n",
        "            # Recursively decode the first half\n",
        "            active_paths_after_u1 = self._recursive_decode(active_path_indices, bit_index, half_size)\n",
        "\n",
        "            # Split step - compute LLRs for the second half (u_2)\n",
        "            for path_idx in active_paths_after_u1:\n",
        "                u1_decisions = self.hard_decisions[path_idx][bit_index:bit_index + half_size]\n",
        "                llr_g = self._g(self.llrs[path_idx][bit_index:bit_index + half_size], self.llrs[path_idx][bit_index + half_size:bit_index + block_size], u1_decisions)\n",
        "                self.llrs[path_idx][bit_index + half_size:bit_index + block_size] = llr_g\n",
        "\n",
        "            # Recursively decode the second half\n",
        "            active_paths_after_u2 = self._recursive_decode(active_paths_after_u1, bit_index + half_size, half_size)\n",
        "\n",
        "            # Prune paths after finishing a sub-block\n",
        "            if len(active_paths_after_u2) > self.list_size:\n",
        "                sorted_indices = sorted(active_paths_after_u2, key=lambda i: self.path_metrics[i])\n",
        "                return sorted_indices[:self.list_size]\n",
        "            else:\n",
        "                return active_paths_after_u2\n",
        "\n",
        "\n",
        "    def _f(self, L1, L2):\n",
        "        # More accurate LLR combining for F operation\n",
        "        return np.sign(L1) * np.sign(L2) * np.minimum(np.abs(L1), np.abs(L2)) + np.log(1 + np.exp(-np.abs(L1 + L2))) - np.log(1 + np.exp(-np.abs(L1 - L2)))\n",
        "\n",
        "    def _g(self, L1, L2, u1):\n",
        "        # LLR combining for G operation\n",
        "        return L2 + (1 - 2 * u1) * L1\n",
        "\n",
        "    def _check_crc(self, bits):\n",
        "         if self._crc_polynomial is None:\n",
        "             return True # No CRC to check\n",
        "\n",
        "         # Extract data and CRC bits\n",
        "         data_bits = bits[:self.K]\n",
        "         received_crc = bits[self.K:]\n",
        "\n",
        "         # Compute CRC for the data bits\n",
        "         computed_crc = self._compute_crc_for_info_bits(data_bits)\n",
        "\n",
        "         # Check if the received CRC matches the computed CRC\n",
        "         return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "    def _compute_crc_for_info_bits(self, info_bits):\n",
        "        if self._crc_polynomial is None:\n",
        "            return np.array([])\n",
        "\n",
        "        polynomial = self._crc_polynomial\n",
        "        length = self._crc_length\n",
        "        data = np.concatenate((info_bits, np.zeros(length, dtype=int)))\n",
        "\n",
        "        # Perform polynomial division\n",
        "        remainder = np.copy(data) # Use the data with appended zeros directly\n",
        "        poly_len = len(polynomial)\n",
        "        data_len = len(remainder)\n",
        "\n",
        "        if data_len < poly_len: # Handle cases where data is shorter than polynomial\n",
        "           return remainder[-length:] # CRC is just the padded zeros\n",
        "\n",
        "        for i in range(data_len - poly_len, -1, -1):\n",
        "           if remainder[i] == 1: # Iterate from MSB of the current window\n",
        "            remainder[i:i + poly_len] ^= polynomial\n",
        "\n",
        "        # The CRC is the last 'length' bits of the remainder\n",
        "        return remainder[-length:]\n",
        "######################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########################################################\n",
        "\n",
        "#part 5 already sent.\n",
        "\n",
        "\n",
        "\n",
        "#Part 6: Plotting Functions\n",
        "\n",
        "def plot_training_validation(train_losses, val_losses):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    if val_losses:\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_ber_bler_comparison(snr_range, rnn_results, scl_results_all, list_sizes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # BER Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BER_RNN'], label='RNN')\n",
        "    for size, scl_results in scl_results_all.items():\n",
        "        plt.plot(snr_range, [result['BER'] for result in scl_results], label=f'SCL, List Size {size}')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('Bit Error Rate (BER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # BLER Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BLER_RNN'], label='RNN')\n",
        "    for size, scl_results in scl_results_all.items():\n",
        "        plt.plot(snr_range, [result['BLER'] for result in scl_results], label=f'SCL, List Size {size}')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title('Block Error Rate (BLER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def plot_ber_bler_scl(snr_range, scl_results_all, list_sizes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # BER Plot for SCL\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)  # Set y-limits\n",
        "    for size in list_sizes:\n",
        "        if size not in scl_results_all or not scl_results_all[size]:\n",
        "            continue\n",
        "        plt.plot(snr_range, [result['BER'] for result in scl_results_all[size]], label=f'SCL, List Size {size}', marker='x', linestyle='--')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('SCL Bit Error Rate (BER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # BLER Plot for SCL\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)  # Set y-limits\n",
        "    for size in list_sizes:\n",
        "        if size not in scl_results_all or not scl_results_all[size]:\n",
        "            continue\n",
        "        plt.plot(snr_range, [result['BLER'] for result in scl_results_all[size]], label=f'SCL, List Size {size}', marker='x', linestyle='--')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title('SCL Block Error Rate (BLER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    #for RNN decoder plots\n",
        "def plot_ber_bler_rnn(snr_range, rnn_results):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # BER Plot for RNN\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)  # Set y-limits\n",
        "    plt.plot(snr_range, rnn_results['BER_RNN'], label='RNN', marker='o', linestyle='-')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('RNN Bit Error Rate (BER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # BLER Plot for RNN\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)  # Set y-limits\n",
        "    plt.plot(snr_range, rnn_results['BLER_RNN'], label='RNN', marker='o', linestyle='-')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title('RNN Block Error Rate (BLER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Part 6 continued: Performance Evaluation Function\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range_db, channel_type, list_sizes, num_trials):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    rnn_perf_results = {'BER_RNN': [], 'BLER_RNN': []}\n",
        "    scl_perf_results = {size: [] for size in list_sizes}\n",
        "\n",
        "    rnn_model = rnn_trainer.model.to(device) # Ensure model is on the correct device\n",
        "\n",
        "    for snr_db in snr_range_db:\n",
        "        logging.info(f\"Simulating at SNR: {snr_db} dB\")\n",
        "\n",
        "        total_bits_rnn = 0\n",
        "        bit_errors_rnn = 0\n",
        "        total_blocks_rnn = 0\n",
        "        block_errors_rnn = 0\n",
        "\n",
        "        total_bits_scl = {size: 0 for size in list_sizes}\n",
        "        bit_errors_scl = {size: 0 for size in list_sizes}\n",
        "        total_blocks_scl = {size: 0 for size in list_sizes}\n",
        "        block_errors_scl = {size: 0 for size in list_sizes}\n",
        "\n",
        "        for trial in range(num_trials):\n",
        "            info_bits = polar_code_gen.generate_info_bits()\n",
        "            encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "            modulated_signal = bpsk_modulate(encoded_signal)\n",
        "            received_signal = channel_simulator.simulate(modulated_signal, snr_db)\n",
        "\n",
        "            # RNN Decoding\n",
        "            with torch.no_grad():\n",
        "                received_tensor = torch.FloatTensor(received_signal).view(1, -1).to(device)\n",
        "                rnn_output_prob = rnn_model(received_tensor).cpu().detach().numpy().squeeze()\n",
        "                rnn_decoded_bits = (rnn_output_prob > 0.5).astype(int)\n",
        "\n",
        "            total_bits_rnn += INFO_BITS\n",
        "            bit_errors_rnn += np.sum(rnn_decoded_bits != info_bits)\n",
        "            total_blocks_rnn += 1\n",
        "            if not np.array_equal(rnn_decoded_bits, info_bits):\n",
        "                block_errors_rnn += 1\n",
        "\n",
        "            # SCL Decoding\n",
        "            # Convert received signal to LLRs for SCL decoder (assuming BPSK and AWGN)\n",
        "            # LLR = 2 * y / sigma^2\n",
        "            snr_linear = 10**(snr_db/10)\n",
        "            noise_variance = 1 / (2 * snr_linear) # Assuming unit signal power after BPSK\n",
        "            received_llrs = (2 * received_signal) / noise_variance\n",
        "\n",
        "            for list_size in list_sizes:\n",
        "                scl_decoder = PolarCodeDecoder(\n",
        "                    N=polar_code_gen.N,\n",
        "                    K=polar_code_gen.K,\n",
        "                    list_size=list_size,\n",
        "                    crc_poly=polar_code_gen.crc_polynomials.get(polar_code_gen.crc_type) # Pass CRC info\n",
        "                )\n",
        "                scl_decoded_bits = scl_decoder.decode(received_llrs)\n",
        "\n",
        "                total_bits_scl[list_size] += INFO_BITS\n",
        "                bit_errors_scl[list_size] += np.sum(scl_decoded_bits != info_bits)\n",
        "                total_blocks_scl[list_size] += 1\n",
        "                if not np.array_equal(scl_decoded_bits, info_bits):\n",
        "                    block_errors_scl[list_size] += 1\n",
        "\n",
        "        # Calculate BER and BLER for RNN\n",
        "        rnn_ber = bit_errors_rnn / total_bits_rnn if total_bits_rnn > 0 else 0\n",
        "        rnn_bler = block_errors_rnn / total_blocks_rnn if total_blocks_rnn > 0 else 0\n",
        "        rnn_perf_results['BER_RNN'].append(rnn_ber)\n",
        "        rnn_perf_results['BLER_RNN'].append(rnn_bler)\n",
        "        logging.info(f\"SNR: {snr_db} dB, RNN BER: {rnn_ber:.4e}, BLER: {rnn_bler:.4e}\")\n",
        "\n",
        "\n",
        "        # Calculate BER and BLER for SCL\n",
        "        for list_size in list_sizes:\n",
        "            scl_ber = bit_errors_scl[list_size] / total_bits_scl[list_size] if total_bits_scl[list_size] > 0 else 0\n",
        "            scl_bler = block_errors_scl[list_size] / total_blocks_scl[list_size] if total_blocks_scl[list_size] > 0 else 0\n",
        "            scl_perf_results[list_size].append({'BER': scl_ber, 'BLER': scl_bler})\n",
        "            logging.info(f\"SNR: {snr_db} dB, SCL List Size {list_size} BER: {scl_ber:.4e}, BLER: {scl_bler:.4e}\")\n",
        "\n",
        "\n",
        "    return rnn_perf_results, scl_perf_results\n",
        "\n",
        "\n",
        "#Part 7\n",
        "#main() function\n",
        "def main():\n",
        "    try:\n",
        "        # Set up the device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Configuration parameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 50000\n",
        "        NUM_TRIALS_PERF = 1500\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11)\n",
        "        LIST_SIZES = [1, 8, 16]\n",
        "\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "        # Polar code generator initialization\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        rnn_model = EnhancedRNNDecoder(BLOCK_LENGTH, INFO_BITS).to(device)\n",
        "        rnn_trainer = DecoderTrainer(rnn_model, LEARNING_RATE)\n",
        "\n",
        "        logging.info(f\"Code Rate: {polar_code_gen.R}\")\n",
        "\n",
        "        # Generate and save dataset\n",
        "        X_raw, y_raw = prepare_polar_dataset(\n",
        "            polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type='AWGN'\n",
        "        )\n",
        "        save_dataset_to_csv(X_raw, y_raw, 'awgn_dataset.csv')\n",
        "\n",
        "        # Reshape and split data, moving to the device\n",
        "        X_tensor = torch.FloatTensor(X_raw).view(-1, BLOCK_LENGTH).to(device)\n",
        "        y_tensor = torch.FloatTensor(y_raw).view(-1, INFO_BITS).to(device)\n",
        "\n",
        "        # Split data\n",
        "        train_size = int(0.8 * X_tensor.shape[0])\n",
        "        train_X = X_tensor[:train_size]\n",
        "        train_y = y_tensor[:train_size]\n",
        "        val_X = X_tensor[train_size:]\n",
        "        val_y = y_tensor[train_size:]\n",
        "\n",
        "        # RNN Model Training\n",
        "        train_losses, val_losses = rnn_trainer.train(\n",
        "            train_X, train_y, X_val=val_X, y_val=val_y, epochs=EPOCHS, batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Performance comparison\n",
        "        rnn_perf_results, scl_perf_results = performance_comparison(\n",
        "            rnn_trainer, polar_code_gen, SNR_RANGE_AWGN, 'AWGN', LIST_SIZES, NUM_TRIALS_PERF\n",
        "        )\n",
        "\n",
        "        # Plot results\n",
        "        plot_training_validation(train_losses, val_losses)\n",
        "        plot_ber_bler_rnn(SNR_RANGE_AWGN, rnn_perf_results)\n",
        "       # plot_ber_bler_comparison(SNR_RANGE_AWGN, rnn_perf_results, scl_perf_results, LIST_SIZES)\n",
        "        plot_ber_bler_comparison(SNR_RANGE_AWGN, rnn_perf_results, scl_perf_results, LIST_SIZES)\n",
        "        plot_ber_bler_scl(SNR_RANGE_AWGN, scl_perf_results, LIST_SIZES)\n",
        "        # Example Confusion Matrix\n",
        "        y_true_example = train_y[:100].cpu().numpy()\n",
        "        rnn_input_example = train_X[:100]\n",
        "        rnn_output_prob_example = rnn_trainer.model(rnn_input_example).cpu().detach().numpy()\n",
        "        rnn_output_example = (rnn_output_prob_example > 0.5).astype(int)\n",
        "        y_pred_example = rnn_output_example.squeeze()\n",
        "        plot_confusion_matrix(y_true_example.flatten(), y_pred_example.flatten(), title='Confusion Matrix')\n",
        "\n",
        "        logging.info(\" AWGN Channel Simulation Complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "syXb7bvBmPzy",
        "outputId": "835d959c-3815-466c-e745-f62ed0341977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug: Reliability sequence length: 124\n",
            "Debug: self.N = 128, self.K = 64, self._crc_length = 7, self.K_crc = 71\n",
            "Debug: Info channel indices length (after slicing and sorting): 71\n",
            "Debug: Frozen channel indices length (after set difference and sorting): 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKoJ-FIxpTeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}