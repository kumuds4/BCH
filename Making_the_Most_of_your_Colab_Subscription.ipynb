{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mport numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import logging\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configuration parameters\n",
        "BLOCK_LENGTH = 128\n",
        "INFO_BITS = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "NUM_SAMPLES_TRAIN = 50000\n",
        "NUM_TRIALS_PERF = 1500\n",
        "SNR_RANGE_AWGN = np.linspace(0, 10, 21)\n",
        "LIST_SIZES = [1, 8, 16]\n",
        "\n",
        "#part 2\n",
        "\n",
        "def compute_crc(data, polynomial):\n",
        "    poly_len = len(polynomial)\n",
        "    crc_length = poly_len - 1\n",
        "    data_with_zeros = np.concatenate((data, np.zeros(crc_length, dtype=int)))\n",
        "    remainder = np.copy(data_with_zeros)\n",
        "    for i in range(len(remainder) - poly_len + 1):\n",
        "        if remainder[i] == 1:\n",
        "            remainder[i:i + poly_len] ^= polynomial\n",
        "    return remainder[-crc_length:]\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, channel_snr_db, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K / N\n",
        "        self.channel_snr_db = channel_snr_db\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {'CRC-7': (np.array([1, 0, 0, 0, 1, 0, 0, 1], dtype=int), 7)}\n",
        "\n",
        "        if crc_type in self.crc_polynomials:\n",
        "            self._crc_polynomial = self.crc_polynomials[crc_type][0]\n",
        "            self._crc_length = self.crc_polynomials[crc_type][1]\n",
        "        else:\n",
        "            self._crc_polynomial = None\n",
        "            self._crc_length = 0\n",
        "\n",
        "        self.K_crc = self.K + self._crc_length\n",
        "        self.frozen_set, self.info_set = self._get_frozen_and_info_sets()\n",
        "\n",
        "    def _get_frozen_and_info_sets(self):\n",
        "        if self.N == 128:\n",
        "            reliability_sequence = self._get_3gpp_reliability_sequence_128()\n",
        "            info_channel_indices = sorted(reliability_sequence[-self.K_crc:])\n",
        "            frozen_channel_indices = sorted(list(set(range(self.N)) - set(info_channel_indices)))\n",
        "        else:\n",
        "            raise NotImplementedError(\"Reliability sequence for N != 128 is not implemented.\")\n",
        "        return frozen_channel_indices, info_channel_indices\n",
        "\n",
        "    def _get_3gpp_reliability_sequence_128(self):\n",
        "        return [\n",
        "            0, 1, 2, 4, 8, 16, 3, 5, 9, 6, 17, 10, 18, 32, 12, 33,\n",
        "            20, 24, 34, 36, 40, 7, 11, 19, 21, 13, 22, 25, 26, 28,\n",
        "            48, 35, 37, 38, 41, 42, 44, 56, 14, 15, 23, 27, 29, 30,\n",
        "            31, 39, 43, 45, 46, 49, 50, 52, 57, 58, 60, 63, 47, 51,\n",
        "            53, 54, 59, 61, 62, 65, 66, 67, 68, 70, 72, 73, 74, 75,\n",
        "            76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 77,\n",
        "            79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 102, 103,\n",
        "            104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
        "            116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127\n",
        "        ]\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        info_bits_with_crc = self.append_crc(info_bits)\n",
        "        if len(info_bits_with_crc) != len(self.info_set):\n",
        "            raise ValueError(\"Length mismatch\")\n",
        "        u = np.zeros(self.N, dtype=int)\n",
        "        u[list(self.info_set)] = info_bits_with_crc\n",
        "        encoded = self._polar_transform(u)\n",
        "        return encoded\n",
        "def _polar_transform(self, u):\n",
        "        if len(u) == 1:\n",
        "            return u\n",
        "        else:\n",
        "            half_N = len(u) // 2\n",
        "            x_upper = self._polar_transform(u[:half_N])\n",
        "            x_lower = self._polar_transform(u[half_N:])\n",
        "            return np.concatenate([(x_upper + x_lower) % 2, x_lower])\n",
        "\n",
        "def append_crc(self, info_bits):\n",
        "        if self.crc_type not in self.crc_polynomials:\n",
        "            return info_bits\n",
        "        polynomial, length = self.crc_polynomials[self.crc_type]\n",
        "        data_for_crc = np.copy(info_bits)\n",
        "        crc_bits = compute_crc(data_for_crc, polynomial)\n",
        "        if len(crc_bits) != length:\n",
        "            logging.warning(f\"Calculated CRC length ({len(crc_bits)}) does not match expected length ({length})\")\n",
        "        return np.concatenate((info_bits, crc_bits))\n",
        "\n",
        " #part 3\n",
        "\n",
        "def bpsk_modulate(bits):\n",
        "    bits = np.array(bits, dtype=int)\n",
        "    return 2 * bits - 1\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def simulate(self, signal, snr_db):\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "        noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "        noise = noise_std * np.random.randn(*signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        modulated_signal = bpsk_modulate(encoded_signal)\n",
        "        received_signal = channel_simulator.simulate(modulated_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def save_dataset_to_csv(X, y, filename='dataset.csv'):\n",
        "    data = np.hstack((X, y))\n",
        "    columns = [f'received_{i}' for i in range(X.shape[1])] + [f'bit_{j}' for j in range(y.shape[1])]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.to_csv(filename, index=False)\n",
        "    logging.info(f\"Dataset saved to {filename}\")\n",
        "\n",
        " #part 4\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size=128, num_layers=2):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_reshaped = x.unsqueeze(1)\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x_reshaped, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate):\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=32):\n",
        "        dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            self.model.train()\n",
        "\n",
        "            for X_batch, y_batch in loader:\n",
        "                X_batch = X_batch.view(-1, BLOCK_LENGTH)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(X_batch)\n",
        "                loss = self.criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            train_loss = epoch_loss / len(loader)\n",
        "            train_losses.append(train_loss)\n",
        "            logging.info(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_output = self.model(X_val.view(-1, BLOCK_LENGTH))\n",
        "                    val_loss = self.criterion(val_output, y_val).item()\n",
        "                    val_losses.append(val_loss)\n",
        "                    logging.info(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return train_losses, val_losses if X_val is not None else None\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X_test.view(-1, BLOCK_LENGTH))\n",
        "            predicted = (outputs > 0.5).int()\n",
        "            total = y_test.numel()\n",
        "            bit_errors = torch.sum(predicted != y_test).item()\n",
        "            block_errors = torch.sum(torch.any(predicted != y_test, dim=1)).item()\n",
        "            ber = bit_errors / total\n",
        "            bler = block_errors / X_test.size(0)\n",
        "\n",
        "        return ber, bler\n",
        "\n",
        "# Part 5\n",
        "############################################################################\n",
        "\n",
        "\n",
        "lass PolarCodeDecoder:\n",
        "    def __init__(self, N, K, list_size, crc_poly=None):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.list_size = list_size\n",
        "        self.frozen_set = self._get_frozen_set()\n",
        "        self.info_set = sorted(list(set(range(N)) - set(self.frozen_set)))\n",
        "        self._crc_polynomial = crc_poly[0] if crc_poly else None\n",
        "        self._crc_length = crc_poly[1] if crc_poly else 0\n",
        "\n",
        "    def _get_frozen_set(self):\n",
        "        return set(range(self.K, self.N))\n",
        "\n",
        "    def decode(self, received_llrs):\n",
        "        active_path_indices = list(range(self.list_size))\n",
        "        self.paths = [[] for _ in range(self.list_size)]\n",
        "        self.path_metrics = [0.0] * self.list_size\n",
        "        self.hard_decisions = [np.zeros(self.N, dtype=int) for _ in range(self.list_size)]\n",
        "        self.llrs = [np.copy(received_llrs) for _ in range(self.list_size)]\n",
        "\n",
        "        final_active_path_indices = self._recursive_decode(active_path_indices, 0, self.N)\n",
        "        best_path_index = np.argmin(self.path_metrics)\n",
        "        return self.hard_decisions[best_path_index][list(self.info_set)]\n",
        "\n",
        "    def _recursive_decode(self, active_path_indices, bit_index, block_size):\n",
        "        if block_size == 1:\n",
        "            for path_idx in active_path_indices:\n",
        "                llr = self.llrs[path_idx][bit_index]\n",
        "                if bit_index in self.frozen_set:\n",
        "                    self.hard_decisions[path_idx][bit_index] = 0\n",
        "                else:\n",
        "                    self.hard_decisions[path_idx][bit_index] = 0 if llr >= 0 else 1\n",
        "            return active_path_indices\n",
        "        else:\n",
        "            half_size = block_size // 2\n",
        "            for path_idx in active_path_indices:\n",
        "                llr_f = self._f(self.llrs[path_idx][bit_index:bit_index + half_size],\n",
        "                                self.llrs[path_idx][bit_index + half_size:bit_index + block_size])\n",
        "                self.llrs[path_idx][bit_index:bit_index + half_size] = llr_f\n",
        "\n",
        "            active_paths_after_u1 = self._recursive_decode(active_path_indices, bit_index, half_size)\n",
        "\n",
        "            for path_idx in active_paths_after_u1:\n",
        "                u1_decisions = self.hard_decisions[path_idx][bit_index:bit_index + half_size]\n",
        "                llr_g = self._g(self.llrs[path_idx][bit_index:bit_index + half_size],\n",
        "                                self.llrs[path_idx][bit_index + half_size:bit_index + block_size], u1_decisions)\n",
        "                self.llrs[path_idx][bit_index + half_size:bit_index + block_size] = llr_g\n",
        "\n",
        "            return self._recursive_decode(active_paths_after_u1, bit_index + half_size, half_size)\n",
        "\n",
        "    def _f(self, L1, L2):\n",
        "        return np.minimum(np.abs(L1), np.abs(L2)) * np.sign(L1) * np.sign(L2)\n",
        "\n",
        "    def _g(self, L1, L2, u1):\n",
        "        return L2 + (1 - 2 * u1) * L1\n",
        "\n",
        "    def compute_crc(data, polynomial):\n",
        "    \"\"\"\n",
        "    Computes CRC for data using the given polynomial.\n",
        "    Args:\n",
        "        data: Numpy array of binary data bits (0s and 1s).\n",
        "        polynomial: Numpy array of binary polynomial coefficients (e.g., [1, 0, 0, 0, 1, 0, 0, 1] for x^7 + x^3 + 1).\n",
        "    Returns:\n",
        "        Numpy array of CRC bits.\n",
        "    \"\"\"\n",
        "    poly_len = len(polynomial)\n",
        "    crc_length = poly_len - 1\n",
        "    data_with_zeros = np.concatenate((data, np.zeros(crc_length, dtype=int)))\n",
        "    remainder = np.copy(data_with_zeros)\n",
        "\n",
        "    for i in range(len(remainder) - poly_len + 1):\n",
        "        if remainder[i] == 1:\n",
        "            remainder[i:i + poly_len] ^= polynomial\n",
        "\n",
        "    return remainder[-crc_length:]\n",
        "#############################################################################\n",
        "#part 6 Plotting fuctions\n",
        "\n",
        "def plot_ber_bler_comparison(snr_range, rnn_results, scl_results, sc_results, list_sizes):\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # BER Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BER_RNN'], label='RNN')\n",
        "    for size in list_sizes:\n",
        "        plt.plot(snr_range, [result['BER'] for result in scl_results[size]], label=f'SCL, List Size {size}')\n",
        "    plt.plot(snr_range, sc_results['BER_SC'], label='SC')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('Bit Error Rate (BER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # BLER Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BLER_RNN'], label='RNN')\n",
        "    for size in list_sizes:\n",
        "        plt.plot(snr_range, [result['BLER'] for result in scl_results[size]], label=f'SCL, List Size {size}')\n",
        "    plt.plot(snr_range, sc_results['BLER_SC'], label='SC')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title('Block Error Rate (BLER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_ber_bler_single(snr_range, ber, bler, name=''):\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, ber, marker='o')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title(f'{name} BER')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    ax = plt.gca()\n",
        "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, bler, marker='o')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title(f'{name} BLER')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    ax = plt.gca()\n",
        "    ax.yaxis.set_major_formatter(LogFormatterMathtext())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_ber_bler_single(snr_range, ber, bler, name=''):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, ber, marker='o')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title(f'{name} BER')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, bler, marker='o')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title(f'{name} BLER')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# For RNN:\n",
        "plot_ber_bler_single(SNR_RANGE_AWGN, rnn_results['BER_RNN'], rnn_results['BLER_RNN'], name='RNN')\n",
        "\n",
        "# For SC:\n",
        "plot_ber_bler_single(SNR_RANGE_AWGN, sc_results['BER_SC'], sc_results['BLER_SC'], name='SC')\n",
        "\n",
        "# For SCL (L=8, for example):\n",
        "plot_ber_bler_single(\n",
        "    SNR_RANGE_AWGN,\n",
        "    [d['BER'] for d in scl_results[8]],\n",
        "    [d['BLER'] for d in scl_results[8]],\n",
        "    name='SCL L=8'\n",
        ")\n",
        "\n",
        "######################################################################\n",
        "def plot_training_validation(train_losses, val_losses):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    if val_losses:\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_ber_bler_comparison(snr_range, rnn_results, scl_results, list_sizes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # BER Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BER_RNN'], label='RNN')\n",
        "    for size in list_sizes:\n",
        "        plt.plot(snr_range, [result['BER'] for result in scl_results[size]], label=f'SCL, List Size {size}')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('Bit Error Rate (BER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # BLER Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.yscale('log')\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.plot(snr_range, rnn_results['BLER_RNN'], label='RNN')\n",
        "    for size in list_sizes:\n",
        "        plt.plot(snr_range, [result['BLER'] for result in scl_results[size]], label=f'SCL, List Size {size}')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.title('Block Error Rate (BLER)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "#Part 7: Main Function\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Set up the device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Configuration parameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 50000\n",
        "        NUM_TRIALS_PERF = 1500\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 10, 21)\n",
        "        LIST_SIZES = [1, 8, 16]\n",
        "\n",
        "        # Polar code generator initialization\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        rnn_model = EnhancedRNNDecoder(BLOCK_LENGTH, INFO_BITS).to(device)\n",
        "        rnn_trainer = DecoderTrainer(rnn_model, LEARNING_RATE)\n",
        "\n",
        "        # Generate and save dataset\n",
        "        X_raw, y_raw = prepare_polar_dataset(\n",
        "            polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type='AWGN'\n",
        "        )\n",
        "        save_dataset_to_csv(X_raw, y_raw, 'awgn_dataset.csv')\n",
        "\n",
        "        # Reshape and split data, moving to the device\n",
        "        X_tensor = torch.FloatTensor(X_raw).view(-1, BLOCK_LENGTH).to(device)\n",
        "        y_tensor = torch.FloatTensor(y_raw).view(-1, INFO_BITS).to(device)\n",
        "\n",
        "        # Split data\n",
        "        train_size = int(0.8 * X_tensor.shape[0])\n",
        "        train_X = X_tensor[:train_size]\n",
        "        train_y = y_tensor[:train_size]\n",
        "        val_X = X_tensor[train_size:]\n",
        "        val_y = y_tensor[train_size:]\n",
        "\n",
        "        # RNN Model Training\n",
        "        train_losses, val_losses = rnn_trainer.train(\n",
        "            train_X, train_y, X_val=val_X, y_val=val_y, epochs=EPOCHS, batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Performance comparison\n",
        "        rnn_perf_results, scl_results = performance_comparison(\n",
        "            rnn_trainer, polar_code_gen, SNR_RANGE_AWGN, 'AWGN', LIST_SIZES, NUM_TRIALS_PERF\n",
        "        )\n",
        "\n",
        "        # Plot results\n",
        "        plot_training_validation(train_losses, val_losses)\n",
        "        plot_ber_bler_comparison(SNR_RANGE_AWGN, rnn_perf_results, scl_results, LIST_SIZES)\n",
        "\n",
        "        # Example Confusion Matrix\n",
        "        y_true_example = train_y[:100].cpu().numpy()\n",
        "        rnn_input_example = train_X[:100]\n",
        "        rnn_output_prob_example = rnn_trainer.model(rnn_input_example).cpu().detach().numpy()\n",
        "        rnn_output_example = (rnn_output_prob_example > 0.5).astype(int)\n",
        "        y_pred_example = rnn_output_example.squeeze()\n",
        "        plot_confusion_matrix(y_true_example.flatten(), y_pred_example.flatten(), title='Confusion Matrix')\n",
        "\n",
        "            # RNN plot\n",
        "        plot_ber_bler_single(SNR_RANGE_AWGN, rnn_results['BER_RNN'], rnn_results['BLER_RNN'], name='RNN')\n",
        "\n",
        "        # SC plot\n",
        "        plot_ber_bler_single(SNR_RANGE_AWGN, sc_results['BER_SC'], sc_results['BLER_SC'], name='SC')\n",
        "\n",
        "        # SCL plot (for each list size separately)\n",
        "        for L in LIST_SIZES:\n",
        "            plot_ber_bler_single(\n",
        "                SNR_RANGE_AWGN,\n",
        "                [d['BER'] for d in scl_results[L]],\n",
        "                [d['BLER'] for d in scl_results[L]],\n",
        "                name=f'SCL L={L}'\n",
        "            )\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "sLE4rmpyGpSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}