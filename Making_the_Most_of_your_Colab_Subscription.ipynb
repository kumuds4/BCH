{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yl_Lh5CACZ7",
        "outputId": "c2d1ce4d-f3aa-47a9-93e0-20add08c87fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "wRsayCXgAUQ6",
        "outputId": "543428df-5219-42b0-d32a-6be24ee92b2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f096af0-e977-4ef0-b7aa-0212c70d74e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f096af0-e977-4ef0-b7aa-0212c70d74e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# polar_code_generator.py\n",
        "# polar_code_generator.py\n",
        "!pip install ipympl\n",
        "!pip install scikit-learn\n",
        "!pip install numpy torch matplotlib scikit-learn\n",
        "!pip install -U matplotlib\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "#import matplotlib.pyplot as p\n",
        "#import ipympl\n",
        "matplotlib.use('Agg')  # Or try 'TkAgg', 'Qt5Agg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Add this line\n",
        "import logging\n",
        "import traceback\n",
        "# polar_code_generator.py\n",
        "!pip install ipympl\n",
        "!pip install scikit-learn\n",
        "!pip install numpy torch matplotlib scikit-learn\n",
        "!pip install -U matplotlib\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.pyplot as p\n",
        "#import ipympl\n",
        "matplotlib.use('Agg')  # Or try 'TkAgg', 'Qt5Agg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Add this line\n",
        "import logging\n",
        "import traceback\n",
        "# polar_code_generator.py\n",
        "!pip install ipympl\n",
        "!pip install scikit-learn\n",
        "!pip install numpy torch matplotlib scikit-learn\n",
        "!pip install -U matplotlib\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.pyplot as p\n",
        "#import ipympl\n",
        "matplotlib.use('Agg')  # Or try 'TkAgg', 'Qt5Agg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Add this line\n",
        "import logging\n",
        "import traceback\n",
        "# Import custom modules\n",
        "#from polar_code_generator import PolarCodeGenerator\n",
        "#from channel_simulator import ChannelSimulator\n",
        "#from neural_decoder import NeuralDecoder\n",
        "#from rnn_trainer import RNNTrainer\n",
        "#from ml_trainer import MLTrainer\n",
        "#from dataset_preparation import (\n",
        " #   prepare_polar_dataset,\n",
        "  #  prepare_dataset_for_training\n",
        "!pip install ipympl\n",
        "!pip install scikit-learn\n",
        "!pip install numpy torch matplotlib scikit-learn\n",
        "!pip install -U matplotlib\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.pyplot as p\n",
        "#import ipympl\n",
        "matplotlib.use('Agg')  # Or try 'TkAgg', 'Qt5Agg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Add this line\n",
        "import logging\n",
        "import traceback\n",
        "# polar_code_generator.py\n",
        "!pip install ipympl\n",
        "!pip install scikit-learn\n",
        "!pip install numpy torch matplotlib scikit-learn\n",
        "!pip install -U matplotlib\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.pyplot as p\n",
        "#import ipympl\n",
        "matplotlib.use('Agg')  # Or try 'TkAgg', 'Qt5Agg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Add this line\n",
        "import logging\n",
        "import traceback\n",
        "# Import custom modules\n",
        "#from polar_code_generator import PolarCodeGenerator\n",
        "#from channel_simulator import ChannelSimulator\n",
        "#from neural_decoder import NeuralDecoder\n",
        "#from rnn_trainer import RNNTrainer\n",
        "#from ml_trainer import MLTrainer\n",
        "#from dataset_preparation import (\n",
        " #   prepare_polar_dataset,\n",
        "  #  prepare_dataset_for_training\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N=128, K=64):\n",
        "        \"\"\"\n",
        "        Initialize Polar Code Generator with CRC-7 Polynomial\n",
        "\n",
        "        Args:\n",
        "            N (int): Total block length\n",
        "            K (int): Information bit length\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K / N  # Code rate\n",
        "\n",
        "        # CRC-7 Polynomial (Standard polynomial for communication)\n",
        "        # x^7 + x^6 + x^5 + x^2 + x^0\n",
        "        self.crc_polynomial = 0b10100011  # CRC-7 polynomial\n",
        "        self.crc_order = 7  # 7-bit CRC\n",
        "\n",
        "    def crc_generate(self, data):\n",
        "        \"\"\"\n",
        "        Generate CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Input data bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: CRC checksum bits\n",
        "        \"\"\"\n",
        "        # Convert input to numpy array\n",
        "        data = np.asarray(data)\n",
        "\n",
        "        # Create data with zero padding for CRC\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.crc_order, dtype=int)])\n",
        "\n",
        "        # CRC calculation\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Return the last 'crc_order' bits as CRC\n",
        "        return data_with_zeros[-self.crc_order:]\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        \"\"\"\n",
        "        Generate random information bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Random information bits\n",
        "        \"\"\"\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Place information bits\n",
        "        encoded_bits[:len(full_info)] = full_info\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def crc_verify(self, data, received_crc):\n",
        "        \"\"\"\n",
        "        Verify CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Original data bits\n",
        "            received_crc (np.ndarray): Received CRC checksum\n",
        "\n",
        "        Returns:\n",
        "            bool: True if CRC is valid, False otherwise\n",
        "        \"\"\"\n",
        "        # Combine data and received CRC\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        # CRC verification\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    full_data[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Check if the last 'crc_order' bits are zero\n",
        "        return np.all(full_data[-self.crc_order:] == 0)\n",
        "\n",
        "    def bhattacharyya_parameter(self, W, n):\n",
        "        \"\"\"\n",
        "        Compute Bhattacharyya parameter for channel polarization\n",
        "\n",
        "        Args:\n",
        "            W (float): Initial channel crossover probability\n",
        "            n (int): Recursion depth\n",
        "\n",
        "        Returns:\n",
        "            float: Bhattacharyya parameter\n",
        "        \"\"\"\n",
        "        if n == 0:\n",
        "            return W\n",
        "\n",
        "        # Recursive Bhattacharyya parameter computation\n",
        "        W_used = self.bhattacharyya_parameter(W, n-1)\n",
        "        W_transform = 2 * (W_used ** 2) - (W_used ** 4)\n",
        "\n",
        "        return W_transform\n",
        "\n",
        "def generate_polar_code_matrix(self):\n",
        "    \"\"\"\n",
        "    Generate polar code matrix using Bhattacharyya parameter\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Indices of information bit positions\n",
        "    \"\"\"\n",
        "    # Initial channel crossover probability (Binary Symmetric Channel)\n",
        "    W = 0.5\n",
        "\n",
        "    # Compute channel capacities\n",
        "    channel_capacities = []\n",
        "    for _ in range(self.N):\n",
        "        # Compute Bhattacharyya parameter\n",
        "        capacity = self.bhattacharyya_parameter(W, int(math.log2(self.N)))\n",
        "        channel_capacities.append(capacity)\n",
        "\n",
        "    # Sort channel capacities\n",
        "    sorted_indices = np.argsort(channel_capacities)\n",
        "\n",
        "    # Select best channels for information bits\n",
        "    info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "    return info_indices\n",
        "\n",
        "def polar_encode(self, info_bits):\n",
        "    \"\"\"\n",
        "    Systematic Polar Encoding with CRC\n",
        "\n",
        "    Args:\n",
        "        info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Encoded codeword\n",
        "    \"\"\"\n",
        "    # Generate CRC\n",
        "    crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "    # Combine info bits and CRC\n",
        "    full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "    # Initialize codeword\n",
        "    encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "    # Get indices for information bits\n",
        "    info_indices = self.generate_polar_code_matrix()\n",
        "\n",
        "    # Ensure we don't exceed available indices\n",
        "    max_info_length = min(len(full_info), len(info_indices))\n",
        "\n",
        "    # Place information bits at selected indices\n",
        "    encoded_bits[info_indices[:max_info_length]] = full_info[:max_info_length]\n",
        "\n",
        "    return encoded_bits\n",
        "\n",
        "def bhattacharyya_parameter(self, W, n):\n",
        "    \"\"\"\n",
        "    Compute Bhattacharyya parameter for channel polarization\n",
        "\n",
        "    Args:\n",
        "        W (float): Initial channel crossover probability\n",
        "        n (int): Recursion depth\n",
        "\n",
        "    Returns:\n",
        "        float: Bhattacharyya parameter\n",
        "    \"\"\"\n",
        "    if n == 0:\n",
        "        return W\n",
        "\n",
        "    # Recursive Bhattacharyya parameter computation\n",
        "    W_used = self.bhattacharyya_parameter(W, n-1)\n",
        "    W_transform = 2 * (W_used ** 2) - (W_used ** 4)\n",
        "    return W_transform # Add this line to fix the syntax error\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        \"\"\"\n",
        "        Generate random information bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Random information bits\n",
        "        \"\"\"\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Get indices for information bits\n",
        "        info_indices = self.generate_polar_code_matrix()\n",
        "        info_indices = info_indices[:len(full_info)]\n",
        "\n",
        "        # Place information bits at selected indices\n",
        "        encoded_bits[info_indices] = full_info\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "# Part 1: Channel Simulator\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        \"\"\"\n",
        "        Initialize Channel Simulator\n",
        "\n",
        "        Args:\n",
        "            channel_type (str): Type of channel (AWGN or Rayleigh)\n",
        "        \"\"\"\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        \"\"\"\n",
        "        Transmit signal through channel\n",
        "\n",
        "        Args:\n",
        "            signal (np.ndarray): Input signal\n",
        "            snr (float): Signal-to-Noise Ratio in dB\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Received noisy signal\n",
        "        \"\"\"\n",
        "        # Convert SNR to linear scale\n",
        "        snr_linear = 10 ** (snr / 10)\n",
        "\n",
        "        # Noise standard deviation\n",
        "        noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "\n",
        "        # Generate noise\n",
        "        if self.channel_type == 'AWGN':\n",
        "            # Additive White Gaussian Noise\n",
        "            noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            # Rayleigh Fading Channel\n",
        "            fading = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "            noise = fading * np.random.normal(0, noise_std, signal.shape)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "        return signal + noise\n",
        "\n",
        "\n",
        "# channel_simulator.py\n",
        "\n",
        "\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        \"\"\"\n",
        "        Initialize Channel Simulator\n",
        "\n",
        "        Args:\n",
        "            channel_type (str): Type of channel (AWGN or Rayleigh)\n",
        "        \"\"\"\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        \"\"\"\n",
        "        Transmit signal through channel\n",
        "\n",
        "        Args:\n",
        "            signal (np.ndarray): Input signal\n",
        "            snr (float): Signal-to-Noise Ratio in dB\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Received noisy signal\n",
        "        \"\"\"\n",
        "        # Convert SNR to linear scale\n",
        "        snr_linear = 10 ** (snr / 10)\n",
        "\n",
        "        # Noise standard deviation\n",
        "        noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "\n",
        "        # Generate noise\n",
        "        if self.channel_type == 'AWGN':\n",
        "            # Additive White Gaussian Noise\n",
        "            noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            # Rayleigh Fading Channel\n",
        "            fading = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "            noise = fading * np.random.normal(0, noise_std, signal.shape)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "        return signal + noise\n",
        "\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Neural network model\n",
        "            learning_rate (float): Optimization learning rate\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=20, batch_size=64):\n",
        "        \"\"\"\n",
        "        Train the model\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Training features\n",
        "            y_train (np.ndarray): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train)\n",
        "        y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        for epoch in range(epochs):\n",
        "            # Forward pass\n",
        "            outputs = self.model(X_train)\n",
        "            loss = self.criterion(outputs, y_train)\n",
        "\n",
        "            # Backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        return train_losses\n",
        "\n",
        "    def plot_training_performance(self, train_losses, title='Training Performance'):\n",
        "        \"\"\"\n",
        "        Plot training performance\n",
        "\n",
        "        Args:\n",
        "            train_losses (list): Training losses\n",
        "            title (str): Plot title\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses)\n",
        "        plt.title(title)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.close()\n",
        "\n",
        "class RNNTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize RNN Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): RNN neural network model\n",
        "            learning_rate (float): Optimization learning rate\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=20, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the RNN model\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Training features\n",
        "            y_train (np.ndarray): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Convert to torch tensors and move to device\n",
        "        X_train = torch.FloatTensor(X_train).to(self.device)\n",
        "        y_train = torch.FloatTensor(y_train).to(self.device).unsqueeze(1)\n",
        "\n",
        "        # Reshape input for RNN if needed\n",
        "        if X_train.dim() == 2:\n",
        "            X_train = X_train.unsqueeze(2)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X_train))\n",
        "        X_val, y_val = X_train[train_size:], y_train[train_size:]\n",
        "        X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            epoch_train_losses = []\n",
        "\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_X = X_train[i:i+batch_size]\n",
        "                batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_train_losses.append(loss.item())\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val)\n",
        "                val_loss = self.criterion(val_outputs, y_val)\n",
        "\n",
        "            # Record losses\n",
        "            avg_train_loss = np.mean(epoch_train_losses)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def plot_training_performance(self, train_losses, val_losses=None, title='RNN Training Performance'):\n",
        "        \"\"\"\n",
        "        Plot RNN training performance\n",
        "\n",
        "        Args:\n",
        "            train_losses (list): Training losses\n",
        "            val_losses (list, optional): Validation losses\n",
        "            title (str): Plot title\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Training Loss Plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.title(f'{title} - Training Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Validation Loss Plot\n",
        "        if val_losses:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(val_losses, label='Validation Loss', color='red')\n",
        "            plt.title(f'{title} - Validation Loss')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.close()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the trained model\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features for prediction\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Reshape input for RNN if needed\n",
        "        if X.dim() == 2:\n",
        "            X = X.unsqueeze(2)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X)\n",
        "\n",
        "        return predictions.cpu().numpy()\n",
        "\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize ML (MLP) Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Multi-Layer Perceptron model\n",
        "            learning_rate (float): Optimization learning rate\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=20, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the ML model\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Training features\n",
        "            y_train (np.ndarray): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Convert to torch tensors and move to device\n",
        "        X_train = torch.FloatTensor(X_train).to(self.device)\n",
        "        y_train = torch.FloatTensor(y_train).to(self.device).unsqueeze(1)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X_train))\n",
        "        X_val, y_val = X_train[train_size:], y_train[train_size:]\n",
        "        X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            epoch_train_losses = []\n",
        "\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_X = X_train[i:i+batch_size]\n",
        "                batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_train_losses.append(loss.item())\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val)\n",
        "                val_loss = self.criterion(val_outputs, y_val)\n",
        "\n",
        "            # Record losses\n",
        "            avg_train_loss = np.mean(epoch_train_losses)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def plot_training_performance(self, train_losses, val_losses=None, title='ML Training Performance'):\n",
        "        \"\"\"\n",
        "        Plot ML training performance\n",
        "\n",
        "        Args:\n",
        "            train_losses (list): Training losses\n",
        "            val_losses (list, optional): Validation losses\n",
        "            title (str): Plot title\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Training Loss Plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.title(f'{title} - Training Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Validation Loss Plot\n",
        "        if val_losses:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(val_losses, label='Validation Loss', color='red')\n",
        "            plt.title(f'{title} - Validation Loss')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.close()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the trained model\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features for prediction\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X)\n",
        "\n",
        "        return predictions.cpu().numpy()\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, feature_type='codeword'):\n",
        "    \"\"\"\n",
        "    Advanced dataset preparation for Polar Codes\n",
        "\n",
        "    Args:\n",
        "        polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "        num_samples (int): Number of samples to generate\n",
        "        feature_type (str): Type of feature extraction\n",
        "\n",
        "    Returns:\n",
        "        tuple: Features and labels\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate info bits\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "        # Encode\n",
        "        codeword = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "        # Feature extraction\n",
        "        if feature_type == 'codeword':\n",
        "            # Use full codeword as features\n",
        "            features = codeword\n",
        "        elif feature_type == 'statistical':\n",
        "            # Statistical features\n",
        "            features = [\n",
        "                np.mean(codeword),\n",
        "                np.std(codeword),\n",
        "                np.sum(codeword),\n",
        "                np.count_nonzero(codeword)\n",
        "            ]\n",
        "        elif feature_type == 'frequency':\n",
        "            # Frequency-based features\n",
        "            unique, counts = np.unique(codeword, return_counts=True)\n",
        "            features = dict(zip(unique, counts))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported feature type: {feature_type}\")\n",
        "\n",
        "        X.append(features)\n",
        "\n",
        "        # Binary classification label (e.g., based on mean)\n",
        "        y.append(1 if np.mean(codeword) > 0.5 else 0)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def prepare_dataset_for_training(X, y, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Prepare dataset for neural network training\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Features\n",
        "        y (np.ndarray): Labels\n",
        "        test_size (float): Proportion of test data\n",
        "        random_state (int): Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        tuple: Train and test splits\n",
        "    \"\"\"\n",
        "    # Split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def normalize_features(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Normalize features using min-max scaling\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): Training features\n",
        "        X_test (np.ndarray): Test features\n",
        "\n",
        "    Returns:\n",
        "        tuple: Normalized training and test features\n",
        "    \"\"\"\n",
        "    # Compute min and max for each feature\n",
        "    min_vals = np.min(X_train, axis=0)\n",
        "    max_vals = np.max(X_train, axis=0)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    max_vals[max_vals == min_vals] = 1\n",
        "\n",
        "    # Normalize\n",
        "    X_train_normalized = (X_train - min_vals) / (max_vals - min_vals)\n",
        "    X_test_normalized = (X_test - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "    return X_train_normalized, X_test_normalized\n",
        "\n",
        "def create_rnn_model(input_size):\n",
        "    \"\"\"\n",
        "    Create RNN Model\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Input feature dimension\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: RNN model\n",
        "    \"\"\"\n",
        "    class RNNDecoder(nn.Module):\n",
        "        def __init__(self, input_size):\n",
        "            super(RNNDecoder, self).__init__()\n",
        "\n",
        "            self.rnn = nn.Sequential(\n",
        "                nn.LSTM(\n",
        "                    input_size=input_size,\n",
        "                    hidden_size=64,\n",
        "                    num_layers=2,\n",
        "                    batch_first=True\n",
        "                ),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            )\n",
        "\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(64, 32),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(32, 1),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            # Ensure input is 3D for RNN\n",
        "            if x.dim() == 2:\n",
        "                x = x.unsqueeze(2)\n",
        "\n",
        "            # RNN processing\n",
        "            rnn_out, _ = self.rnn(x)\n",
        "\n",
        "            # Take the last time step\n",
        "            out = rnn_out[:, -1, :]\n",
        "\n",
        "            # Final classification\n",
        "            return self.fc(out)\n",
        "\n",
        "    return RNNDecoder(input_size)\n",
        "def compute_channel_performance(model, channel, snr_range, polar_code_gen):\n",
        "    \"\"\"\n",
        "    Compute Bit Error Rate (BER) and Block Error Rate (BLER)\n",
        "\n",
        "    Args:\n",
        "        model: Trained decoder model\n",
        "        channel: Channel simulator\n",
        "        snr_range (np.ndarray): SNR range\n",
        "        polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "\n",
        "    Returns:\n",
        "        tuple: BER and BLER arrays\n",
        "    \"\"\"\n",
        "    ber_values = []\n",
        "    bler_values = []\n",
        "\n",
        "    for snr in snr_range:\n",
        "        block_errors = 0\n",
        "        bit_errors = 0\n",
        "        total_blocks = 100\n",
        "\n",
        "        for _ in range(total_blocks):\n",
        "            # Generate info bits\n",
        "            info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "            # Encode\n",
        "            encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "            # Transmit through channel\n",
        "            received_signal = channel.transmit(encoded_signal, snr)\n",
        "\n",
        "            # Decode\n",
        "            decoded_bits = model.predict(received_signal.reshape(1, -1))\n",
        "            decoded_bits = (decoded_bits > 0.5).astype(int).flatten()\n",
        "\n",
        "            # Compute errors\n",
        "            block_error = not np.array_equal(info_bits, decoded_bits)\n",
        "            bit_error = np.sum(info_bits != decoded_bits)\n",
        "\n",
        "            block_errors += block_error\n",
        "            bit_errors += bit_error\n",
        "\n",
        "        # Compute BER and BLER\n",
        "        ber = bit_errors / (total_blocks * len(info_bits))\n",
        "        bler = block_errors / total_blocks\n",
        "\n",
        "        ber_values.append(ber)\n",
        "        bler_values.append(bler)\n",
        "\n",
        "    return np.array(ber_values), np.array(bler_values)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): True labels\n",
        "        y_pred (array-like): Predicted labels\n",
        "        title (str): Plot title\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_error_performance(snr_range, ber_data, bler_data):\n",
        "    \"\"\"\n",
        "    Plot BER and BLER performance\n",
        "\n",
        "    Args:\n",
        "        snr_range (np.ndarray): SNR range\n",
        "        ber_data (dict): Bit Error Rate data\n",
        "        bler_data (dict): Block Error Rate data\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # BER Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for model, ber in ber_data.items():\n",
        "        plt.semilogy(snr_range, ber, label=f'{model} BER')\n",
        "    plt.title('Bit Error Rate Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Bit Error Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # BLER Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for model, bler in bler_data.items():\n",
        "        plt.semilogy(snr_range, bler, label=f'{model} BLER')\n",
        "    plt.title('Block Error Rate Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('Block Error Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('error_performance.png')\n",
        "    plt.close()\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
        "        \"\"\"\n",
        "        RNN Decoder for Polar Codes\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Input feature dimension\n",
        "            hidden_size (int): RNN hidden layer size\n",
        "            num_layers (int): Number of RNN layers\n",
        "        \"\"\"\n",
        "        super(RNNDecoder, self).__init__()\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.3\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass with comprehensive input handling\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output predictions\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.FloatTensor(x)\n",
        "\n",
        "        # Reshape input if necessary\n",
        "        if x.ndimension() == 2:\n",
        "            x = x.unsqueeze(2)\n",
        "\n",
        "        # Ensure 3D tensor [batch_size, sequence_length, input_size]\n",
        "        if x.ndimension() != 3:\n",
        "            raise ValueError(f\"Expected 3D input, got {x.ndimension()}D input with shape {x.shape}\")\n",
        "\n",
        "        # Ensure input has correct number of features\n",
        "        if x.size(-1) != 4:\n",
        "            # Pad or repeat features to match expected input size\n",
        "            x = x.repeat(1, 1, 4)[:, :, :4]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Take the last time step\n",
        "        out = lstm_out[:, -1, :]\n",
        "\n",
        "        # Final classification\n",
        "        return self.fc(out)\n",
        "\n",
        "class RNNTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize RNN Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): RNN model to train\n",
        "            learning_rate (float): Learning rate for optimizer\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the RNN model\n",
        "\n",
        "        Args:\n",
        "            X_train (torch.Tensor): Training features\n",
        "            y_train (torch.Tensor): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor and move to device\n",
        "        X_train = X_train.to(self.device)\n",
        "        y_train = y_train.to(self.device)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X_train))\n",
        "        X_val, y_val = X_train[train_size:], y_train[train_size:]\n",
        "        X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        # Progress tracking\n",
        "        log_interval = max(1, epochs // 10)  # Log every 10% of epochs\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            epoch_train_losses = []\n",
        "\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_X = X_train[i:i+batch_size]\n",
        "                batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_train_losses.append(loss.item())\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val)\n",
        "                val_loss = self.criterion(val_outputs, y_val)\n",
        "\n",
        "            # Record losses\n",
        "            avg_train_loss = np.mean(epoch_train_losses)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            # Reduced verbosity logging\n",
        "            if epoch % log_interval == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the trained model\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features for prediction\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Reshape input for RNN if needed\n",
        "        if X.dim() == 2:\n",
        "            X = X.unsqueeze(2)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X)\n",
        "\n",
        "        return predictions.cpu().numpy()\n",
        "\n",
        "class MLDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers=[128, 64, 32], output_size=1):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron Decoder\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Input feature dimension\n",
        "            hidden_layers (list): Hidden layer sizes\n",
        "            output_size (int): Output dimension\n",
        "        \"\"\"\n",
        "        super(MLDecoder, self).__init__()\n",
        "\n",
        "        # Advanced feature extraction and classification layers\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.BatchNorm1d(hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.4)  # Regularization\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.extend([\n",
        "            nn.Linear(prev_size, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, output_size),\n",
        "            nn.Sigmoid()  # Probabilistic output\n",
        "        ])\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass with advanced feature learning\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoded probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.FloatTensor(x)\n",
        "\n",
        "        # Ensure 2D input\n",
        "        if x.dim() == 3:\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Normalize input\n",
        "        x = (x - x.mean(dim=0)) / (x.std(dim=0) + 1e-7)\n",
        "\n",
        "        return self.model(x)\n",
        "\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize ML Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Neural network model\n",
        "            learning_rate (float): Learning rate for optimizer\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5  # L2 regularization\n",
        "        )\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the ML model\n",
        "\n",
        "        Args:\n",
        "            X_train (torch.Tensor): Training features\n",
        "            y_train (torch.Tensor): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor and move to device\n",
        "        X_train = X_train.to(self.device)\n",
        "        y_train = y_train.to(self.device)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X_train))\n",
        "        X_val, y_val = X_train[train_size:], y_train[train_size:]\n",
        "        X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
        "\n",
        "        # Training loop\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        # Progress tracking\n",
        "        log_interval = max(1, epochs // 10)  # Log every 10% of epochs\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            epoch_train_losses = []\n",
        "\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_X = X_train[i:i+batch_size]\n",
        "                batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_train_losses.append(loss.item())\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val)\n",
        "                val_loss = self.criterion(val_outputs, y_val)\n",
        "\n",
        "            # Record losses\n",
        "            avg_train_loss = np.mean(epoch_train_losses)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            # Reduced verbosity logging\n",
        "            if epoch % log_interval == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the trained model\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features for prediction\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a torch tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Ensure 2D input\n",
        "        if X.dim() == 3:\n",
        "            X = X.view(X.size(0), -1)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X)\n",
        "\n",
        "        return predictions.cpu().numpy()\n",
        "class DecoderComparator:\n",
        "    def __init__(self, polar_code_gen, dataset_params):\n",
        "        \"\"\"\n",
        "        Comprehensive Decoder Comparison Framework\n",
        "\n",
        "        Args:\n",
        "            polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "            dataset_params (dict): Dataset configuration\n",
        "        \"\"\"\n",
        "        self.polar_code_gen = polar_code_gen\n",
        "        self.dataset_params = dataset_params\n",
        "\n",
        "        # Initialize different decoders\n",
        "        self.traditional_decoder = TraditionalPolarDecoder(\n",
        "            N=dataset_params['block_length'],\n",
        "            K=dataset_params['info_bits']\n",
        "        )\n",
        "\n",
        "        self.ml_decoder = MLDecoder(\n",
        "            input_size=dataset_params['block_length'],\n",
        "            hidden_layers=[128, 64, 32]\n",
        "        )\n",
        "\n",
        "        self.rnn_decoder = RNNDecoder(\n",
        "            input_size=dataset_params['block_length']\n",
        "        )\n",
        "\n",
        "    def prepare_comparative_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare dataset with advanced feature extraction\n",
        "\n",
        "        Returns:\n",
        "            tuple: Processed features and labels\n",
        "        \"\"\"\n",
        "        X, y = prepare_advanced_dataset(\n",
        "            self.polar_code_gen,\n",
        "            num_samples=self.dataset_params['num_samples']\n",
        "        )\n",
        "\n",
        "        # Additional feature engineering\n",
        "        X_features = extract_advanced_features(X)\n",
        "\n",
        "        return X_features, y\n",
        "\n",
        "    def compare_decoder_performance(self):\n",
        "        \"\"\"\n",
        "        Comprehensive decoder performance comparison\n",
        "\n",
        "        Returns:\n",
        "            dict: Performance metrics for each decoder\n",
        "        \"\"\"\n",
        "        # Prepare dataset\n",
        "        X, y = self.prepare_comparative_dataset()\n",
        "\n",
        "        # Performance metrics dictionary\n",
        "        performance_metrics = {\n",
        "            'traditional': self.evaluate_traditional_decoder(X, y),\n",
        "            'ml_decoder': self.evaluate_ml_decoder(X, y),\n",
        "            'rnn_decoder': self.evaluate_rnn_decoder(X, y)\n",
        "        }\n",
        "\n",
        "        return performance_metrics\n",
        "\n",
        "    def evaluate_traditional_decoder(self, X, y):\n",
        "        # Implementation of traditional decoder evaluation\n",
        "        pass\n",
        "\n",
        "    def evaluate_ml_decoder(self, X, y):\n",
        "        # Implementation of ML decoder evaluation\n",
        "        pass\n",
        "\n",
        "    def evaluate_rnn_decoder(self, X, y):\n",
        "        # Implementation of RNN decoder evaluation\n",
        "        pass\n",
        "class TraditionalPolarDecoder:\n",
        "    def __init__(self, N, K):\n",
        "        \"\"\"\n",
        "        Traditional Polar Code Successive Cancellation Decoder\n",
        "\n",
        "        Args:\n",
        "            N (int): Total block length\n",
        "            K (int): Information bit length\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.rate = K / N\n",
        "\n",
        "    def polar_transform(self, llr):\n",
        "        \"\"\"\n",
        "        Polar code transform using Bhattacharyya parameter\n",
        "\n",
        "        Args:\n",
        "            llr (np.ndarray): Log-Likelihood Ratios\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Transformed LLRs\n",
        "        \"\"\"\n",
        "        n = int(np.log2(len(llr)))\n",
        "        for i in range(n):\n",
        "            u = np.zeros(len(llr))\n",
        "            for j in range(len(llr) // 2):\n",
        "                # Bit-channel transformation\n",
        "                u[2*j] = np.sign(llr[j]) * np.sign(llr[j + len(llr)//2]) * \\\n",
        "                         min(abs(llr[j]), abs(llr[j + len(llr)//2]))\n",
        "                u[2*j + 1] = llr[j + len(llr)//2]\n",
        "            llr = u\n",
        "        return llr\n",
        "\n",
        "    def successive_cancellation_decode(self, received_signal):\n",
        "        \"\"\"\n",
        "        Successive Cancellation Decoding\n",
        "\n",
        "        Args:\n",
        "            received_signal (np.ndarray): Received noisy signal\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Decoded information bits\n",
        "        \"\"\"\n",
        "        # Convert received signal to LLRs\n",
        "        llr = np.log((1 + received_signal) / (1 - received_signal))\n",
        "\n",
        "        # Polar transform\n",
        "        transformed_llr = self.polar_transform(llr)\n",
        "\n",
        "        # Decode using successive cancellation\n",
        "        decoded_bits = np.zeros(self.N, dtype=int)\n",
        "        for i in range(self.N):\n",
        "            # Decision based on LLR sign\n",
        "            decoded_bits[i] = 1 if transformed_llr[i] < 0 else 0\n",
        "\n",
        "        return decoded_bits\n",
        "\n",
        "    def compute_performance(self, channel, snr_range, polar_code_gen):\n",
        "        \"\"\"\n",
        "        Compute performance metrics for Traditional Polar Decoder\n",
        "\n",
        "        Args:\n",
        "            channel (ChannelSimulator): Channel simulator\n",
        "            snr_range (np.ndarray): SNR range\n",
        "            polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "\n",
        "        Returns:\n",
        "            tuple: BER and BLER arrays\n",
        "        \"\"\"\n",
        "        ber_values = []\n",
        "        bler_values = []\n",
        "\n",
        "        for snr in snr_range:\n",
        "            block_errors = 0\n",
        "            bit_errors = 0\n",
        "            total_blocks = 100\n",
        "\n",
        "            for _ in range(total_blocks):\n",
        "                # Generate info bits\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "                # Encode\n",
        "                encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "                # Transmit through channel\n",
        "                received_signal = channel.transmit(encoded_signal, snr)\n",
        "\n",
        "                # Decode\n",
        "                decoded_bits = self.successive_cancellation_decode(received_signal)\n",
        "\n",
        "                # Compute errors\n",
        "                block_error = not np.array_equal(info_bits, decoded_bits[:len(info_bits)])\n",
        "                bit_error = np.sum(info_bits != decoded_bits[:len(info_bits)])\n",
        "\n",
        "                block_errors += block_error\n",
        "                bit_errors += bit_error\n",
        "\n",
        "            # Compute BER and BLER\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N=128, K=64):\n",
        "        \"\"\"\n",
        "        Initialize Polar Code Generator with CRC-7 Polynomial\n",
        "\n",
        "        Args:\n",
        "            N (int): Total block length\n",
        "            K (int): Information bit length\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K / N  # Code rate\n",
        "\n",
        "        # CRC-7 Polynomial (Standard polynomial for communication)\n",
        "        # x^7 + x^6 + x^5 + x^2 + x^0\n",
        "        self.crc_polynomial = 0b10100011  # CRC-7 polynomial\n",
        "        self.crc_order = 7  # 7-bit CRC\n",
        "\n",
        "    def crc_generate(self, data):\n",
        "        \"\"\"\n",
        "        Generate CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Input data bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: CRC checksum bits\n",
        "        \"\"\"\n",
        "        # Convert input to numpy array\n",
        "        data = np.asarray(data)\n",
        "\n",
        "        # Create data with zero padding for CRC\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.crc_order, dtype=int)])\n",
        "\n",
        "        # CRC calculation\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Return the last 'crc_order' bits as CRC\n",
        "        return data_with_zeros[-self.crc_order:]\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        \"\"\"\n",
        "        Generate random information bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Random information bits\n",
        "        \"\"\"\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Place information bits\n",
        "        encoded_bits[:len(full_info)] = full_info\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def crc_verify(self, data, received_crc):\n",
        "        \"\"\"\n",
        "        Verify CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Original data bits\n",
        "            received_crc (np.ndarray): Received CRC checksum\n",
        "\n",
        "        Returns:\n",
        "            bool: True if CRC is valid, False otherwise\n",
        "        \"\"\"\n",
        "        # Combine data and received CRC\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        # CRC verification\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    full_data[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Check if the last 'crc_order' bits are zero\n",
        "        return np.all(full_data[-self.crc_order:] == 0)\n",
        "\n",
        "    def bhattacharyya_parameter(self, W, n):\n",
        "        \"\"\"\n",
        "        Compute Bhattacharyya parameter for channel polarization\n",
        "\n",
        "        Args:\n",
        "            W (float): Initial channel crossover probability\n",
        "            n (int): Recursion depth\n",
        "\n",
        "        Returns:\n",
        "            float: Bhattacharyya parameter\n",
        "        \"\"\"\n",
        "        if n == 0:\n",
        "            return W\n",
        "\n",
        "        # Recursive Bhattacharyya parameter computation\n",
        "        W_used = self.bhattacharyya_parameter(W, n-1)\n",
        "        W_transform = 2 * (W_used ** 2) - (W_used ** 4)\n",
        "\n",
        "        return W_transform\n",
        "\n",
        "    def generate_polar_code_matrix(self):\n",
        "        \"\"\"\n",
        "        Generate polar code matrix using Bhattacharyya parameter\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Indices of information bit positions\n",
        "        \"\"\"\n",
        "        # Initial channel crossover probability (Binary Symmetric Channel)\n",
        "        W = 0.5\n",
        "\n",
        "        # Compute channel capacities\n",
        "        channel_capacities = []\n",
        "        for _ in range(self.N):\n",
        "            # Compute Bhattacharyya parameter\n",
        "            capacity = self.bhattacharyya_parameter(W, int(math.log2(self.N)))\n",
        "            channel_capacities.append(capacity)\n",
        "\n",
        "        # Sort channel capacities\n",
        "        sorted_indices = np.argsort(channel_capacities)\n",
        "\n",
        "        # Select best channels for information bits\n",
        "        info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "        return info_indices\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Get indices for information bits\n",
        "        info_indices = self.generate_polar_code_matrix()\n",
        "\n",
        "        # Ensure we don't exceed available indices\n",
        "        max_info_length = min(len(full_info), len(info_indices))\n",
        "\n",
        "        # Place information bits at selected indices\n",
        "        encoded_bits[info_indices[:max_info_length]] = full_info[:max_info_length]\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "class TraditionalPolarDecoder:\n",
        "    def __init__(self, N, K):\n",
        "        \"\"\"\n",
        "        Traditional Polar Code Successive Cancellation Decoder\n",
        "\n",
        "        Args:\n",
        "            N (int): Total block length\n",
        "            K (int): Information bit length\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.rate = K / N\n",
        "\n",
        "    def polar_transform(self, llr):\n",
        "        \"\"\"\n",
        "        Polar code transform using Bhattacharyya parameter\n",
        "\n",
        "        Args:\n",
        "            llr (np.ndarray): Log-Likelihood Ratios\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Transformed LLRs\n",
        "        \"\"\"\n",
        "        n = int(np.log2(len(llr)))\n",
        "        for i in range(n):\n",
        "            u = np.zeros(len(llr))\n",
        "            for j in range(len(llr) // 2):\n",
        "                # Bit-channel transformation\n",
        "                u[2*j] = np.sign(llr[j]) * np.sign(llr[j + len(llr)//2]) * \\\n",
        "                         min(abs(llr[j]), abs(llr[j + len(llr)//2]))\n",
        "                u[2*j + 1] = llr[j + len(llr)//2]\n",
        "            llr = u\n",
        "        return llr\n",
        "\n",
        "    def successive_cancellation_decode(self, received_signal):\n",
        "        \"\"\"\n",
        "        Successive Cancellation Decoding\n",
        "\n",
        "        Args:\n",
        "            received_signal (np.ndarray): Received noisy signal\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Decoded information bits\n",
        "        \"\"\"\n",
        "        # Convert received signal to LLRs\n",
        "        llr = np.log((1 + received_signal) / (1 - received_signal))\n",
        "\n",
        "        # Polar transform\n",
        "        transformed_llr = self.polar_transform(llr)\n",
        "\n",
        "        # Decode using successive cancellation\n",
        "        decoded_bits = np.zeros(self.N, dtype=int)\n",
        "        for i in range(self.N):\n",
        "            # Decision based on LLR sign\n",
        "            decoded_bits[i] = 1 if transformed_llr[i] < 0 else 0\n",
        "\n",
        "        return decoded_bits\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Prediction method for compatibility with other decoders\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input signals to decode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Prediction probabilities\n",
        "        \"\"\"\n",
        "        # Store predictions\n",
        "        predictions = []\n",
        "\n",
        "        # Decode each input signal\n",
        "        for signal in X:\n",
        "            # Decode the signal\n",
        "            decoded_bits = self.successive_cancellation_decode(signal)\n",
        "\n",
        "            # Use mean of decoded bits as prediction probability\n",
        "            prediction = np.mean(decoded_bits)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_performance(self, channel, snr_range, polar_code_gen):\n",
        "        \"\"\"\n",
        "        Compute performance metrics for Traditional Polar Decoder\n",
        "\n",
        "        Args:\n",
        "            channel (ChannelSimulator): Channel simulator\n",
        "            snr_range (np.ndarray): SNR range\n",
        "            polar_code_gen (PolarCodeGenerator): Polar code generator\n",
        "\n",
        "        Returns:\n",
        "            tuple: BER and BLER arrays\n",
        "        \"\"\"\n",
        "        ber_values = []\n",
        "        bler_values = []\n",
        "\n",
        "        for snr in snr_range:\n",
        "            block_errors = 0\n",
        "            bit_errors = 0\n",
        "            total_blocks = 100\n",
        "\n",
        "            for _ in range(total_blocks):\n",
        "                # Generate info bits\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "                # Encode\n",
        "                encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "                # Transmit through channel\n",
        "                received_signal = channel.transmit(encoded_signal, snr)\n",
        "\n",
        "                # Decode\n",
        "                decoded_bits = self.successive_cancellation_decode(received_signal)\n",
        "\n",
        "                # Compute errors\n",
        "                block_error = not np.array_equal(info_bits, decoded_bits[:len(info_bits)])\n",
        "                bit_error = np.sum(info_bits != decoded_bits[:len(info_bits)])\n",
        "\n",
        "                block_errors += block_error\n",
        "                bit_errors += bit_error\n",
        "\n",
        "            # Compute BER and BLER\n",
        "            ber = bit_errors / (total_blocks * len(info_bits))\n",
        "            bler = block_errors / total_blocks\n",
        "\n",
        "            ber_values.append(ber)\n",
        "            bler_values.append(bler)\n",
        "\n",
        "        return np.array(ber_values), np.array(bler_values)\n",
        "\n",
        "  # The main function file\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Comprehensive Polar Code Simulation and Decoder Evaluation\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Global Simulation Parameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 10\n",
        "        BATCH_SIZE = 64\n",
        "        NUM_SAMPLES = 500\n",
        "        SNR_RANGE = np.linspace(0, 10, 10)\n",
        "        NUM_TRIALS = 100\n",
        "\n",
        "        # Device Configuration\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\" Using Device: {device}\")\n",
        "\n",
        "        # Polar Code Generator\n",
        "        #polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        #print(\" Polar Code Generator Initialized\")\n",
        "        #Polar Code Generator Class\n",
        "        class PolarCodeGenerator:\n",
        "            def __init__(self, N, K):\n",
        "                self.N = N\n",
        "                self.K = K\n",
        "\n",
        "            def generate_info_bits(self):\n",
        "                return np.random.randint(2, size=self.K)\n",
        "\n",
        "            def polar_encode(self, info_bits):\n",
        "                codeword = np.zeros(self.N, dtype=np.float32)\n",
        "                codeword[:self.K] = info_bits\n",
        "                return codeword\n",
        "\n",
        "        # Create Polar Code Generator\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        print(\" Polar Code Generator Initialized\")\n",
        "\n",
        "        # Prepare Dataset\n",
        "        def prepare_dataset(polar_code_gen, num_samples):\n",
        "            X, y = [], []\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "                codeword = polar_code_gen.polar_encode(info_bits)\n",
        "                X.append(codeword)\n",
        "                y.append(1 if np.mean(codeword) > 0.5 else 0)\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        # Generate Dataset\n",
        "        X, y = prepare_dataset(polar_code_gen, num_samples=NUM_SAMPLES)\n",
        "        print(f\"Dataset Prepared: X shape {X.shape}, y shape {y.shape}\")\n",
        "\n",
        "        # Split Dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train).to(device)\n",
        "        X_test = torch.FloatTensor(X_test).to(device)\n",
        "        y_train = torch.FloatTensor(y_train).to(device).unsqueeze(1)\n",
        "        y_test = torch.FloatTensor(y_test).to(device).unsqueeze(1)\n",
        "\n",
        "        # Initialize Decoders\n",
        "        rnn_decoder = RNNDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        ml_decoder = MLDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "\n",
        "        # Decoder Training Function\n",
        "        def train_decoder(model, X_train, y_train, epochs=10, batch_size=64):\n",
        "            criterion = nn.BCELoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            train_losses, val_losses = [], []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "\n",
        "                # Shuffle data\n",
        "                indices = torch.randperm(X_train.size(0))\n",
        "                X_batch = X_train[indices]\n",
        "                y_batch = y_train[indices]\n",
        "\n",
        "                for i in range(0, len(X_batch), batch_size):\n",
        "                    batch_X = X_batch[i:i+batch_size]\n",
        "                    batch_y = y_batch[i:i+batch_size]\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                avg_loss = total_loss / (len(X_batch) // batch_size)\n",
        "                train_losses.append(avg_loss)\n",
        "\n",
        "                # Validation\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_outputs = model(X_train)\n",
        "                    val_loss = criterion(val_outputs, y_train)\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n",
        "\n",
        "            return train_losses, val_losses\n",
        "\n",
        "        # Train Decoders\n",
        "        rnn_train_losses, rnn_val_losses = train_decoder(\n",
        "            rnn_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "        ml_train_losses, ml_val_losses = train_decoder(\n",
        "            ml_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # Visualization and Performance Analysis\n",
        "        plt.figure(figsize=(20, 15))\n",
        "\n",
        "        # Training Losses\n",
        "        plt.subplot(2, 3, 1)\n",
        "        plt.plot(rnn_train_losses, label='RNN Decoder Training Loss')\n",
        "        plt.plot(rnn_val_losses, label='RNN Decoder Validation Loss')\n",
        "        plt.title('RNN Decoder Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('RNN_losses.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # ML Decoder Losses\n",
        "        plt.subplot(2, 3, 2)\n",
        "        plt.plot(ml_train_losses, label='ML Decoder Training Loss')\n",
        "        plt.plot(ml_val_losses, label='ML Decoder Validation Loss')\n",
        "        plt.title('ML Decoder Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('ML_losses.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "        # Confusion Matrices\n",
        "        # RNN Decoder Confusion Matrix\n",
        "        plt.subplot(2, 3, 3)\n",
        "        rnn_pred = (rnn_decoder(X_test) > 0.5).float().cpu().numpy()\n",
        "        rnn_cm = confusion_matrix(y_test.cpu().numpy(), rnn_pred)\n",
        "        sns.heatmap(rnn_cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('RNN Decoder\\nConfusion Matrix')\n",
        "\n",
        "        # ML Decoder Confusion Matrix\n",
        "        plt.subplot(2, 3, 4)\n",
        "        ml_pred = (ml_decoder(X_test) > 0.5).float().cpu().numpy()\n",
        "        ml_cm = confusion_matrix(y_test.cpu().numpy(), ml_pred)\n",
        "        sns.heatmap(ml_cm, annot=True, fmt='d', cmap='Greens')\n",
        "        plt.title('ML Decoder\\nConfusion Matrix')\n",
        "\n",
        "        # Performance Evaluation\n",
        "        # Channel Simulators\n",
        "        awgn_channel = ChannelSimulator(channel_type='AWGN')\n",
        "        rayleigh_channel = ChannelSimulator(channel_type='Rayleigh')\n",
        "\n",
        "        # Compute performance for RNN and ML Decoders\n",
        "        rnn_ber_awgn, rnn_bler_awgn = compute_ber_bler(\n",
        "            rnn_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        ml_ber_awgn, ml_bler_awgn = compute_ber_bler(\n",
        "            ml_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "\n",
        "        rnn_ber_rayleigh, rnn_bler_rayleigh = compute_ber_bler(\n",
        "            rnn_decoder, rayleigh_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        ml_ber_rayleigh, ml_bler_rayleigh = compute_ber_bler(\n",
        "            ml_decoder, rayleigh_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "\n",
        "        # Performance Summary Subplot\n",
        "        plt.subplot(2, 3, 5)\n",
        "        performance_summary = f\"\"\"\n",
        "        Performance Summary:\n",
        "        AWGN Channel:\n",
        "        RNN BER: {rnn_ber_awgn[-1]:.2e}\n",
        "        ML BER: {ml_ber_awgn[-1]:.2e}\n",
        "\n",
        "        Rayleigh Channel:\n",
        "        RNN BER: {rnn_ber_rayleigh[-1]:.2e}\n",
        "        ML BER: {ml_ber_rayleigh[-1]:.2e}\n",
        "        \"\"\"\n",
        "        plt.text(0.1, 0.5, performance_summary, fontsize=10,\n",
        "                 verticalalignment='center', horizontalalignment='left')\n",
        "        plt.axis('off')\n",
        "        plt.title('Performance Summary')\n",
        "\n",
        "        # BER/BLER Plots\n",
        "        plt.subplot(2, 3, 6)\n",
        "        plot_performance(\n",
        "            SNR_RANGE,\n",
        "            None,  # No traditional decoder\n",
        "            rnn_decoder,\n",
        "            ml_decoder,\n",
        "            polar_code_gen,\n",
        "            awgn_channel,\n",
        "            rayleigh_channel\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\" Simulation Complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Comprehensive Simulation Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Comprehensive Polar Code Simulation and Decoder Evaluation\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Global Simulation Parameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 10\n",
        "        BATCH_SIZE = 64\n",
        "        NUM_SAMPLES = 500\n",
        "        SNR_RANGE = np.linspace(0, 10, 10)\n",
        "        LIST_SIZES = [1, 8, 16]\n",
        "        NUM_TRIALS = 100\n",
        "\n",
        "        # Device Configuration\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\" Using Device: {device}\")\n",
        "\n",
        "        # 1. Polar Code Generator\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        print(\" Polar Code Generator Initialized\")\n",
        "\n",
        "        # 2. Prepare Dataset\n",
        "        def prepare_dataset(polar_code_gen, num_samples):\n",
        "            X, y = [], []\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "                codeword = polar_code_gen.polar_encode(info_bits)\n",
        "                X.append(codeword)\n",
        "                y.append(1 if np.mean(codeword) > 0.5 else 0)\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        # Generate Dataset\n",
        "        X, y = prepare_dataset(polar_code_gen, num_samples=NUM_SAMPLES)\n",
        "        print(f\"Dataset Prepared: X shape {X.shape}, y shape {y.shape}\")\n",
        "\n",
        "        # 3. Split Dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train).to(device)\n",
        "        X_test = torch.FloatTensor(X_test).to(device)\n",
        "        y_train = torch.FloatTensor(y_train).to(device).unsqueeze(1)\n",
        "        y_test = torch.FloatTensor(y_test).to(device).unsqueeze(1)\n",
        "\n",
        "        # 4. Initialize Decoders\n",
        "        # RNN Decoder\n",
        "        rnn_decoder = RNNDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "\n",
        "        # ML Decoder\n",
        "        ml_decoder = MLDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "\n",
        "        # 5. Decoder Training Function\n",
        "        def train_decoder(model, X_train, y_train, epochs=10, batch_size=64):\n",
        "            criterion = nn.BCELoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            train_losses, val_losses = [], []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "\n",
        "                # Shuffle data\n",
        "                indices = torch.randperm(X_train.size(0))\n",
        "                X_batch = X_train[indices]\n",
        "                y_batch = y_train[indices]\n",
        "\n",
        "                for i in range(0, len(X_batch), batch_size):\n",
        "                    batch_X = X_batch[i:i+batch_size]\n",
        "                    batch_y = y_batch[i:i+batch_size]\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                avg_loss = total_loss / (len(X_batch) // batch_size)\n",
        "                train_losses.append(avg_loss)\n",
        "\n",
        "                # Validation (using training data for simplicity)\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_outputs = model(X_train)\n",
        "                    val_loss = criterion(val_outputs, y_train)\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n",
        "\n",
        "            return train_losses, val_losses\n",
        "\n",
        "        # 6. Train Decoders\n",
        "        # RNN Decoder Training\n",
        "        rnn_train_losses, rnn_val_losses = train_decoder(\n",
        "            rnn_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # ML Decoder Training\n",
        "        ml_train_losses, ml_val_losses = train_decoder(\n",
        "            ml_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # 7. Visualization and Performance Analysis\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # Training Losses\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(rnn_train_losses, label='RNN Decoder')\n",
        "        plt.plot(ml_train_losses, label='ML Decoder')\n",
        "        plt.title('Training Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('rnn_train_losses.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Validation Losses\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(rnn_val_losses, label='RNN Decoder')\n",
        "        plt.plot(ml_val_losses, label='ML Decoder')\n",
        "        plt.title('Validation Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('rnn_ml_val_losses.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # 8. Confusion Matrices\n",
        "        plt.subplot(2, 2, 3)\n",
        "        # RNN Decoder Confusion Matrix\n",
        "        rnn_pred = (rnn_decoder(X_test) > 0.5).float().cpu().numpy()\n",
        "        rnn_cm = confusion_matrix(y_test.cpu().numpy(), rnn_pred)\n",
        "        sns.heatmap(rnn_cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('RNN Decoder\\nConfusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('rnn_confusion_matrix.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        plt.subplot(2, 2, 4)\n",
        "        # ML Decoder Confusion Matrix\n",
        "        ml_pred = (ml_decoder(X_test) > 0.5).float().cpu().numpy()\n",
        "        ml_cm = confusion_matrix(y_test.cpu().numpy(), ml_pred)\n",
        "        sns.heatmap(ml_cm, annot=True, fmt='d', cmap='Greens')\n",
        "        plt.title('ML Decoder\\nConfusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('ml_confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "        # 9. Performance Evaluation\n",
        "        # Channel Simulators\n",
        "        awgn_channel = ChannelSimulator(channel_type='AWGN')\n",
        "        rayleigh_channel = ChannelSimulator(channel_type='Rayleigh')\n",
        "\n",
        "        # Compute performance for RNN and ML Decoders\n",
        "        rnn_ber_awgn, rnn_bler_awgn = compute_ber_bler(\n",
        "            rnn_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        ml_ber_awgn, ml_bler_awgn = compute_ber_bler(\n",
        "            ml_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "\n",
        "        rnn_ber_rayleigh, rnn_bler_rayleigh = compute_ber_bler(\n",
        "            rnn_decoder, rayleigh_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        ml_ber_rayleigh, ml_bler_rayleigh = compute_ber_bler(\n",
        "            ml_decoder, rayleigh_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "\n",
        "        # Plot BER and BLER\n",
        "        plot_performance(\n",
        "            SNR_RANGE,\n",
        "            None,  # No traditional decoder\n",
        "            rnn_decoder,\n",
        "            ml_decoder,\n",
        "            polar_code_gen,\n",
        "            awgn_channel,\n",
        "            rayleigh_channel\n",
        "        )\n",
        "\n",
        "        print(\" Simulation Complete!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 2. Channel Simulator\n",
        "        class ChannelSimulator:\n",
        "            def __init__(self, channel_type='AWGN'):\n",
        "                self.channel_type = channel_type\n",
        "\n",
        "            def add_noise(self, codeword, snr):\n",
        "                noise_std = 10 ** (-snr / 20)\n",
        "                noisy_codeword = codeword + np.random.normal(0, noise_std, codeword.shape)\n",
        "                return noisy_codeword\n",
        "\n",
        "        # 3. Decoder Definitions\n",
        "        class TraditionalDecoder(nn.Module):\n",
        "            def __init__(self, input_size):\n",
        "                super().__init__()\n",
        "                self.linear = nn.Linear(input_size, 1)\n",
        "                self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.sigmoid(self.linear(x))\n",
        "\n",
        "        class RNNDecoder(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
        "                super().__init__()\n",
        "                self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "                self.fc = nn.Linear(hidden_size, 1)\n",
        "                self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "            def forward(self, x):\n",
        "                # Reshape input for LSTM\n",
        "                x = x.unsqueeze(1)\n",
        "                out, _ = self.rnn(x)\n",
        "                return self.sigmoid(self.fc(out[:, -1, :]))\n",
        "\n",
        "        class MLDecoder(nn.Module):\n",
        "            def __init__(self, input_size, hidden_layers=[64, 32]):\n",
        "                super().__init__()\n",
        "                layers = []\n",
        "                prev_size = input_size\n",
        "\n",
        "                for hidden_size in hidden_layers:\n",
        "                    layers.extend([\n",
        "                        nn.Linear(prev_size, hidden_size),\n",
        "                        nn.BatchNorm1d(hidden_size),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.2)\n",
        "                    ])\n",
        "                    prev_size = hidden_size\n",
        "\n",
        "                layers.append(nn.Linear(prev_size, 1))\n",
        "                layers.append(nn.Sigmoid())\n",
        "\n",
        "                self.model = nn.Sequential(*layers)\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.model(x)\n",
        "\n",
        "        # 4. Prepare Dataset\n",
        "        def prepare_dataset(polar_code_gen, num_samples):\n",
        "            X, y = [], []\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "                codeword = polar_code_gen.polar_encode(info_bits)\n",
        "                X.append(codeword)\n",
        "                y.append(1 if np.mean(codeword) > 0.5 else 0)\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        # Create Polar Code Generator\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        print(\" Polar Code Generator Initialized\")\n",
        "\n",
        "        # Generate Dataset\n",
        "        X, y = prepare_dataset(polar_code_gen, num_samples=NUM_SAMPLES)\n",
        "        print(f\"Dataset Prepared: X shape {X.shape}, y shape {y.shape}\")\n",
        "\n",
        "        # Split Dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train).to(device)\n",
        "        X_test = torch.FloatTensor(X_test).to(device)\n",
        "        y_train = torch.FloatTensor(y_train).to(device).unsqueeze(1)\n",
        "        y_test = torch.FloatTensor(y_test).to(device).unsqueeze(1)\n",
        "\n",
        "        # 5. Decoder Training Function\n",
        "        def train_decoder(model, X_train, y_train, epochs=10, batch_size=64):\n",
        "            criterion = nn.BCELoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            train_losses, val_losses = [], []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "\n",
        "                # Shuffle data\n",
        "                indices = torch.randperm(X_train.size(0))\n",
        "                X_batch = X_train[indices]\n",
        "                y_batch = y_train[indices]\n",
        "\n",
        "                for i in range(0, len(X_batch), batch_size):\n",
        "                    batch_X = X_batch[i:i+batch_size]\n",
        "                    batch_y = y_batch[i:i+batch_size]\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                avg_loss = total_loss / (len(X_batch) // batch_size)\n",
        "                train_losses.append(avg_loss)\n",
        "\n",
        "                # Validation (using training data for simplicity)\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_outputs = model(X_train)\n",
        "                    val_loss = criterion(val_outputs, y_train)\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n",
        "\n",
        "            return train_losses, val_losses\n",
        "\n",
        "        # 6. Initialize and Train Decoders\n",
        "        # Traditional Decoder\n",
        "        traditional_decoder = TraditionalDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        traditional_train_losses, traditional_val_losses = train_decoder(\n",
        "            traditional_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # RNN Decoder\n",
        "        rnn_decoder = RNNDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        rnn_train_losses, rnn_val_losses = train_decoder(\n",
        "            rnn_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # ML Decoder\n",
        "        ml_decoder = MLDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        ml_train_losses, ml_val_losses = train_decoder(\n",
        "            ml_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # Rest of the code remains the same as in the previous response...\n",
        "\n",
        "        # Performance Evaluation and Plotting section\n",
        "        # (Keep the previous implementation of performance evaluation and plotting)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        print(\" Dataset Split Completed\")\n",
        "\n",
        "        # 4. Traditional Polar Decoder Performance\n",
        "        traditional_decoder = TraditionalPolarDecoder(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "\n",
        "        # Channel Simulators\n",
        "        awgn_channel = ChannelSimulator(channel_type='AWGN')\n",
        "        rayleigh_channel = ChannelSimulator(channel_type='Rayleigh')\n",
        "\n",
        "        # Compute Traditional Decoder Performance\n",
        "        traditional_ber_awgn, traditional_bler_awgn = traditional_decoder.compute_performance(\n",
        "            awgn_channel,\n",
        "            SNR_RANGE,\n",
        "            polar_code_gen\n",
        "        )\n",
        "\n",
        "        traditional_ber_rayleigh, traditional_bler_rayleigh = traditional_decoder.compute_performance(\n",
        "            rayleigh_channel,\n",
        "            SNR_RANGE,\n",
        "            polar_code_gen\n",
        "        )\n",
        "\n",
        "\n",
        "        # Remaining code for ML Decoder, performance computation, and visualization\n",
        "        # would follow in the same manner as previous implementations[Previous code remains the same]\n",
        "        # Hyperparameters\n",
        "        # 5. RNN Decoder Training\n",
        "\n",
        "\n",
        "        # 6. Training Performance and Error Performance Visualization\n",
        "        plt.figure(figsize=(20, 15))\n",
        "\n",
        "        # Combined Training and Validation Losses\n",
        "        plt.subplot(2, 3, 1)\n",
        "        plt.plot(rnn_train_losses, label='RNN Training Loss', color='blue')\n",
        "        plt.plot(rnn_val_losses, label='RNN Validation Loss', color='red')\n",
        "        plt.plot(ml_train_losses, label='ML Training Loss', color='green')\n",
        "        plt.plot(ml_val_losses, label='ML Validation Loss', color='orange')\n",
        "        plt.title('Combined Training and Validation Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('combined_losses.png')\n",
        "        plt.close()\n",
        "        print(\" Combined Losses Saved\")\n",
        "\n",
        "\n",
        "\n",
        "        # Prepare results dictionary for BER/BLER\n",
        "        performance_results = {\n",
        "            'Traditional': {\n",
        "                'ber_awgn': traditional_ber_awgn,\n",
        "                'bler_awgn': traditional_bler_awgn,\n",
        "                'ber_rayleigh': traditional_ber_rayleigh,\n",
        "                'bler_rayleigh': traditional_bler_rayleigh\n",
        "            },\n",
        "            'RNN': {\n",
        "                'ber_awgn': rnn_ber_awgn,\n",
        "                'bler_awgn': rnn_bler_awgn,\n",
        "                'ber_rayleigh': rnn_ber_rayleigh,\n",
        "                'bler_rayleigh': rnn_bler_rayleigh\n",
        "            },\n",
        "            'ML': {\n",
        "                'ber_awgn': ml_ber_awgn,\n",
        "                'bler_awgn': ml_bler_awgn,\n",
        "                'ber_rayleigh': ml_ber_rayleigh,\n",
        "                'bler_rayleigh': ml_bler_rayleigh\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # BER - AWGN Channel\n",
        "        plt.subplot(2, 3, 4)\n",
        "        for decoder in ['Traditional', 'RNN', 'ML']:\n",
        "            plt.semilogy(\n",
        "                SNR_RANGE,\n",
        "                performance_results[decoder]['ber_awgn'],\n",
        "                label=f'{decoder} BER',\n",
        "                marker='o'\n",
        "            )\n",
        "        plt.title('BER - AWGN Channel')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('Bit Error Rate')\n",
        "        plt.ylim(1e-5, 1e0)\n",
        "        plt.legend()\n",
        "        plt.grid(True, which='both', ls='-', alpha=0.5)\n",
        "\n",
        "        # BLER - AWGN Channel\n",
        "        plt.subplot(2, 3, 5)\n",
        "        for decoder in ['Traditional', 'RNN', 'ML']:\n",
        "            plt.semilogy(\n",
        "                SNR_RANGE,\n",
        "                performance_results[decoder]['bler_awgn'],\n",
        "                label=f'{decoder} BLER',\n",
        "                marker='s'\n",
        "            )\n",
        "        plt.title('BLER - AWGN Channel')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('Block Error Rate')\n",
        "        plt.ylim(1e-5, 1e0)\n",
        "        plt.legend()\n",
        "        plt.grid(True, which='both', ls='-', alpha=0.5)\n",
        "\n",
        "        # Rayleigh Channel BER\n",
        "        plt.subplot(2, 3, 6)\n",
        "        for decoder in ['Traditional', 'RNN', 'ML']:\n",
        "            plt.semilogy(\n",
        "                SNR_RANGE,\n",
        "                performance_results[decoder]['ber_rayleigh'],\n",
        "                label=f'{decoder} BER',\n",
        "                marker='^'\n",
        "            )\n",
        "        plt.title('BER - Rayleigh Channel')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('Bit Error Rate')\n",
        "        plt.ylim(1e-5, 1e0)\n",
        "        plt.legend()\n",
        "        plt.grid(True, which='both', ls='-', alpha=0.5)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('comprehensive_performance.png')\n",
        "        plt.close()\n",
        "        print(\" Comprehensive Performance Plots Saved\")\n",
        "\n",
        "        # Confusion Matrix Visualization\n",
        "        plt.figure(figsize=(15, 6))\n",
        "\n",
        "        # Traditional Decoder Confusion Matrix\n",
        "        plt.subplot(1, 3, 1)\n",
        "        traditional_predictions = traditional_decoder.predict(X_test.cpu().numpy())\n",
        "        traditional_pred_classes = (traditional_predictions > 0.5).astype(int)\n",
        "        traditional_cm = confusion_matrix(y_test.cpu().numpy(), traditional_pred_classes)\n",
        "        sns.heatmap(traditional_cm, annot=True, fmt='d', cmap='Purples')\n",
        "        plt.title('Traditional Decoder\\nConfusion Matrix')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "\n",
        "        # RNN Decoder Confusion Matrix\n",
        "        plt.subplot(1, 3, 2)\n",
        "        rnn_predictions = rnn_trainer.predict(X_test.cpu().numpy())\n",
        "        rnn_pred_classes = (rnn_predictions > 0.5).astype(int)\n",
        "        rnn_cm = confusion_matrix(y_test.cpu().numpy(), rnn_pred_classes)\n",
        "        sns.heatmap(rnn_cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('RNN Decoder\\nConfusion Matrix')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "\n",
        "        # ML Decoder Confusion Matrix\n",
        "        plt.subplot(1, 3, 3)\n",
        "        ml_predictions = ml_trainer.predict(X_test.cpu().numpy())\n",
        "        ml_pred_classes = (ml_predictions > 0.5).astype(int)\n",
        "        ml_cm = confusion_matrix(y_test.cpu().numpy(), ml_pred_classes)\n",
        "        sns.heatmap(ml_cm, annot=True, fmt='d', cmap='Greens')\n",
        "        plt.title('ML Decoder\\nConfusion Matrix')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('decoder_confusion_matrices.png')\n",
        "        plt.close()\n",
        "        print(\" Confusion Matrices Saved\")\n",
        "\n",
        "        # Classification Reports\n",
        "        print(\"Classification Reports:\")\n",
        "        print(\"Traditional Decoder Classification Report:\")\n",
        "        print(classification_report(\n",
        "            y_test.cpu().numpy(),\n",
        "            traditional_pred_classes\n",
        "        ))\n",
        "\n",
        "        print(\"RNN Decoder Classification Report:\")\n",
        "        print(classification_report(\n",
        "            y_test.cpu().numpy(),\n",
        "            rnn_pred_classes\n",
        "        ))\n",
        "\n",
        "        print(\"ML Decoder Classification Report:\")\n",
        "        print(classification_report(\n",
        "            y_test.cpu().numpy(),\n",
        "            ml_pred_classes\n",
        "        ))\n",
        "\n",
        "        print(\" Simulation Complete!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Device Configuration\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\" Using Device: {device}\")\n",
        "\n",
        "        # 1. Polar Code Generator\n",
        "        class PolarCodeGenerator:\n",
        "            def __init__(self, N, K):\n",
        "                self.N = N\n",
        "                self.K = K\n",
        "\n",
        "            def generate_info_bits(self):\n",
        "                return np.random.randint(2, size=self.K)\n",
        "\n",
        "            def polar_encode(self, info_bits):\n",
        "                # Simplified encoding\n",
        "                codeword = np.zeros(self.N, dtype=np.float32)\n",
        "                codeword[:self.K] = info_bits\n",
        "                return codeword\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        print(\" Polar Code Generator Initialized\")\n",
        "\n",
        "        # 2. Prepare Dataset\n",
        "        def prepare_dataset(polar_code_gen, num_samples):\n",
        "            X, y = [], []\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "                codeword = polar_code_gen.polar_encode(info_bits)\n",
        "                X.append(codeword)\n",
        "                y.append(1 if np.mean(codeword) > 0.5 else 0)\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        # Generate Dataset\n",
        "        X, y = prepare_dataset(polar_code_gen, num_samples=NUM_SAMPLES)\n",
        "        print(f\"Dataset Prepared: X shape {X.shape}, y shape {y.shape}\")\n",
        "\n",
        "        # 3. Split Dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train).to(device)\n",
        "        X_test = torch.FloatTensor(X_test).to(device)\n",
        "        y_train = torch.FloatTensor(y_train).to(device).unsqueeze(1)\n",
        "        y_test = torch.FloatTensor(y_test).to(device).unsqueeze(1)\n",
        "\n",
        "        # 4. Decoder Definitions\n",
        "        class TraditionalDecoder(nn.Module):\n",
        "            def __init__(self, input_size):\n",
        "                super().__init__()\n",
        "                self.linear = nn.Linear(input_size, 1)\n",
        "                self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.sigmoid(self.linear(x))\n",
        "\n",
        "        class RNNDecoder(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
        "                super().__init__()\n",
        "                self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "                self.fc = nn.Linear(hidden_size, 1)\n",
        "                self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "            def forward(self, x):\n",
        "                # Reshape input for LSTM\n",
        "                x = x.unsqueeze(1)\n",
        "                out, _ = self.rnn(x)\n",
        "                return self.sigmoid(self.fc(out[:, -1, :]))\n",
        "\n",
        "        class MLDecoder(nn.Module):\n",
        "            def __init__(self, input_size, hidden_layers=[64, 32]):\n",
        "                super().__init__()\n",
        "                layers = []\n",
        "                prev_size = input_size\n",
        "\n",
        "                for hidden_size in hidden_layers:\n",
        "                    layers.extend([\n",
        "                        nn.Linear(prev_size, hidden_size),\n",
        "                        nn.BatchNorm1d(hidden_size),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.2)\n",
        "                    ])\n",
        "                    prev_size = hidden_size\n",
        "\n",
        "                layers.append(nn.Linear(prev_size, 1))\n",
        "                layers.append(nn.Sigmoid())\n",
        "\n",
        "                self.model = nn.Sequential(*layers)\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.model(x)\n",
        "\n",
        "        # 5. Decoder Training Function\n",
        "        def train_decoder(model, X_train, y_train, epochs=10, batch_size=64):\n",
        "            criterion = nn.BCELoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            train_losses, val_losses = [], []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "\n",
        "                # Shuffle data\n",
        "                indices = torch.randperm(X_train.size(0))\n",
        "                X_batch = X_train[indices]\n",
        "                y_batch = y_train[indices]\n",
        "\n",
        "                for i in range(0, len(X_batch), batch_size):\n",
        "                    batch_X = X_batch[i:i+batch_size]\n",
        "                    batch_y = y_batch[i:i+batch_size]\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                avg_loss = total_loss / (len(X_batch) // batch_size)\n",
        "                train_losses.append(avg_loss)\n",
        "\n",
        "                # Validation (using training data for simplicity)\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_outputs = model(X_train)\n",
        "                    val_loss = criterion(val_outputs, y_train)\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n",
        "\n",
        "            return train_losses, val_losses\n",
        "\n",
        "        # 6. Initialize and Train Decoders\n",
        "        # Traditional Decoder\n",
        "        traditional_decoder = TraditionalDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        traditional_train_losses, traditional_val_losses = train_decoder(\n",
        "            traditional_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # RNN Decoder\n",
        "        rnn_decoder = RNNDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        rnn_train_losses, rnn_val_losses = train_decoder(\n",
        "            rnn_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # ML Decoder\n",
        "        ml_decoder = MLDecoder(input_size=BLOCK_LENGTH).to(device)\n",
        "        ml_train_losses, ml_val_losses = train_decoder(\n",
        "            ml_decoder, X_train, y_train, epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # 7. Visualization and Performance Analysis\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # Training Losses\n",
        "         # Modify the confusion matrix plotting section\n",
        "        plt.subplot(2, 3, 1)\n",
        "        # Traditional Decoder Confusion Matrix\n",
        "        traditional_pred = traditional_decoder.predict(X_test.cpu().numpy())\n",
        "        traditional_pred_classes = (traditional_pred > 0.5).astype(int)\n",
        "        traditional_cm = confusion_matrix(y_test.cpu().numpy(), traditional_pred_classes)\n",
        "        sns.heatmap(traditional_cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Traditional Decoder\\nConfusion Matrix')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "\n",
        "        # Similar modifications for RNN and ML decoders\n",
        "        # ... (apply the same pattern to other decoder confusion matrices)\n",
        "\n",
        "\n",
        "        # Validation Losses\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(traditional_val_losses, label='Traditional Decoder')\n",
        "        plt.plot(rnn_val_losses, label='RNN Decoder')\n",
        "        plt.plot(ml_val_losses, label='ML Decoder')\n",
        "        plt.title('Validation Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\" Simulation Complete!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Previous decoder implementations remain the same\n",
        "\n",
        "        # Additional helper function for performance evaluation\n",
        "        def compute_ber_bler(decoder, channel, snr_range, polar_code_gen, num_trials=100):\n",
        "            ber_results = []\n",
        "            bler_results = []\n",
        "\n",
        "            for snr in snr_range:\n",
        "                ber_snr, bler_snr = [], []\n",
        "\n",
        "                for _ in range(num_trials):\n",
        "                    # Generate test sample\n",
        "                    info_bits = polar_code_gen.generate_info_bits()\n",
        "                    codeword = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "                    # Add channel noise\n",
        "                    noisy_codeword = channel.add_noise(codeword, snr)\n",
        "\n",
        "                    # Convert to tensor\n",
        "                    noisy_tensor = torch.FloatTensor(noisy_codeword).to(device).unsqueeze(0)\n",
        "\n",
        "                    # Decode\n",
        "                    with torch.no_grad():\n",
        "                        decoded_prob = decoder(noisy_tensor)\n",
        "                        decoded_bit = (decoded_prob > 0.5).float().cpu().numpy()[0]\n",
        "\n",
        "                    # Compute BER and BLER\n",
        "                    ber = np.mean(np.abs(decoded_bit - info_bits))\n",
        "                    bler = 1 if ber > 0 else 0\n",
        "\n",
        "                    ber_snr.append(ber)\n",
        "                    bler_snr.append(bler)\n",
        "\n",
        "                ber_results.append(np.mean(ber_snr))\n",
        "                bler_results.append(np.mean(bler_snr))\n",
        "\n",
        "            return ber_results, bler_results\n",
        "\n",
        "        # Existing code for dataset preparation and decoder training...\n",
        "\n",
        "\n",
        "        # Performance Evaluation\n",
        "        # Prepare channels\n",
        "        awgn_channel = ChannelSimulator(channel_type='AWGN')\n",
        "        rayleigh_channel = ChannelSimulator(channel_type='Rayleigh')\n",
        "\n",
        "        # Compute BER and BLER for different decoders and channels\n",
        "        traditional_ber_awgn, traditional_bler_awgn = compute_ber_bler(\n",
        "            traditional_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        rnn_ber_awgn, rnn_bler_awgn = compute_ber_bler(\n",
        "            rnn_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "        ml_ber_awgn, ml_bler_awgn = compute_ber_bler(\n",
        "            ml_decoder, awgn_channel, SNR_RANGE, polar_code_gen\n",
        "        )\n",
        "\n",
        "\n",
        "        # Classification Reports\n",
        "        plt.subplot(2, 3, 6)\n",
        "        plt.text(0.1, 0.9, \"Classification Reports:\", fontsize=12, fontweight='bold')\n",
        "        plt.text(0.1, 0.8, \"Traditional Decoder:\", fontsize=10)\n",
        "        plt.text(0.1, 0.7, classification_report(y_test.cpu().numpy(), traditional_pred), fontsize=8)\n",
        "        plt.text(0.1, 0.4, \"RNN Decoder:\", fontsize=10)\n",
        "        plt.text(0.1, 0.3, classification_report(y_test.cpu().numpy(), rnn_pred), fontsize=8)\n",
        "        plt.text(0.1, 0.0, \"ML Decoder:\", fontsize=10)\n",
        "        plt.text(0.1, -0.1, classification_report(y_test.cpu().numpy(), ml_pred), fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Comprehensive Simulation Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxoTWtuA2Ar",
        "outputId": "e7025585-f0c5-4f7c-e66b-9ab639b544c8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.11/dist-packages (0.9.7)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.11/dist-packages (0.9.7)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.11/dist-packages (0.9.7)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.11/dist-packages (0.9.7)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.11/dist-packages (0.9.7)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            " Using Device: cuda\n",
            " Polar Code Generator Initialized\n",
            "Dataset Prepared: X shape (500, 128), y shape (500,)\n",
            " Comprehensive Simulation Error: input.size(-1) must be equal to input_size. Expected 128, got 4\n",
            " Using Device: cuda\n",
            " Comprehensive Simulation Error: cannot access local variable 'PolarCodeGenerator' where it is not associated with a value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-55-7b670bc4bc02>\", line 2074, in main\n",
            "    rnn_train_losses, rnn_val_losses = train_decoder(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-55-7b670bc4bc02>\", line 2052, in train_decoder\n",
            "    outputs = model(batch_X)\n",
            "              ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-55-7b670bc4bc02>\", line 1185, in forward\n",
            "    lstm_out, _ = self.lstm(x)\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1101, in forward\n",
            "    self.check_forward_args(input, hx, batch_sizes)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1002, in check_forward_args\n",
            "    self.check_input(input, batch_sizes)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 314, in check_input\n",
            "    raise RuntimeError(\n",
            "RuntimeError: input.size(-1) must be equal to input_size. Expected 128, got 4\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-55-7b670bc4bc02>\", line 2213, in main\n",
            "    polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
            "                     ^^^^^^^^^^^^^^^^^^\n",
            "UnboundLocalError: cannot access local variable 'PolarCodeGenerator' where it is not associated with a value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7R917Ey4U4H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}