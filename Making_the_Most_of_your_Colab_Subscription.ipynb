{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k4tWd-7jWSxB",
        "outputId": "c2384a61-aff0-48bc-91d5-3bdcea176104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "lg2hV3-LWg0d",
        "outputId": "c7c4f912-e5e5-4d68-dc4d-02e5f92d6d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6326041b-0510-4084-9ae4-1785d059de6b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6326041b-0510-4084-9ae4-1785d059de6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving making_the_most_of_your_colab_subscription (15).py to making_the_most_of_your_colab_subscription (15).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on May 23, 2025 12.21 PM\n",
        "# Updates code script\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Device Configuration\n",
        "# Fix: Removed the extra '.cuda' from torch.cuda.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # The original code returned (received_signal > 0).astype(float) which converts\n",
        "            # received signal to hard decisions (0 or 1). This is typically done *after*\n",
        "            # decoding. For an RNN decoder, you usually feed the *soft* received signal\n",
        "            # (LLRs or just the raw received values) to extract more information.\n",
        "            # Let's return the raw received signal instead of hard decisions.\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound (Union Bound) might be misleading.\n",
        "            # Let's return BEP and a placeholder for BLER for now.\n",
        "            bler = 1 - (1 - bep) ** block_length # This is a very loose upper bound (Union Bound)\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        # Adjusted the last layer to have output_size neurons\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128), # Increased layer size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2), # Added dropout for regularization\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid() # Sigmoid for multi-label binary classification (each bit is independent)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x) # Output shape: [batch_size, output_size]\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        # Use BCELoss for multi-label binary classification\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        # No need for _preprocess_tensors anymore, handle preprocessing in main\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        # Split data into training and validation sets using TensorDataset and DataLoader\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        # The model outputs probabilities for each bit.\n",
        "        # For prediction, we threshold these probabilities (e.g., > 0.5) to get binary predictions.\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, num_trials):\n",
        "    # 'List size' is not applicable to this RNN decoder, using a placeholder.\n",
        "    performance_results = {'RNN Decoder': {'BER': [], 'BLER': []}}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "        X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "        # Convert y to a PyTorch tensor before passing to predict (although predict handles numpy too)\n",
        "        y_tensor = torch.FloatTensor(y)\n",
        "\n",
        "        predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "        actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "        ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "        performance_results['RNN Decoder']['BER'].append(ber)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        bler = block_errors / num_trials\n",
        "        performance_results['RNN Decoder']['BLER'].append(bler)\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 12)) # Adjusted figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    # Iterate through the decoder types (currently just 'RNN Decoder')\n",
        "    for decoder_name, results in performance_results.items():\n",
        "        plt.plot(snr_range, results['BER'], label=decoder_name)\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BER\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    # Iterate through the decoder types (currently just 'RNN Decoder')\n",
        "    for decoder_name, results in performance_results.items():\n",
        "        plt.plot(snr_range, results['BLER'], label=decoder_name)\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BLER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BLER\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        " # part six\n",
        "#latest main\n",
        "def main():\n",
        "    try:\n",
        "        BLOCK_LENGTH = 32\n",
        "        INFO_BITS = 16\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 10000 # Increased training samples\n",
        "        NUM_TRIALS_PERF = 2000  # Number of trials (blocks) for performance comparison at each SNR\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11) # More points for smoother curve\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 11) # More points for smoother curve\n",
        "        # LIST_SIZES is no longer directly used by the RNN, but kept for context if other decoders are added\n",
        "        LIST_SIZES = [1, 4, 8]\n",
        "\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        results = {}\n",
        "        channels = {\n",
        "            'AWGN': EnhancedChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': EnhancedChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        for channel_name, channel in channels.items():\n",
        "            logging.info(f\"Analyzing {channel_name} Channel\")\n",
        "            # Prepare dataset for training and validation\n",
        "            logging.info(f\"Generating training data ({NUM_SAMPLES_TRAIN} samples) for {channel_name} at SNR=5dB\")\n",
        "            # Train at a fixed moderate SNR, evaluate performance across a range\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type=channel_name)\n",
        "\n",
        "            # Convert numpy arrays to PyTorch tensors\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            y_tensor = torch.FloatTensor(y) # y_tensor shape: [num_samples, K]\n",
        "\n",
        "            # Flatten input features for the FCNN-based decoder\n",
        "            X_tensor_flat = X_tensor.view(X_tensor.shape[0], -1) # Shape [num_samples, N]\n",
        "\n",
        "            # No need to split y_tensor into binary labels, keep its original shape [num_samples, K]\n",
        "            # The BCELoss will expect predictions of shape [batch_size, K] and targets of shape [batch_size, K]\n",
        "\n",
        "            # Verify tensor shapes before training\n",
        "            print(\"\\nðŸ”¬ Processed Tensor Shapes (Training):\")\n",
        "            print(f\"X_tensor_flat shape: {X_tensor_flat.shape}\")\n",
        "            print(f\"y_tensor shape: {y_tensor.shape}\")\n",
        "\n",
        "            # Calculate the input size for the RNN based on the flattened data\n",
        "            input_feature_size = X_tensor_flat.size(1) # This will be N (BLOCK_LENGTH)\n",
        "            output_size = INFO_BITS # The RNN should output K bits\n",
        "            print(f\"Calculated input feature size: {input_feature_size}\")\n",
        "            print(f\"Calculated output size (info bits): {output_size}\")\n",
        "\n",
        "\n",
        "            # Enhanced RNN Decoder (now correctly outputs K bits)\n",
        "            rnn_model = EnhancedRNNDecoder(input_size=input_feature_size, output_size=output_size)\n",
        "            rnn_trainer = DecoderTrainer(rnn_model)\n",
        "\n",
        "            logging.info(f\"Starting training for {channel_name} Channel RNN Decoder\")\n",
        "            # Train the RNN Decoder with multi-bit labels\n",
        "            # Pass the flattened X and original y tensors\n",
        "            train_losses, val_losses = rnn_trainer.train(X_tensor_flat, y_tensor, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "            logging.info(f\"Finished training for {channel_name} Channel RNN Decoder\")\n",
        "\n",
        "\n",
        "            # Perform performance comparison across SNR range\n",
        "            snr_range = SNR_RANGE_AWGN if channel_name == 'AWGN' else SNR_RANGE_RAYLEIGH\n",
        "            logging.info(f\"Evaluating performance for {channel_name} Channel across SNR range: {snr_range}\")\n",
        "\n",
        "            # Call the modified performance_comparison\n",
        "            # Note: The 'list_sizes' parameter is not used by the RNN performance comparison,\n",
        "            # but kept for function signature compatibility if needed later for other decoders.\n",
        "            performance_results = performance_comparison(\n",
        "                rnn_trainer, polar_code_gen, snr_range, channel_name, NUM_TRIALS_PERF\n",
        "            )\n",
        "            logging.info(f\"Finished performance evaluation for {channel_name} Channel\")\n",
        "\n",
        "\n",
        "            # Plotting Confusion Matrix for the test set\n",
        "            # First, prepare a separate test set for confusion matrix visualization\n",
        "            # Use a moderate SNR, e.g., 3dB, and a reasonable number of samples\n",
        "            logging.info(f\"Generating test data ({NUM_TRIALS_PERF} samples) for Confusion Matrix at SNR=3dB for {channel_name}\")\n",
        "            X_test_cm, y_test_cm = prepare_polar_dataset(polar_code_gen, num_samples=NUM_TRIALS_PERF, snr_db=3.0, channel_type=channel_name)\n",
        "            X_test_cm_tensor = torch.FloatTensor(X_test_cm).view(X_test_cm.shape[0], -1)\n",
        "            y_test_cm_tensor = torch.FloatTensor(y_test_cm) # Keep original shape [num_samples, K]\n",
        "\n",
        "\n",
        "            predictions_test = rnn_trainer.predict(X_test_cm_tensor) # predictions_test shape: [num_samples, K]\n",
        "            actual_labels_test = y_test_cm_tensor.numpy() # actual_labels_test shape: [num_samples, K]\n",
        "\n",
        "            # To plot a single confusion matrix, we need to flatten the predictions and actual labels\n",
        "            # This treats each predicted bit as an independent classification outcome.\n",
        "            predictions_flat = predictions_test.flatten()\n",
        "            actual_labels_flat = actual_labels_test.flatten()\n",
        "\n",
        "            # Calculate and display confusion matrix\n",
        "            logging.info(f\"Plotting Confusion Matrix for {channel_name} Channel Test Set\")\n",
        "            cm = confusion_matrix(actual_labels_flat, predictions_flat)\n",
        "            ConfusionMatrixDisplay(cm, display_labels=[0, 1]).plot() # Specify display_labels\n",
        "            plt.title(f'Confusion Matrix - {channel_name}')\n",
        "            plt.xlabel('Predicted label (All Info Bits)')\n",
        "            plt.ylabel('True label (All Info Bits)')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Plot comprehensive analysis (training loss, BER, BLER)\n",
        "            logging.info(f\"Plotting performance analysis for {channel_name} Channel\")\n",
        "            plot_comprehensive_analysis(\n",
        "                 train_losses, val_losses, performance_results, snr_range, channel_name\n",
        "            )\n",
        "\n",
        "\n",
        "            results[channel_name] = {\n",
        "                'decoder': rnn_trainer,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'performance': performance_results\n",
        "            }\n",
        "\n",
        "        logging.info(\"ðŸŽ‰ Simulation Complete!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Updates code script\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%(Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Return the raw received signal instead of hard decisions for RNN input\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound might be misleading.\n",
        "            # Using a very loose upper bound (Union Bound)\n",
        "            bler = 1 - (1 - bep) ** block_length\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "# This function will now evaluate the same RNN decoder but store results keyed by 'list_size' labels.\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    # Initialize performance results dictionary to store results for each list size label\n",
        "    performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "        X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "        predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "        actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "        ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        bler = block_errors / num_trials\n",
        "\n",
        "        # Store the calculated BER and BLER for EACH specified list size label.\n",
        "        # Note: The values are the same because it's the same RNN performance being measured.\n",
        "        for list_size in list_sizes:\n",
        "            performance_results[list_size]['BER'].append(ber)\n",
        "            performance_results[list_size]['BLER'].append(bler)\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 15)) # Increased figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BLER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BLER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.yscale('log')\n",
        "     # Adjust ylim for BLER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "\n",
        "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "    plt.show()\n",
        "######################################################################################\n",
        "\n",
        "#latest plot functions\n",
        "# Updates code script\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "# Fix: Corrected format string for datefmt\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Return the raw received signal instead of hard decisions for RNN input\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound might be misleading.\n",
        "            # Using a very loose upper bound (Union Bound)\n",
        "            bler = 1 - (1 - bep) ** block_length\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "# This function will now evaluate the same RNN decoder but store results keyed by 'list_size' labels.\n",
        "#def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    # Initialize performance results dictionary to store results for each list size label\n",
        " #   performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "  #  channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "   # for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "    #    X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "     #   predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "      #  actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "       # ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        #block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        #bler = block_errors / num_trials\n",
        "\n",
        "        # Store the calculated BER and BLER for EACH specified list size label.\n",
        "        # Note: The values are the same because it's the same RNN performance being measured.\n",
        "        #for list_size in list_sizes:\n",
        "         #   performance_results[list_size]['BER'].append(ber)\n",
        "          #  performance_results[list_size]['BLER'].append(bler)\n",
        "\n",
        "    #return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 15)) # Increased figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BLER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BLER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.yscale('log')\n",
        "     # Adjust ylim for BLER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "\n",
        "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "    plt.show()\n",
        "####################################################\n",
        "# another trial to have all plots\n",
        "\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for list_size in list_sizes:\n",
        "        for snr_db in snr_range:\n",
        "            # Here, introduce any logic specific to list_size\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "            # Example: Adjust how predictions are made or interpreted based on list size\n",
        "            predictions = rnn_trainer.predict(X)\n",
        "\n",
        "            actual_labels = y\n",
        "            ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "            block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "            bler = block_errors / num_trials\n",
        "\n",
        "            performance_results[list_size]['BER'].append(ber)\n",
        "            performance_results[list_size]['BLER'].append(bler)\n",
        "            print(f\"List Size: {list_size}, SNR: {snr_db}, BER: {ber}, BLER: {bler}\")\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "####################################################\n",
        "\n",
        " # part six\n",
        "#latest main\n",
        "#latest main\n",
        "def main():\n",
        "    try:\n",
        "        BLOCK_LENGTH = 32\n",
        "        INFO_BITS = 16\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 10000 # Increased training samples\n",
        "        NUM_TRIALS_PERF = 2000  # Number of trials (blocks) for performance comparison at each SNR\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11) # More points for smoother curve\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 11) # More points for smoother curve\n",
        "        LIST_SIZES = [1, 4, 8] # List sizes to use for plotting labels\n",
        "\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        results = {}\n",
        "        channels = {\n",
        "            'AWGN': EnhancedChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': EnhancedChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        for channel_name, channel in channels.items():\n",
        "            logging.info(f\"Analyzing {channel_name} Channel\")\n",
        "            # Prepare dataset for training and validation\n",
        "            logging.info(f\"Generating training data ({NUM_SAMPLES_TRAIN} samples) for {channel_name} at SNR=5dB\")\n",
        "            # Train at a fixed moderate SNR, evaluate performance across a range\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type=channel_name)\n",
        "\n",
        "            # Convert numpy arrays to PyTorch tensors\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            y_tensor = torch.FloatTensor(y) # y_tensor shape: [num_samples, K]\n",
        "\n",
        "            # Flatten input features for the FCNN-based decoder\n",
        "            X_tensor_flat = X_tensor.view(X_tensor.shape[0], -1) # Shape [num_samples, N]\n",
        "\n",
        "            # No need to split y_tensor into binary labels, keep its original shape [num_samples, K]\n",
        "            # The BCELoss will expect predictions of shape [batch_size, K] and targets of shape [batch_size, K]\n",
        "\n",
        "            # Verify tensor shapes before training\n",
        "            print(\"\\nðŸ”¬ Processed Tensor Shapes (Training):\")\n",
        "            print(f\"X_tensor_flat shape: {X_tensor_flat.shape}\")\n",
        "            print(f\"y_tensor shape: {y_tensor.shape}\")\n",
        "\n",
        "            # Calculate the input size for the RNN based on the flattened data\n",
        "            input_feature_size = X_tensor_flat.size(1) # This will be N (BLOCK_LENGTH)\n",
        "            output_size = INFO_BITS # The RNN should output K bits\n",
        "            print(f\"Calculated input feature size: {input_feature_size}\")\n",
        "            print(f\"Calculated output size (info bits): {output_size}\")\n",
        "\n",
        "\n",
        "            # Enhanced RNN Decoder (now correctly outputs K bits)\n",
        "            rnn_model = EnhancedRNNDecoder(input_size=input_feature_size, output_size=output_size)\n",
        "            rnn_trainer = DecoderTrainer(rnn_model)\n",
        "\n",
        "            logging.info(f\"Starting training for {channel_name} Channel RNN Decoder\")\n",
        "            # Train the RNN Decoder with multi-bit labels\n",
        "            # Pass the flattened X and original y tensors\n",
        "            train_losses, val_losses = rnn_trainer.train(X_tensor_flat, y_tensor, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "            logging.info(f\"Finished training for {channel_name} Channel RNN Decoder\")\n",
        "\n",
        "\n",
        "            # Perform performance comparison across SNR range\n",
        "            snr_range = SNR_RANGE_AWGN if channel_name == 'AWGN' else SNR_RANGE_RAYLEIGH\n",
        "            logging.info(f\"Evaluating performance for {channel_name} Channel across SNR range: {snr_range}\")\n",
        "\n",
        "            # Call the modified performance_comparison\n",
        "            # This will run the RNN decoder performance once and store results under multiple list_size keys.\n",
        "            performance_results = performance_comparison(\n",
        "                rnn_trainer, polar_code_gen, snr_range, channel_name, LIST_SIZES, NUM_TRIALS_PERF\n",
        "            )\n",
        "            logging.info(f\"Finished performance evaluation for {channel_name} Channel\")\n",
        "\n",
        "\n",
        "            # Plotting Confusion Matrix for the test set\n",
        "            # First, prepare a separate test set for confusion matrix visualization\n",
        "            # Use a moderate SNR, e.g., 3dB, and a reasonable number of samples\n",
        "            logging.info(f\"Generating test data ({NUM_TRIALS_PERF} samples) for Confusion Matrix at SNR=3dB for {channel_name}\")\n",
        "            X_test_cm, y_test_cm = prepare_polar_dataset(polar_code_gen, num_samples=NUM_TRIALS_PERF, snr_db=3.0, channel_type=channel_name)\n",
        "            X_test_cm_tensor = torch.FloatTensor(X_test_cm).view(X_test_cm.shape[0], -1)\n",
        "            y_test_cm_tensor = torch.FloatTensor(y_test_cm) # Keep original shape [num_samples, K]\n",
        "\n",
        "\n",
        "            predictions_test = rnn_trainer.predict(X_test_cm_tensor) # predictions_test shape: [num_samples, K]\n",
        "            actual_labels_test = y_test_cm_tensor.numpy() # actual_labels_test shape: [num_samples, K]\n",
        "\n",
        "            # To plot a single confusion matrix, we need to flatten the predictions and actual labels\n",
        "            # This treats each predicted bit as an independent classification outcome.\n",
        "            predictions_flat = predictions_test.flatten()\n",
        "            actual_labels_flat = actual_labels_test.flatten()\n",
        "\n",
        "            # Calculate and display confusion matrix\n",
        "            logging.info(f\"Plotting Confusion Matrix for {channel_name} Channel Test Set\")\n",
        "            cm = confusion_matrix(actual_labels_flat, predictions_flat)\n",
        "            ConfusionMatrixDisplay(cm, display_labels=[0, 1]).plot() # Specify display_labels\n",
        "            plt.title(f'Confusion Matrix - {channel_name}')\n",
        "            plt.xlabel('Predicted label (All Info Bits)')\n",
        "            plt.ylabel('True label (All Info Bits)')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Plot comprehensive analysis (training loss, BER, BLER)\n",
        "            logging.info(f\"Plotting performance analysis for {channel_name} Channel\")\n",
        "            plot_comprehensive_analysis(\n",
        "                 train_losses, val_losses, performance_results, snr_range, channel_name\n",
        "            )\n",
        "\n",
        "\n",
        "            results[channel_name] = {\n",
        "                'decoder': rnn_trainer,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'performance': performance_results\n",
        "            }\n",
        "\n",
        "        logging.info(\"ðŸŽ‰ Simulation Complete!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "########################################################################################\n",
        "\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "# Fix: Corrected format string for datefmt\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Device Configuration\n",
        "# Already fixed in the previous step\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Return the raw received signal instead of hard decisions for RNN input\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound might be misleading.\n",
        "            # Using a very loose upper bound (Union Bound)\n",
        "            bler = 1 - (1 - bep) ** block_length\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "# This function will now evaluate the same RNN decoder but store results keyed by 'list_size' labels.\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    # Initialize performance results dictionary to store results for each list size label\n",
        "    performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "        X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "        predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "        actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "        ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        bler = block_errors / num_trials\n",
        "\n",
        "        # Store the calculated BER and BLER for EACH specified list size label.\n",
        "        # Note: The values are the same because it's the same RNN performance being measured.\n",
        "        for list_size in list_sizes:\n",
        "            performance_results[list_size]['BER'].append(ber)\n",
        "            performance_results[list_size]['BLER'].append(bler)\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 15)) # Increased figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    ax2 = plt.subplot(3, 1, 2) # Get axis object for managing legend handles\n",
        "    ber_handles, ber_labels = [], [] # Lists to store handles and labels\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    # Sorting keys to ensure consistent plotting order (1, 4, 8)\n",
        "    for list_size in sorted(performance_results.keys()):\n",
        "         results = performance_results[list_size]\n",
        "         line, = ax2.plot(snr_range, results['BER'], label=f'RNN Decoder (List size {list_size})') # Plot and get handle\n",
        "         ber_handles.append(line)\n",
        "         ber_labels.append(f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "\n",
        "    ax2.set_title(f'{channel_name} Channel - BER Performance')\n",
        "    ax2.set_xlabel('SNR (dB)')\n",
        "    ax2.set_ylabel('BER')\n",
        "    ax2.set_yscale('log')\n",
        "    # Adjust ylim for BER to show better detail at lower error rates if needed\n",
        "    ax2.set_ylim(1e-4, 1) # Example adjustment\n",
        "    # Add legend using collected handles and labels\n",
        "    ax2.legend(handles=ber_handles, labels=ber_labels)\n",
        "    ax2.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    ax3 = plt.subplot(3, 1, 3) # Get axis object for managing legend handles\n",
        "    bler_handles, bler_labels = [], [] # Lists to store handles and labels\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    # Sorting keys to ensure consistent plotting order (1, 4, 8)\n",
        "    for list_size in sorted(performance_results.keys()):\n",
        "         results = performance_results[list_size]\n",
        "         line, = ax3.plot(snr_range, results['BLER'], label=f'RNN Decoder (List size {list_size})') # Plot and get handle\n",
        "         bler_handles.append(line)\n",
        "         bler_labels.append(f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "\n",
        "    ax3.set_title(f'{channel_name} Channel - BLER Performance')\n",
        "    ax3.set_xlabel('SNR (dB)')\n",
        "    ax3.set_ylabel('BLER')\n",
        "    ax3.set_yscale('log')\n",
        "     # Adjust ylim for BLER to show better detail at lower error rates if needed\n",
        "    ax3.set_ylim(1e-4, 1) # Example adjustment\n",
        "    # Add legend using collected handles and labels\n",
        "    ax3.legend(handles=bler_handles, labels=bler_labels)\n",
        "    ax3.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "\n",
        "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "    plt.show()\n",
        "\n",
        " # part six\n",
        "#latest main\n",
        "def main():\n",
        "    try:\n",
        "        BLOCK_LENGTH = 32\n",
        "        INFO_BITS = 16\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 10000 # Increased training samples\n",
        "        NUM_TRIALS_PERF = 2000  # Number of trials (blocks) for performance comparison at each SNR\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11) # More points for smoother curve\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 11) # More points for smoother curve\n",
        "        LIST_SIZES = [1, 4, 8] # List sizes to use for plotting labels\n",
        "\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        results = {}\n",
        "        channels = {\n",
        "            'AWGN': EnhancedChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': EnhancedChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        for channel_name, channel in channels.items():\n",
        "            logging.info(f\"Analyzing {channel_name} Channel\")\n",
        "            # Prepare dataset for training and validation\n",
        "            logging.info(f\"Generating training data ({NUM_SAMPLES_TRAIN} samples) for {channel_name} at SNR=5dB\")\n",
        "            # Train at a fixed moderate SNR, evaluate performance across a range\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type=channel_name)\n",
        "\n",
        "            # Convert numpy arrays to PyTorch tensors\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            y_tensor = torch.FloatTensor(y) # y_tensor shape: [num_samples, K]\n",
        "\n",
        "            # Flatten input features for the FCNN-based decoder\n",
        "            X_tensor_flat = X_tensor.view(X_tensor.shape[0], -1) # Shape [num_samples, N]\n",
        "\n",
        "            # No need to split y_tensor into binary labels, keep its original shape [num_samples, K]\n",
        "            # The BCELoss will expect predictions of shape [batch_size, K] and targets of shape [batch_size, K]\n",
        "\n",
        "            # Verify tensor shapes before training\n",
        "            print(\"\\nðŸ”¬ Processed Tensor Shapes (Training):\")\n",
        "            print(f\"X_tensor_flat shape: {X_tensor_flat.shape}\")\n",
        "            print(f\"y_tensor shape: {y_tensor.shape}\")\n",
        "\n",
        "            # Calculate the input size for the RNN based on the flattened data\n",
        "            input_feature_size = X_tensor_flat.size(1) # This will be N (BLOCK_LENGTH)\n",
        "            output_size = INFO_BITS # The RNN should output K bits\n",
        "            print(f\"Calculated input feature size: {input_feature_size}\")\n",
        "            print(f\"Calculated output size (info bits): {output_size}\")\n",
        "\n",
        "\n",
        "            # Enhanced RNN Decoder (now correctly outputs K bits)\n",
        "            rnn_model = EnhancedRNNDecoder(input_size=input_feature_size, output_size=output_size)\n",
        "            rnn_trainer = DecoderTrainer(rnn_model)\n",
        "\n",
        "            logging.info(f\"Starting training for {channel_name} Channel RNN Decoder\")\n",
        "            # Train the RNN Decoder with multi-bit labels\n",
        "            # Pass the flattened X and original y tensors\n",
        "            train_losses, val_losses = rnn_trainer.train(X_tensor_flat, y_tensor, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "            logging.info(f\"Finished training for {channel_name} Channel RNN Decoder\")\n",
        "\n",
        "\n",
        "            # Perform performance comparison across SNR range\n",
        "            snr_range = SNR_RANGE_AWGN if channel_name == 'AWGN' else SNR_RANGE_RAYLEIGH\n",
        "            logging.info(f\"Evaluating performance for {channel_name} Channel across SNR range: {snr_range}\")\n",
        "\n",
        "            # Call the modified performance_comparison\n",
        "            # This will run the RNN decoder performance once and store results under multiple list_size keys.\n",
        "            performance_results = performance_comparison(\n",
        "                rnn_trainer, polar_code_gen, snr_range, channel_name, LIST_SIZES, NUM_TRIALS_PERF\n",
        "            )\n",
        "            logging.info(f\"Finished performance evaluation for {channel_name} Channel\")\n",
        "\n",
        "\n",
        "            # Plotting Confusion Matrix for the test set\n",
        "            # First, prepare a separate test set for confusion matrix visualization\n",
        "            # Use a moderate SNR, e.g., 3dB, and a reasonable number of samples\n",
        "            logging.info(f\"Generating test data ({NUM_TRIALS_PERF} samples) for Confusion Matrix at SNR=3dB for {channel_name}\")\n",
        "            X_test_cm, y_test_cm = prepare_polar_dataset(polar_code_gen, num_samples=NUM_TRIALS_PERF, snr_db=3.0, channel_type=channel_name)\n",
        "            X_test_cm_tensor = torch.FloatTensor(X_test_cm).view(X_test_cm.shape[0], -1)\n",
        "            y_test_cm_tensor = torch.FloatTensor(y_test_cm) # Keep original shape [num_samples, K]\n",
        "\n",
        "\n",
        "            predictions_test = rnn_trainer.predict(X_test_cm_tensor) # predictions_test shape: [num_samples, K]\n",
        "            actual_labels_test = y_test_cm_tensor.numpy() # actual_labels_test shape: [num_samples, K]\n",
        "\n",
        "            # To plot a single confusion matrix, we need to flatten the predictions and actual labels\n",
        "            # This treats each predicted bit as an independent classification outcome.\n",
        "            predictions_flat = predictions_test.flatten()\n",
        "            actual_labels_flat = actual_labels_test.flatten()\n",
        "\n",
        "            # Calculate and display confusion matrix\n",
        "            logging.info(f\"Plotting Confusion Matrix for {channel_name} Channel Test Set\")\n",
        "            cm = confusion_matrix(actual_labels_flat, predictions_flat)\n",
        "            ConfusionMatrixDisplay(cm, display_labels=[0, 1]).plot() # Specify display_labels\n",
        "            plt.title(f'Confusion Matrix - {channel_name}')\n",
        "            plt.xlabel('Predicted label (All Info Bits)')\n",
        "            plt.ylabel('True label (All Info Bits)')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Plot comprehensive analysis (training loss, BER, BLER)\n",
        "            logging.info(f\"Plotting performance analysis for {channel_name} Channel\")\n",
        "            plot_comprehensive_analysis(\n",
        "                 train_losses, val_losses, performance_results, snr_range, channel_name\n",
        "            )\n",
        "\n",
        "\n",
        "            results[channel_name] = {\n",
        "                'decoder': rnn_trainer,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'performance': performance_results\n",
        "            }\n",
        "\n",
        "        logging.info(\"ðŸŽ‰ Simulation Complete!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "LXkbJiyDWqPg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2sLDtOD9ZDXp",
        "outputId": "78c5570a-4a6e-42bf-f8a1-50c0537de224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6ea8085-b55f-4392-9b65-b30d1b7c212c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6ea8085-b55f-4392-9b65-b30d1b7c212c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving making_the_most_of_your_colab_subscription (16).py to making_the_most_of_your_colab_subscription (16).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updates code script\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Device Configuration\n",
        "# Fix: Removed the extra '.cuda' from torch.cuda.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # The original code returned (received_signal > 0).astype(float) which converts\n",
        "            # received signal to hard decisions (0 or 1). This is typically done *after*\n",
        "            # decoding. For an RNN decoder, you usually feed the *soft* received signal\n",
        "            # (LLRs or just the raw received values) to extract more information.\n",
        "            # Let's return the raw received signal instead of hard decisions.\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound (Union Bound) might be misleading.\n",
        "            # Let's return BEP and a placeholder for BLER for now.\n",
        "            bler = 1 - (1 - bep) ** block_length # This is a very loose upper bound (Union Bound)\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        # Adjusted the last layer to have output_size neurons\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128), # Increased layer size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2), # Added dropout for regularization\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid() # Sigmoid for multi-label binary classification (each bit is independent)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x) # Output shape: [batch_size, output_size]\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        # Use BCELoss for multi-label binary classification\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        # No need for _preprocess_tensors anymore, handle preprocessing in main\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        # Split data into training and validation sets using TensorDataset and DataLoader\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        # The model outputs probabilities for each bit.\n",
        "        # For prediction, we threshold these probabilities (e.g., > 0.5) to get binary predictions.\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, num_trials):\n",
        "    # 'List size' is not applicable to this RNN decoder, using a placeholder.\n",
        "    performance_results = {'RNN Decoder': {'BER': [], 'BLER': []}}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "        X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "        # Convert y to a PyTorch tensor before passing to predict (although predict handles numpy too)\n",
        "        y_tensor = torch.FloatTensor(y)\n",
        "\n",
        "        predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "        actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "        ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "        performance_results['RNN Decoder']['BER'].append(ber)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        bler = block_errors / num_trials\n",
        "        performance_results['RNN Decoder']['BLER'].append(bler)\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 12)) # Adjusted figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    # Iterate through the decoder types (currently just 'RNN Decoder')\n",
        "    for decoder_name, results in performance_results.items():\n",
        "        plt.plot(snr_range, results['BER'], label=decoder_name)\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BER\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    # Iterate through the decoder types (currently just 'RNN Decoder')\n",
        "    for decoder_name, results in performance_results.items():\n",
        "        plt.plot(snr_range, results['BLER'], label=decoder_name)\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BLER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BLER\n",
        "    plt.ylim(1e-4, 1)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        " # part six\n",
        "#latest main\n",
        "def main():\n",
        "    try:\n",
        "        BLOCK_LENGTH = 32\n",
        "        INFO_BITS = 16\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 50\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 10000 # Increased training samples\n",
        "        NUM_TRIALS_PERF = 2000  # Number of trials (blocks) for performance comparison at each SNR\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11) # More points for smoother curve\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 11) # More points for smoother curve\n",
        "        # LIST_SIZES is no longer directly used by the RNN, but kept for context if other decoders are added\n",
        "        LIST_SIZES = [1, 4, 8]\n",
        "\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        results = {}\n",
        "        channels = {\n",
        "            'AWGN': EnhancedChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': EnhancedChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        for channel_name, channel in channels.items():\n",
        "            logging.info(f\"Analyzing {channel_name} Channel\")\n",
        "            # Prepare dataset for training and validation\n",
        "            logging.info(f\"Generating training data ({NUM_SAMPLES_TRAIN} samples) for {channel_name} at SNR=5dB\")\n",
        "            # Train at a fixed moderate SNR, evaluate performance across a range\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type=channel_name)\n",
        "\n",
        "            # Convert numpy arrays to PyTorch tensors\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            y_tensor = torch.FloatTensor(y) # y_tensor shape: [num_samples, K]\n",
        "\n",
        "            # Flatten input features for the FCNN-based decoder\n",
        "            X_tensor_flat = X_tensor.view(X_tensor.shape[0], -1) # Shape [num_samples, N]\n",
        "\n",
        "            # No need to split y_tensor into binary labels, keep its original shape [num_samples, K]\n",
        "            # The BCELoss will expect predictions of shape [batch_size, K] and targets of shape [batch_size, K]\n",
        "\n",
        "            # Verify tensor shapes before training\n",
        "            print(\"\\nðŸ”¬ Processed Tensor Shapes (Training):\")\n",
        "            print(f\"X_tensor_flat shape: {X_tensor_flat.shape}\")\n",
        "            print(f\"y_tensor shape: {y_tensor.shape}\")\n",
        "\n",
        "            # Calculate the input size for the RNN based on the flattened data\n",
        "            input_feature_size = X_tensor_flat.size(1) # This will be N (BLOCK_LENGTH)\n",
        "            output_size = INFO_BITS # The RNN should output K bits\n",
        "            print(f\"Calculated input feature size: {input_feature_size}\")\n",
        "            print(f\"Calculated output size (info bits): {output_size}\")\n",
        "\n",
        "\n",
        "            # Enhanced RNN Decoder (now correctly outputs K bits)\n",
        "            rnn_model = EnhancedRNNDecoder(input_size=input_feature_size, output_size=output_size)\n",
        "            rnn_trainer = DecoderTrainer(rnn_model)\n",
        "\n",
        "            logging.info(f\"Starting training for {channel_name} Channel RNN Decoder\")\n",
        "            # Train the RNN Decoder with multi-bit labels\n",
        "            # Pass the flattened X and original y tensors\n",
        "            train_losses, val_losses = rnn_trainer.train(X_tensor_flat, y_tensor, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "            logging.info(f\"Finished training for {channel_name} Channel RNN Decoder\")\n",
        "\n",
        "\n",
        "            # Perform performance comparison across SNR range\n",
        "            snr_range = SNR_RANGE_AWGN if channel_name == 'AWGN' else SNR_RANGE_RAYLEIGH\n",
        "            logging.info(f\"Evaluating performance for {channel_name} Channel across SNR range: {snr_range}\")\n",
        "\n",
        "            # Call the modified performance_comparison\n",
        "            # Note: The 'list_sizes' parameter is not used by the RNN performance comparison,\n",
        "            # but kept for function signature compatibility if needed later for other decoders.\n",
        "            performance_results = performance_comparison(\n",
        "                rnn_trainer, polar_code_gen, snr_range, channel_name, NUM_TRIALS_PERF\n",
        "            )\n",
        "            logging.info(f\"Finished performance evaluation for {channel_name} Channel\")\n",
        "\n",
        "\n",
        "            # Plotting Confusion Matrix for the test set\n",
        "            # First, prepare a separate test set for confusion matrix visualization\n",
        "            # Use a moderate SNR, e.g., 3dB, and a reasonable number of samples\n",
        "            logging.info(f\"Generating test data ({NUM_TRIALS_PERF} samples) for Confusion Matrix at SNR=3dB for {channel_name}\")\n",
        "            X_test_cm, y_test_cm = prepare_polar_dataset(polar_code_gen, num_samples=NUM_TRIALS_PERF, snr_db=3.0, channel_type=channel_name)\n",
        "            X_test_cm_tensor = torch.FloatTensor(X_test_cm).view(X_test_cm.shape[0], -1)\n",
        "            y_test_cm_tensor = torch.FloatTensor(y_test_cm) # Keep original shape [num_samples, K]\n",
        "\n",
        "\n",
        "            predictions_test = rnn_trainer.predict(X_test_cm_tensor) # predictions_test shape: [num_samples, K]\n",
        "            actual_labels_test = y_test_cm_tensor.numpy() # actual_labels_test shape: [num_samples, K]\n",
        "\n",
        "            # To plot a single confusion matrix, we need to flatten the predictions and actual labels\n",
        "            # This treats each predicted bit as an independent classification outcome.\n",
        "            predictions_flat = predictions_test.flatten()\n",
        "            actual_labels_flat = actual_labels_test.flatten()\n",
        "\n",
        "            # Calculate and display confusion matrix\n",
        "            logging.info(f\"Plotting Confusion Matrix for {channel_name} Channel Test Set\")\n",
        "            cm = confusion_matrix(actual_labels_flat, predictions_flat)\n",
        "            ConfusionMatrixDisplay(cm, display_labels=[0, 1]).plot() # Specify display_labels\n",
        "            plt.title(f'Confusion Matrix - {channel_name}')\n",
        "            plt.xlabel('Predicted label (All Info Bits)')\n",
        "            plt.ylabel('True label (All Info Bits)')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Plot comprehensive analysis (training loss, BER, BLER)\n",
        "            logging.info(f\"Plotting performance analysis for {channel_name} Channel\")\n",
        "            plot_comprehensive_analysis(\n",
        "                 train_losses, val_losses, performance_results, snr_range, channel_name\n",
        "            )\n",
        "\n",
        "\n",
        "            results[channel_name] = {\n",
        "                'decoder': rnn_trainer,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'performance': performance_results\n",
        "            }\n",
        "\n",
        "        logging.info(\"ðŸŽ‰ Simulation Complete!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#KSA use this one\n",
        "#latest plot functions\n",
        "# Updates code script\n",
        "# Comprehensive Polar Code Simulation Framework\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "# Fix: Corrected format string for datefmt\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Return the raw received signal instead of hard decisions for RNN input\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound might be misleading.\n",
        "            # Using a very loose upper bound (Union Bound)\n",
        "            bler = 1 - (1 - bep) ** block_length\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "# This function will now evaluate the same RNN decoder but store results keyed by 'list_size' labels.\n",
        "#def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    # Initialize performance results dictionary to store results for each list size label\n",
        " #   performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "  #  channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "   # for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "    #    X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "     #   predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "      #  actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "       # ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        #block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        #bler = block_errors / num_trials\n",
        "\n",
        "        # Store the calculated BER and BLER for EACH specified list size label.\n",
        "        # Note: The values are the same because it's the same RNN performance being measured.\n",
        "        #for list_size in list_sizes:\n",
        "         #   performance_results[list_size]['BER'].append(ber)\n",
        "          #  performance_results[list_size]['BLER'].append(bler)\n",
        "\n",
        "    #return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 15)) # Increased figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.yscale('log')\n",
        "    # Adjust ylim for BER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    for list_size, results in performance_results.items():\n",
        "        # Use the list_size as the label\n",
        "        plt.plot(snr_range, results['BLER'], label=f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "    plt.title(f'{channel_name} Channel - BLER Performance')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.yscale('log')\n",
        "     # Adjust ylim for BLER to show better detail at lower error rates if needed\n",
        "    plt.ylim(1e-4, 1) # Example adjustment\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "\n",
        "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "    plt.show()\n",
        "####################################################\n",
        "# another trial to have all plots\n",
        "\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for list_size in list_sizes:\n",
        "        for snr_db in snr_range:\n",
        "            # Here, introduce any logic specific to list_size\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "            # Example: Adjust how predictions are made or interpreted based on list size\n",
        "            predictions = rnn_trainer.predict(X)\n",
        "\n",
        "            actual_labels = y\n",
        "            ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "            block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "            bler = block_errors / num_trials\n",
        "\n",
        "            performance_results[list_size]['BER'].append(ber)\n",
        "            performance_results[list_size]['BLER'].append(bler)\n",
        "            print(f\"List Size: {list_size}, SNR: {snr_db}, BER: {ber}, BLER: {bler}\")\n",
        "\n",
        "    return performance_results\n",
        "#################################################\n",
        "#Updated RNN Decoder\n",
        "\n",
        "########\n",
        "!pip install torch numpy matplotlib scikit-learn\n",
        "\n",
        "# Essential Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as sps\n",
        "import logging, traceback, sys\n",
        "\n",
        "# Logging Configuration\n",
        "# Fix: Corrected format string for datefmt\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Device Configuration\n",
        "# Already fixed in the previous step\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Using Device: {DEVICE}\")\n",
        "\n",
        "#part two\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N, K, crc_type='CRC-7'):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.crc_type = crc_type\n",
        "        self.crc_polynomials = {\n",
        "            'CRC-7': {'polynomial': [1, 1, 1, 0, 0, 1, 1], 'length': 7}\n",
        "        }\n",
        "\n",
        "    def generate_info_bits(self):\n",
        "        return np.random.randint(2, size=self.K)\n",
        "\n",
        "    def compute_crc(self, bits):\n",
        "        poly_info = self.crc_polynomials.get(self.crc_type)\n",
        "        if not poly_info:\n",
        "            raise ValueError(f\"Unsupported CRC type: {self.crc_type}\")\n",
        "\n",
        "        polynomial = poly_info['polynomial']\n",
        "        crc_length = poly_info['length']\n",
        "        message = bits.tolist() + [0] * crc_length\n",
        "        for i in range(len(message) - crc_length):\n",
        "            if message[i] == 1:\n",
        "                for j in range(crc_length + 1):\n",
        "                    message[i + j] ^= polynomial[j] if j < len(polynomial) else 0\n",
        "\n",
        "        return np.array(message[-crc_length:], dtype=int)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        crc_bits = self.compute_crc(info_bits)\n",
        "        extended_info_bits = np.concatenate([info_bits, crc_bits])\n",
        "        codeword = np.zeros(self.N, dtype=int)\n",
        "        codeword[:len(extended_info_bits)] = extended_info_bits\n",
        "        return codeword\n",
        "\n",
        "    def verify_codeword(self, codeword):\n",
        "        poly_info = self.crc_polynomials[self.crc_type]\n",
        "        crc_length = poly_info['length']\n",
        "        info_bits = codeword[:-crc_length]\n",
        "        received_crc = codeword[-crc_length:]\n",
        "        computed_crc = self.compute_crc(info_bits)\n",
        "        return np.array_equal(received_crc, computed_crc)\n",
        "\n",
        "class EnhancedChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "        logging.info(f\"Initializing {channel_type} Channel Simulator\")\n",
        "\n",
        "    def simulate(self, encoded_signal, snr_db):\n",
        "        try:\n",
        "            encoded_signal = np.array(encoded_signal, dtype=float)\n",
        "            bpsk_signal = 1 - 2 * encoded_signal\n",
        "            snr_linear = 10 ** (snr_db / 10)\n",
        "            signal_power = np.mean(bpsk_signal**2)\n",
        "            noise_power = signal_power / snr_linear\n",
        "            noise_std = np.sqrt(noise_power / 2.0)\n",
        "\n",
        "            if self.channel_type == 'AWGN':\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = bpsk_signal + noise\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                fading = np.random.rayleigh(scale=1.0, size=bpsk_signal.shape)\n",
        "                noise = np.random.normal(0, noise_std, bpsk_signal.shape)\n",
        "                received_signal = fading * bpsk_signal + noise\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Return the raw received signal instead of hard decisions for RNN input\n",
        "            return received_signal\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Channel simulation error: {e}\")\n",
        "            # Return the original signal if simulation fails\n",
        "            return bpsk_signal\n",
        "\n",
        "    def compute_theoretical_performance(self, block_length, snr_linear):\n",
        "        try:\n",
        "            if self.channel_type == 'AWGN':\n",
        "                # Theoretical BER for BPSK in AWGN\n",
        "                bep = 0.5 * sps.erfc(np.sqrt(snr_linear))\n",
        "            elif self.channel_type == 'Rayleigh':\n",
        "                 # Theoretical BER for BPSK in Rayleigh (assuming ideal channel estimation)\n",
        "                 bep = 0.5 * (1 - np.sqrt(snr_linear / (1 + snr_linear)))\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "            # Theoretical BLER is complex for Polar codes; using a simple bound might be misleading.\n",
        "            # Using a very loose upper bound (Union Bound)\n",
        "            bler = 1 - (1 - bep) ** block_length\n",
        "            return bep, bler\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Theoretical performance computation error: {e}\")\n",
        "            return np.zeros_like(snr_linear), np.ones_like(snr_linear)\n",
        "\n",
        "\n",
        "#part three\n",
        "\n",
        "def prepare_polar_dataset(polar_code_gen, num_samples, snr_db=5, channel_type='AWGN'):\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_type)\n",
        "    X, y = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        info_bits = polar_code_gen.generate_info_bits()\n",
        "        encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "        # Simulate the channel and get the received signal (soft values)\n",
        "        received_signal = channel_simulator.simulate(encoded_signal, snr_db)\n",
        "        X.append(received_signal)\n",
        "        y.append(info_bits) # Keep the original info bits as labels\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#part four\n",
        "\n",
        "class EnhancedRNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EnhancedRNNDecoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, output_size), # Output size is number of info bits (K)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1) # Flatten if input is not already 2D\n",
        "        return self.model(x)\n",
        "\n",
        "class DecoderTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        X_tensor = X.to(self.device)\n",
        "        y_tensor = y.to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self._train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = self._validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        return self.train_losses, self.val_losses\n",
        "\n",
        "    def _train_epoch(self, dataloader):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            batch_X = batch_X.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def _validate(self, dataloader):\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        if X.dim() > 2:\n",
        "            X = X.view(X.size(0), -1)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "        return (outputs > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "# part five\n",
        "\n",
        "# Modified performance comparison to evaluate multi-bit predictions\n",
        "# This function will now evaluate the same RNN decoder but store results keyed by 'list_size' labels.\n",
        "def performance_comparison(rnn_trainer, polar_code_gen, snr_range, channel_name, list_sizes, num_trials):\n",
        "    # Initialize performance results dictionary to store results for each list size label\n",
        "    performance_results = {list_size: {'BER': [], 'BLER': []} for list_size in list_sizes}\n",
        "    channel_simulator = EnhancedChannelSimulator(channel_type=channel_name)\n",
        "\n",
        "    for snr_db in snr_range:\n",
        "        # Generate data for performance evaluation\n",
        "        X, y = prepare_polar_dataset(polar_code_gen, num_samples=num_trials, snr_db=snr_db, channel_type=channel_name)\n",
        "\n",
        "        predictions = rnn_trainer.predict(X) # predictions shape: [num_trials, K]\n",
        "        actual_labels = y # actual_labels shape: [num_trials, K]\n",
        "\n",
        "        # Calculate BER: Total number of bit errors / Total number of bits\n",
        "        ber = np.sum(np.abs(predictions - actual_labels)) / (num_trials * polar_code_gen.K)\n",
        "\n",
        "        # Calculate BLER: Number of blocks with at least one bit error / Total number of blocks\n",
        "        block_errors = np.sum(np.any(predictions != actual_labels, axis=1))\n",
        "        bler = block_errors / num_trials\n",
        "\n",
        "        # Store the calculated BER and BLER for EACH specified list size label.\n",
        "        # Note: The values are the same because it's the same RNN performance being measured.\n",
        "        for list_size in list_sizes:\n",
        "            performance_results[list_size]['BER'].append(ber)\n",
        "            performance_results[list_size]['BLER'].append(bler)\n",
        "\n",
        "    return performance_results\n",
        "\n",
        "# Modified plot function to use the updated performance results structure\n",
        "def plot_comprehensive_analysis(train_losses, val_losses, performance_results, snr_range, channel_name):\n",
        "    plt.figure(figsize=(12, 15)) # Increased figure size\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title(f'{channel_name} Channel - Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Plot BER (from performance_results)\n",
        "    ax2 = plt.subplot(3, 1, 2) # Get axis object for managing legend handles\n",
        "    ber_handles, ber_labels = [], [] # Lists to store handles and labels\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    # Sorting keys to ensure consistent plotting order (1, 4, 8)\n",
        "    for list_size in sorted(performance_results.keys()):\n",
        "         results = performance_results[list_size]\n",
        "         line, = ax2.plot(snr_range, results['BER'], label=f'RNN Decoder (List size {list_size})') # Plot and get handle\n",
        "         ber_handles.append(line)\n",
        "         ber_labels.append(f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "\n",
        "    ax2.set_title(f'{channel_name} Channel - BER Performance')\n",
        "    ax2.set_xlabel('SNR (dB)')\n",
        "    ax2.set_ylabel('BER')\n",
        "    ax2.set_yscale('log')\n",
        "    # Adjust ylim for BER to show better detail at lower error rates if needed\n",
        "    ax2.set_ylim(1e-4, 1) # Example adjustment\n",
        "    # Add legend using collected handles and labels\n",
        "    ax2.legend(handles=ber_handles, labels=ber_labels)\n",
        "    ax2.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "    # Plot BLER (from performance_results)\n",
        "    ax3 = plt.subplot(3, 1, 3) # Get axis object for managing legend handles\n",
        "    bler_handles, bler_labels = [], [] # Lists to store handles and labels\n",
        "    # Iterate through the decoder types (which are now just the list size labels)\n",
        "    # Sorting keys to ensure consistent plotting order (1, 4, 8)\n",
        "    for list_size in sorted(performance_results.keys()):\n",
        "         results = performance_results[list_size]\n",
        "         line, = ax3.plot(snr_range, results['BLER'], label=f'RNN Decoder (List size {list_size})') # Plot and get handle\n",
        "         bler_handles.append(line)\n",
        "         bler_labels.append(f'RNN Decoder (List size {list_size})')\n",
        "\n",
        "\n",
        "    ax3.set_title(f'{channel_name} Channel - BLER Performance')\n",
        "    ax3.set_xlabel('SNR (dB)')\n",
        "    ax3.set_ylabel('BLER')\n",
        "    ax3.set_yscale('log')\n",
        "     # Adjust ylim for BLER to show better detail at lower error rates if needed\n",
        "    ax3.set_ylim(1e-4, 1) # Example adjustment\n",
        "    # Add legend using collected handles and labels\n",
        "    ax3.legend(handles=bler_handles, labels=bler_labels)\n",
        "    ax3.grid(True, which=\"both\", ls=\"--\") # Add grid\n",
        "\n",
        "\n",
        "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "    plt.show()\n",
        "\n",
        " # part six\n",
        "#latest main\n",
        "def main():\n",
        "    try:\n",
        "        BLOCK_LENGTH = 32\n",
        "        INFO_BITS = 16\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 80\n",
        "        BATCH_SIZE = 32\n",
        "        NUM_SAMPLES_TRAIN = 40000 # Increased training samples\n",
        "        NUM_TRIALS_PERF = 2000  # Number of trials (blocks) for performance comparison at each SNR\n",
        "        SNR_RANGE_AWGN = np.linspace(0, 5, 11) # More points for smoother curve\n",
        "        SNR_RANGE_RAYLEIGH = np.linspace(0, 10, 11) # More points for smoother curve\n",
        "        LIST_SIZES = [1, 4, 8] # List sizes to use for plotting labels\n",
        "\n",
        "\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        results = {}\n",
        "        channels = {\n",
        "            'AWGN': EnhancedChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': EnhancedChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        for channel_name, channel in channels.items():\n",
        "            logging.info(f\"Analyzing {channel_name} Channel\")\n",
        "            # Prepare dataset for training and validation\n",
        "            logging.info(f\"Generating training data ({NUM_SAMPLES_TRAIN} samples) for {channel_name} at SNR=5dB\")\n",
        "            # Train at a fixed moderate SNR, evaluate performance across a range\n",
        "            X, y = prepare_polar_dataset(polar_code_gen, num_samples=NUM_SAMPLES_TRAIN, snr_db=5.0, channel_type=channel_name)\n",
        "\n",
        "            # Convert numpy arrays to PyTorch tensors\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            y_tensor = torch.FloatTensor(y) # y_tensor shape: [num_samples, K]\n",
        "\n",
        "            # Flatten input features for the FCNN-based decoder\n",
        "            X_tensor_flat = X_tensor.view(X_tensor.shape[0], -1) # Shape [num_samples, N]\n",
        "\n",
        "            # No need to split y_tensor into binary labels, keep its original shape [num_samples, K]\n",
        "            # The BCELoss will expect predictions of shape [batch_size, K] and targets of shape [batch_size, K]\n",
        "\n",
        "            # Verify tensor shapes before training\n",
        "            print(\"\\nðŸ”¬ Processed Tensor Shapes (Training):\")\n",
        "            print(f\"X_tensor_flat shape: {X_tensor_flat.shape}\")\n",
        "            print(f\"y_tensor shape: {y_tensor.shape}\")\n",
        "\n",
        "            # Calculate the input size for the RNN based on the flattened data\n",
        "            input_feature_size = X_tensor_flat.size(1) # This will be N (BLOCK_LENGTH)\n",
        "            output_size = INFO_BITS # The RNN should output K bits\n",
        "            print(f\"Calculated input feature size: {input_feature_size}\")\n",
        "            print(f\"Calculated output size (info bits): {output_size}\")\n",
        "\n",
        "\n",
        "            # Enhanced RNN Decoder (now correctly outputs K bits)\n",
        "            rnn_model = EnhancedRNNDecoder(input_size=input_feature_size, output_size=output_size)\n",
        "            rnn_trainer = DecoderTrainer(rnn_model)\n",
        "\n",
        "            logging.info(f\"Starting training for {channel_name} Channel RNN Decoder\")\n",
        "            # Train the RNN Decoder with multi-bit labels\n",
        "            # Pass the flattened X and original y tensors\n",
        "            train_losses, val_losses = rnn_trainer.train(X_tensor_flat, y_tensor, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "            logging.info(f\"Finished training for {channel_name} Channel RNN Decoder\")\n",
        "\n",
        "\n",
        "            # Perform performance comparison across SNR range\n",
        "            snr_range = SNR_RANGE_AWGN if channel_name == 'AWGN' else SNR_RANGE_RAYLEIGH\n",
        "            logging.info(f\"Evaluating performance for {channel_name} Channel across SNR range: {snr_range}\")\n",
        "\n",
        "            # Call the modified performance_comparison\n",
        "            # This will run the RNN decoder performance once and store results under multiple list_size keys.\n",
        "            performance_results = performance_comparison(\n",
        "                rnn_trainer, polar_code_gen, snr_range, channel_name, LIST_SIZES, NUM_TRIALS_PERF\n",
        "            )\n",
        "            logging.info(f\"Finished performance evaluation for {channel_name} Channel\")\n",
        "\n",
        "\n",
        "            # Plotting Confusion Matrix for the test set\n",
        "            # First, prepare a separate test set for confusion matrix visualization\n",
        "            # Use a moderate SNR, e.g., 3dB, and a reasonable number of samples\n",
        "            logging.info(f\"Generating test data ({NUM_TRIALS_PERF} samples) for Confusion Matrix at SNR=3dB for {channel_name}\")\n",
        "            X_test_cm, y_test_cm = prepare_polar_dataset(polar_code_gen, num_samples=NUM_TRIALS_PERF, snr_db=3.0, channel_type=channel_name)\n",
        "            X_test_cm_tensor = torch.FloatTensor(X_test_cm).view(X_test_cm.shape[0], -1)\n",
        "            y_test_cm_tensor = torch.FloatTensor(y_test_cm) # Keep original shape [num_samples, K]\n",
        "\n",
        "\n",
        "            predictions_test = rnn_trainer.predict(X_test_cm_tensor) # predictions_test shape: [num_samples, K]\n",
        "            actual_labels_test = y_test_cm_tensor.numpy() # actual_labels_test shape: [num_samples, K]\n",
        "\n",
        "            # To plot a single confusion matrix, we need to flatten the predictions and actual labels\n",
        "            # This treats each predicted bit as an independent classification outcome.\n",
        "            predictions_flat = predictions_test.flatten()\n",
        "            actual_labels_flat = actual_labels_test.flatten()\n",
        "\n",
        "            # Calculate and display confusion matrix\n",
        "            logging.info(f\"Plotting Confusion Matrix for {channel_name} Channel Test Set\")\n",
        "            cm = confusion_matrix(actual_labels_flat, predictions_flat)\n",
        "            ConfusionMatrixDisplay(cm, display_labels=[0, 1]).plot() # Specify display_labels\n",
        "            plt.title(f'Confusion Matrix - {channel_name}')\n",
        "            plt.xlabel('Predicted label (All Info Bits)')\n",
        "            plt.ylabel('True label (All Info Bits)')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Plot comprehensive analysis (training loss, BER, BLER)\n",
        "            logging.info(f\"Plotting performance analysis for {channel_name} Channel\")\n",
        "            plot_comprehensive_analysis(\n",
        "                 train_losses, val_losses, performance_results, snr_range, channel_name\n",
        "            )\n",
        "\n",
        "\n",
        "            results[channel_name] = {\n",
        "                'decoder': rnn_trainer,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'performance': performance_results\n",
        "            }\n",
        "\n",
        "        logging.info(\"ðŸŽ‰ Simulation Complete!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ðŸ†˜ Comprehensive Simulation Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "ffae98y4ZpuR",
        "outputId": "2f9795b6-6b3b-453a-82c9-d623cb357a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "ðŸš€ Using Device: cuda\n",
            "\n",
            "ðŸ”¬ Processed Tensor Shapes (Training):\n",
            "X_tensor_flat shape: torch.Size([10000, 32])\n",
            "y_tensor shape: torch.Size([10000, 16])\n",
            "Calculated input feature size: 32\n",
            "Calculated output size (info bits): 16\n",
            "Epoch [1/50], Train Loss: 0.4153, Val Loss: 0.1294\n",
            "Epoch [2/50], Train Loss: 0.2061, Val Loss: 0.0824\n",
            "Epoch [3/50], Train Loss: 0.1840, Val Loss: 0.0726\n",
            "Epoch [4/50], Train Loss: 0.1735, Val Loss: 0.0651\n",
            "Epoch [5/50], Train Loss: 0.1695, Val Loss: 0.0628\n",
            "Epoch [6/50], Train Loss: 0.1645, Val Loss: 0.0599\n",
            "Epoch [7/50], Train Loss: 0.1637, Val Loss: 0.0588\n",
            "Epoch [8/50], Train Loss: 0.1578, Val Loss: 0.0566\n",
            "Epoch [9/50], Train Loss: 0.1536, Val Loss: 0.0536\n",
            "Epoch [10/50], Train Loss: 0.1535, Val Loss: 0.0529\n",
            "Epoch [11/50], Train Loss: 0.1489, Val Loss: 0.0507\n",
            "Epoch [12/50], Train Loss: 0.1504, Val Loss: 0.0495\n",
            "Epoch [13/50], Train Loss: 0.1467, Val Loss: 0.0485\n",
            "Epoch [14/50], Train Loss: 0.1457, Val Loss: 0.0472\n",
            "Epoch [15/50], Train Loss: 0.1433, Val Loss: 0.0467\n",
            "Epoch [16/50], Train Loss: 0.1413, Val Loss: 0.0467\n",
            "Epoch [17/50], Train Loss: 0.1413, Val Loss: 0.0469\n",
            "Epoch [18/50], Train Loss: 0.1377, Val Loss: 0.0447\n",
            "Epoch [19/50], Train Loss: 0.1364, Val Loss: 0.0439\n",
            "Epoch [20/50], Train Loss: 0.1327, Val Loss: 0.0424\n",
            "Epoch [21/50], Train Loss: 0.1339, Val Loss: 0.0418\n",
            "Epoch [22/50], Train Loss: 0.1301, Val Loss: 0.0409\n",
            "Epoch [23/50], Train Loss: 0.1289, Val Loss: 0.0397\n",
            "Epoch [24/50], Train Loss: 0.1287, Val Loss: 0.0395\n",
            "Epoch [25/50], Train Loss: 0.1252, Val Loss: 0.0381\n",
            "Epoch [26/50], Train Loss: 0.1239, Val Loss: 0.0372\n",
            "Epoch [27/50], Train Loss: 0.1238, Val Loss: 0.0370\n",
            "Epoch [28/50], Train Loss: 0.1217, Val Loss: 0.0373\n",
            "Epoch [29/50], Train Loss: 0.1180, Val Loss: 0.0354\n",
            "Epoch [30/50], Train Loss: 0.1180, Val Loss: 0.0353\n",
            "Epoch [31/50], Train Loss: 0.1153, Val Loss: 0.0345\n",
            "Epoch [32/50], Train Loss: 0.1141, Val Loss: 0.0340\n",
            "Epoch [33/50], Train Loss: 0.1128, Val Loss: 0.0339\n",
            "Epoch [34/50], Train Loss: 0.1126, Val Loss: 0.0331\n",
            "Epoch [35/50], Train Loss: 0.1123, Val Loss: 0.0330\n",
            "Epoch [36/50], Train Loss: 0.1100, Val Loss: 0.0328\n",
            "Epoch [37/50], Train Loss: 0.1075, Val Loss: 0.0309\n",
            "Epoch [38/50], Train Loss: 0.1058, Val Loss: 0.0314\n",
            "Epoch [39/50], Train Loss: 0.1061, Val Loss: 0.0315\n",
            "Epoch [40/50], Train Loss: 0.1055, Val Loss: 0.0322\n",
            "Epoch [41/50], Train Loss: 0.1020, Val Loss: 0.0305\n",
            "Epoch [42/50], Train Loss: 0.1021, Val Loss: 0.0304\n",
            "Epoch [43/50], Train Loss: 0.1006, Val Loss: 0.0288\n",
            "Epoch [44/50], Train Loss: 0.0987, Val Loss: 0.0296\n",
            "Epoch [45/50], Train Loss: 0.0953, Val Loss: 0.0295\n",
            "Epoch [46/50], Train Loss: 0.0970, Val Loss: 0.0294\n",
            "Epoch [47/50], Train Loss: 0.0951, Val Loss: 0.0287\n",
            "Epoch [48/50], Train Loss: 0.0935, Val Loss: 0.0305\n",
            "Epoch [49/50], Train Loss: 0.0915, Val Loss: 0.0282\n",
            "Epoch [50/50], Train Loss: 0.0900, Val Loss: 0.0283\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¬ Processed Tensor Shapes (Training):\n",
            "X_tensor_flat shape: torch.Size([10000, 32])\n",
            "y_tensor shape: torch.Size([10000, 16])\n",
            "Calculated input feature size: 32\n",
            "Calculated output size (info bits): 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.4486, Val Loss: 0.2200\n",
            "Epoch [2/50], Train Loss: 0.2945, Val Loss: 0.1827\n",
            "Epoch [3/50], Train Loss: 0.2795, Val Loss: 0.1733\n",
            "Epoch [4/50], Train Loss: 0.2747, Val Loss: 0.1667\n",
            "Epoch [5/50], Train Loss: 0.2710, Val Loss: 0.1623\n",
            "Epoch [6/50], Train Loss: 0.2611, Val Loss: 0.1583\n",
            "Epoch [7/50], Train Loss: 0.2577, Val Loss: 0.1573\n",
            "Epoch [8/50], Train Loss: 0.2540, Val Loss: 0.1562\n",
            "Epoch [9/50], Train Loss: 0.2481, Val Loss: 0.1518\n",
            "Epoch [10/50], Train Loss: 0.2489, Val Loss: 0.1489\n",
            "Epoch [11/50], Train Loss: 0.2460, Val Loss: 0.1463\n",
            "Epoch [12/50], Train Loss: 0.2435, Val Loss: 0.1459\n",
            "Epoch [13/50], Train Loss: 0.2411, Val Loss: 0.1420\n",
            "Epoch [14/50], Train Loss: 0.2377, Val Loss: 0.1426\n",
            "Epoch [15/50], Train Loss: 0.2358, Val Loss: 0.1407\n",
            "Epoch [16/50], Train Loss: 0.2323, Val Loss: 0.1381\n",
            "Epoch [17/50], Train Loss: 0.2324, Val Loss: 0.1393\n",
            "Epoch [18/50], Train Loss: 0.2290, Val Loss: 0.1339\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5cd33294ba00>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;31m#KSA use this one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5cd33294ba00>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;31m# Train the RNN Decoder with multi-bit labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;31m# Pass the flattened X and original y tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finished training for {channel_name} Channel RNN Decoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5cd33294ba00>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, batch_size, validation_split)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5cd33294ba00>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5cd33294ba00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Flatten if input is not already 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Output shape: [batch_size, output_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDecoderTrainer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}