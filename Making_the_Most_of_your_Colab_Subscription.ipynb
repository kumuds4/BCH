{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NouaZL5DB5T",
        "outputId": "8373b8a0-4e64-42c0-9d1d-2c5021600466"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy Torch\n",
        "!pip install torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split  # If using train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import curve_fit  # For curve fitting\n",
        "from scipy.interpolate import interp1d # For interpolation\n",
        "import seaborn as sns  # For KDE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.interpolate import interp1d\n",
        "import seaborn as sns\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Logger configuration\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "\n",
        "class CRC:\n",
        "    def __init__(self, polynomial=0b10011011, order=7):\n",
        "        self.polynomial = polynomial\n",
        "        self.order = order\n",
        "\n",
        "    def generate_crc(self, data):\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.order, dtype=int)])\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.polynomial >> j) & 1)\n",
        "\n",
        "        return data_with_zeros[-self.order:]\n",
        "\n",
        "\n",
        "    def verify_crc(self, data, received_crc):\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.order + 1):\n",
        "                    full_data[i+j] ^= ((self.polynomial >> j) & 1)\n",
        "\n",
        "        return np.all(full_data[-self.order:] == 0)\n",
        "\n",
        "\n",
        "    # ... (existing CRC implementation)\n",
        "\n",
        "\n",
        "\n",
        "# Then, add the new PolarCodeGenerator class\n",
        "class PolarCodeGenerator:\n",
        "\n",
        "\n",
        "    def __init__(self, N=128, K=64):\n",
        "        self.N = N  # Total block length\n",
        "        self.K = K  # Number of information bits\n",
        "        self.R = K/N  # Code rate\n",
        "        self.crc = CRC()  # CRC object\n",
        "\n",
        "    def generate_polar_code_matrix(self):\n",
        "        \"\"\"\n",
        "        Generate channel polarization using Bhattacharyya parameter method\n",
        "        \"\"\"\n",
        "        def bhattacharyya_parameter(W, n):\n",
        "            if n == 0:\n",
        "                return W\n",
        "            W_used = bhattacharyya_parameter(W, n-1)\n",
        "            W_transform = 2 * W_used**2 - W_used**4\n",
        "            return W_transform\n",
        "\n",
        "        # Compute Bhattacharyya parameters for each channel\n",
        "        channel_capacities = []\n",
        "        for i in range(self.N):\n",
        "            W = 0.5  # Binary symmetric channel\n",
        "            capacity = bhattacharyya_parameter(W, int(np.log2(self.N)))\n",
        "            channel_capacities.append(capacity)\n",
        "\n",
        "        # Sort and select best channels for information bits\n",
        "        sorted_indices = np.argsort(channel_capacities)\n",
        "        info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "        return info_indices\n",
        "\n",
        "    def polar_transform(self, u):\n",
        "        \"\"\"\n",
        "        Recursive Polar Transform (Arıkan's Polarization Transform)\n",
        "        \"\"\"\n",
        "        n = int(np.log2(len(u)))\n",
        "        for i in range(n):\n",
        "            u1 = np.zeros(len(u), dtype=int)\n",
        "            for j in range(len(u) // 2):\n",
        "                # Butterfly operation\n",
        "                u1[2*j] = np.mod(u[j] + u[j + len(u)//2], 2)\n",
        "                u1[2*j + 1] = u[j + len(u)//2]\n",
        "            u = u1\n",
        "        return u\n",
        "\n",
        "    def encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Polar Encoding Process\n",
        "        1. Add CRC\n",
        "        2. Polar Encoding\n",
        "        \"\"\"\n",
        "        # Add CRC to information bits\n",
        "        crc_bits = self.crc.generate_crc(info_bits)\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Polar Encoding\n",
        "        encoded_bits = self._polar_encode(full_info)\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "    def _polar_encode(self, bits):\n",
        "        \"\"\"\n",
        "        Detailed Polar Encoding Implementation\n",
        "        \"\"\"\n",
        "        # Initialize codeword\n",
        "        x = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Determine information bit positions\n",
        "        info_indices = self.generate_polar_code_matrix()\n",
        "\n",
        "        # Assign information bits to selected indices\n",
        "        x[info_indices] = bits\n",
        "\n",
        "        # Polar transformation\n",
        "        n = int(np.log2(self.N))\n",
        "        for i in range(n):\n",
        "            for j in range(0, self.N, 2**(i+1)):\n",
        "                for k in range(2**i):\n",
        "                    # Butterfly operation\n",
        "                    u = x[j+k]\n",
        "                    v = x[j+k+2**i]\n",
        "                    x[j+k] = (u + v) % 2\n",
        "                    x[j+k+2**i] = v\n",
        "\n",
        "        return x\n",
        "\n",
        "    def systematic_polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding\n",
        "        Preserves original information bits in specific positions\n",
        "        \"\"\"\n",
        "        # Add CRC\n",
        "        crc_bits = self.crc.generate_crc(info_bits)\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        x = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Determine information bit positions\n",
        "        info_indices = self.generate_polar_code_matrix()\n",
        "\n",
        "        # Assign information bits to selected indices\n",
        "        x[info_indices] = full_info\n",
        "\n",
        "        # Polar transformation\n",
        "        n = int(np.log2(self.N))\n",
        "        for i in range(n):\n",
        "            for j in range(0, self.N, 2**(i+1)):\n",
        "                for k in range(2**i):\n",
        "                    # Butterfly operation\n",
        "                    u = x[j+k]\n",
        "                    v = x[j+k+2**i]\n",
        "                    x[j+k] = (u + v) % 2\n",
        "                    x[j+k+2**i] = v\n",
        "\n",
        "        return x  # ... (the entire implementation I just provided)\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N=128, K=64):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K/N\n",
        "        self.crc = CRC()\n",
        "\n",
        "    def generate_polar_code_matrix(self):\n",
        "        def bhattacharyya_parameter(W, n):\n",
        "            if n == 0:\n",
        "                return W\n",
        "            W_used = bhattacharyya_parameter(W, n-1)\n",
        "            W_transform = 2 * W_used**2 - W_used**4\n",
        "            return W_transform\n",
        "\n",
        "        channel_capacities = []\n",
        "        for i in range(self.N):\n",
        "            W = 0.5\n",
        "            capacity = bhattacharyya_parameter(W, int(np.log2(self.N)))\n",
        "            channel_capacities.append(capacity)\n",
        "\n",
        "        sorted_indices = np.argsort(channel_capacities)\n",
        "        info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "        return info_indices\n",
        "\n",
        "    def encode(self, info_bits):\n",
        "        crc_bits = self.crc.generate_crc(info_bits)\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "        encoded_bits = self._polar_encode(full_info)\n",
        "        return encoded_bits\n",
        "\n",
        "    def _polar_encode(self, bits):\n",
        "         n = int(np.log2(self.N))\n",
        "         x = np.zeros(self.N, dtype=int)\n",
        "         x[:len(bits)] = bits\n",
        "\n",
        "         for i in range(n):\n",
        "            for j in range(0, self.N, 2**(i+1)):\n",
        "                for k in range(2**i):\n",
        "                    u = x[j+k]\n",
        "                    v = x[j+k+2**i]\n",
        "                    x[j+k] = (u + v) % 2\n",
        "                    x[j+k+2**i] = v\n",
        "\n",
        "\n",
        "         return x  # Return the encoded bits\n",
        "class SCLDecoder:\n",
        "    def __init__(self, list_size=8):\n",
        "        self.list_size = list_size\n",
        "\n",
        "    def decode(self, received_signal, info_indices, block_length):\n",
        "        N = block_length  # Code length\n",
        "        K = len(info_indices)  # Number of information bits\n",
        "        L = self.list_size  # List size\n",
        "\n",
        "        # Initialize lists\n",
        "        active_paths = [([0] * K, 0)]  # (path, path metric)\n",
        "\n",
        "        for i in range(N):\n",
        "            new_paths = []\n",
        "            for path, metric in active_paths:\n",
        "                # Calculate likelihoods for 0 and 1\n",
        "                llr = self._calculate_llr(received_signal[i])  # Replace with your LLR calculation\n",
        "\n",
        "                # Extend paths for both 0 and 1\n",
        "                path0 = path + [0]\n",
        "                path1 = path + [1]\n",
        "\n",
        "                # Update path metrics\n",
        "                metric0 = metric + (0 if llr > 0 else -llr)\n",
        "                metric1 = metric + (0 if llr <= 0 else llr)\n",
        "\n",
        "                new_paths.extend([(path0, metric0), (path1, metric1)])\n",
        "\n",
        "            # Sort and prune paths\n",
        "            new_paths = sorted(new_paths, key=lambda x: x[1])  # Sort by path metric\n",
        "            active_paths = new_paths[:L]  # Keep only L best paths\n",
        "\n",
        "        # Select best path\n",
        "        best_path, _ = active_paths[0]\n",
        "\n",
        "        decoded_bits = np.array(best_path)  # Convert to numpy array\n",
        "        return decoded_bits[:K]  # Extract information bits\n",
        "\n",
        "    def _calculate_llr(self, received_symbol):\n",
        "        # Calculate Log-Likelihood Ratio (LLR)\n",
        "        # This is a placeholder and needs to be replaced with your actual LLR calculation logic\n",
        "        # Example: For AWGN channel\n",
        "        # llr = 2 * received_symbol / (noise_variance ** 2)\n",
        "        # ...\n",
        "        return 0 # Placeholder, replace with actual calculation\n",
        "\n",
        "class PolarCodeSimulation:\n",
        "    def __init__(self, block_length, info_bits, snr_range, hidden_layers, learning_rate, epochs, batch_size, list_sizes=[1, 8, 16]):\n",
        "        self.block_length = block_length\n",
        "        self.info_bits = info_bits\n",
        "        self.snr_range = snr_range\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.list_sizes = list_sizes\n",
        "\n",
        "        try:\n",
        "            # ... your code ...\n",
        "            logger.info(\"PolarCodeSimulation initialized successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"PolarCodeSimulation initialization error: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "    def plot_training_validation_loss(self, train_losses, val_losses):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Decoder Performance Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_ber_bler(self, snr_range, ber_traditional, ber_ml, bler_traditional, bler_ml):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # BER Plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.semilogy(snr_range, ber_traditional, label='Traditional BER')\n",
        "        plt.semilogy(snr_range, ber_ml, label='ML BER')\n",
        "        plt.title('Bit Error Rate')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('BER')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # BLER Plot\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.semilogy(snr_range, bler_traditional, label='Traditional BLER')\n",
        "        plt.semilogy(snr_range, bler_ml, label='ML BLER')\n",
        "        plt.title('Block Error Rate')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('BLER')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_training_metrics(self, train_losses, val_losses, snr_range,\n",
        "                               ber_traditional, ber_ml,\n",
        "                               bler_traditional, bler_ml,\n",
        "                               y_true, y_pred):\n",
        "        # Plot Training and Validation Loss\n",
        "        self.plot_training_validation_loss(train_losses, val_losses)\n",
        "\n",
        "        # Plot Confusion Matrix\n",
        "        self.plot_confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Plot BER/BLER\n",
        "        self.plot_ber_bler(snr_range, ber_traditional, ber_ml,\n",
        "                           bler_traditional, bler_ml)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate_performance(self, ml_model):\n",
        "        num_trials = 1000  # Number of simulations for each SNR\n",
        "        ber_traditional_list = {list_size: [] for list_size in self.list_sizes}\n",
        "        ber_ml_list = []\n",
        "        bler_traditional_list = {list_size: [] for list_size in self.list_sizes}\n",
        "        bler_ml_list = []\n",
        "        info_indices = self.polar_code_gen.generate_polar_code_matrix()  # Get info bit indices\n",
        "\n",
        "        for snr in self.snr_range:\n",
        "            for list_size in self.list_sizes:  # Iterate over the list sizes\n",
        "                ber_traditional = 0\n",
        "                ber_ml = 0\n",
        "                bler_traditional = 0\n",
        "                bler_ml = 0\n",
        "                scl_decoder = SCLDecoder(list_size=list_size)  # Create SCLDecoder with current list size\n",
        "\n",
        "                for _ in range(num_trials):\n",
        "                    info_bits = np.random.randint(2, size=self.info_bits)\n",
        "                    encoded_bits = self.polar_code_gen.encode(info_bits)\n",
        "                    received_signal = self.channel_simulator.transmit(encoded_bits, snr)\n",
        "\n",
        "                    # Traditional Decoding (SCL)\n",
        "                    decoded_bits_traditional = scl_decoder.decode(received_signal, info_indices, self.block_length)\n",
        "\n",
        "                    # ML Decoding\n",
        "                    received_signal_tensor = torch.tensor(received_signal, dtype=torch.float32).to(ml_model.device)\n",
        "                    decoded_bits_ml = ml_model(received_signal_tensor).cpu().detach().numpy()\n",
        "                    decoded_bits_ml = (decoded_bits_ml > 0.5).astype(int)\n",
        "\n",
        "                    # Calculate Errors\n",
        "                    ber_traditional += np.sum(np.abs(info_bits - decoded_bits_traditional)) / self.info_bits\n",
        "                    ber_ml += np.sum(np.abs(info_bits - decoded_bits_ml)) / self.info_bits\n",
        "                    bler_traditional += int(np.any(info_bits != decoded_bits_traditional))\n",
        "                    bler_ml += int(np.any(info_bits != decoded_bits_ml))\n",
        "\n",
        "                # Average Errors over Trials and store in the dictionaries\n",
        "                ber_traditional_list[list_size].append(ber_traditional / num_trials)\n",
        "                ber_ml_list.append(ber_ml / num_trials)\n",
        "                bler_traditional_list[list_size].append(bler_traditional / num_trials)\n",
        "                bler_ml_list.append(bler_ml / num_trials)\n",
        "\n",
        "        # Update simulation results\n",
        "        self.ber_traditional = ber_traditional_list\n",
        "        self.ber_ml = ber_ml_list\n",
        "        self.bler_traditional = bler_traditional_list\n",
        "        self.bler_ml = bler_ml_list\n",
        "\n",
        "        return ber_traditional_list, ber_ml_list, bler_traditional_list, bler_ml_list\n",
        "\n",
        "          # Evaluation and Plotting\n",
        "        ber_traditional, ber_ml, bler_traditional, bler_ml = self.evaluate_performance(trainer.model)  # Unpack results here\n",
        "        # Get y_true and y_pred (you might need to modify this based on your setup)\n",
        "        y_true = ...  # Replace ... with your actual y_true data\n",
        "        y_pred = ...  # Replace ... with your actual y_pred data\n",
        "\n",
        "        # Call the plotting functions\n",
        "        self.plot_training_metrics(train_losses, val_losses, self.snr_range,\n",
        "                                   ber_traditional, ber_ml,\n",
        "                                   bler_traditional, bler_ml,\n",
        "                                   y_true, y_pred)\n",
        "\n",
        "        self.plot_confusion_matrix(y_true, y_pred)  # Call confusion matrix plotting\n",
        "\n",
        "    def run_simulation(self):\n",
        "         # Training\n",
        "          model = MLPolarDecoder(input_size=self.block_length, hidden_layers=self.hidden_layers, output_size=self.info_bits)\n",
        "          trainer = MLTrainer(model, learning_rate=self.learning_rate)\n",
        "          X_train, y_train = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "         #model = MLPolarDecoder(input_size=self.block_length, hidden_layers=self.hidden_layers, output_size=self.info_bits)\n",
        "         #trainer = MLTrainer(model, learning_rate=self.learning_rate)\n",
        "         #X_train, y_train = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "          train_losses, val_losses = trainer.train(X_train, y_train, epochs=self.epochs, batch_size=self.batch_size)\n",
        "\n",
        "         # Evaluation and Plotting\n",
        "          ber_traditional, ber_ml, bler_traditional, bler_ml = self.evaluate_performance(trainer.model)  # Unpack results here\n",
        "\n",
        "         # Assuming you have a separate dataset for evaluation:\n",
        "          X_eval, y_true = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)  # Example for generating evaluation data\n",
        "          received_signal_tensor = torch.tensor(X_eval, dtype=torch.float32).to(trainer.device)  # Convert to tensor and move to device\n",
        "          y_pred = trainer.model(received_signal_tensor).cpu().detach().numpy()  # Get predictions using the trained model\n",
        "          y_pred = (y_pred > 0.5).astype(int)  # Convert to binary\n",
        "\n",
        "          # Call the plotting functions with y_true and y_pred\n",
        "          self.plot_training_metrics(train_losses, val_losses, self.snr_range,\n",
        "                               ber_traditional, ber_ml,\n",
        "                               bler_traditional, bler_ml,\n",
        "                               y_true, y_pred)\n",
        "\n",
        "         # Call the plotting functions with y_true and y_pred\n",
        "          self.plot_ber_bler(self.snr_range,\n",
        "                             ber_traditional, ber_ml,\n",
        "                             bler_traditional, bler_ml,\n",
        "                             ber_traditional, ber_ml,\n",
        "                             bler_traditional, bler_ml)  # Duplicate for both AWGN and Rayleigh for now\n",
        "    #self.plot_ber_bler(snr_range, ber_traditional, ber_ml, bler_traditional, bler_ml) # Assuming plot_ber_bler in the same class\n",
        "\n",
        "\n",
        "          self.plot_confusion_matrix(y_true, y_pred)  # Call confusion matrix plotting\n",
        "    #def plot_training_metrics(self, train_losses, val_losses, snr_range, ber_traditional, ber_ml, bler_traditional, bler_ml):\n",
        "    #    plt.figure(figsize=(15, 10))\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "#simulation = PolarCodeSimulation()\n",
        "#simulation.run_simulation()\n",
        "\n",
        "class ListDecoder:\n",
        "    def __init__(self, list_size=8):\n",
        "        self.list_size = list_size\n",
        "\n",
        "    def decode(self, received_signal):\n",
        "        # Placeholder for list decoding algorithm\n",
        "        # Implement Tal-Vardy list decoding\n",
        "        pass\n",
        "\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        if self.channel_type == 'AWGN':\n",
        "            return self.awgn_channel(signal, snr)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            return self.rayleigh_fading_channel(signal, snr)\n",
        "\n",
        "    def awgn_channel(self, signal, snr):\n",
        "        noise_std = 10 ** (-snr/20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "    def rayleigh_fading_channel(self, signal, snr):\n",
        "        fading_coeff = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "        noisy_signal = fading_coeff * signal\n",
        "        noise_std = 10 ** (-snr/20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return noisy_signal + noise\n",
        "\n",
        "class MLPolarDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, output_size):\n",
        "        super(MLPolarDecoder, self).__init__()\n",
        "        layers = []\n",
        "        # Dynamic layer creation\n",
        "        prev_size = input_size\n",
        "        for i, hidden_size in enumerate(hidden_layers):\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            # Change the num_features to 128 for the first InstanceNorm1d:\n",
        "            if i == 0:  # For the first InstanceNorm1d layer\n",
        "                layers.append(nn.InstanceNorm1d(128, affine=True))  # num_features=128\n",
        "            else:\n",
        "                layers.append(nn.InstanceNorm1d(hidden_size, affine=True))  # num_features=hidden_size\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.3))\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, output_size))\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.to(self.device)  # Move the model to the device\n",
        "\n",
        "    def forward(self, x):\n",
        "          x = torch.unsqueeze(x, 1)  # Adds a dimension of size 1 at position 1\n",
        "          return self.model(x)\n",
        "\n",
        "class PolarCodeTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=5\n",
        "        )\n",
        "\n",
        "   # def train(self, X_train, y_train, epochs=50, batch_size=64):\n",
        "\n",
        "def train(self, X_train, y_train, epochs=100, batch_size=32):\n",
        "    # 1. Split data using train_test_split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "    train_losses = []\n",
        "    val_losses = []  # Initialize list for validation losses\n",
        "\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        self.model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x = batch_x.to(self.device)\n",
        "            batch_y = batch_y.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_x)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        self.scheduler.step(avg_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        # Calculate validation loss\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = self.model(X_val.to(self.device))\n",
        "            val_loss = self.criterion(val_outputs, y_val.to(self.device))\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "    return train_losses, val_losses # The return is outside the loop\n",
        "\n",
        "class MLPolarDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, output_size):\n",
        "        #self.model = model\n",
        "        # Access device through the model\n",
        "        #self.device = self.model.device  # Add this line\n",
        "        #self.model.to(self.device)\n",
        "\n",
        "        super(MLPolarDecoder, self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Define device here\n",
        "        layers = []\n",
        "        # Dynamic layer creation\n",
        "        prev_size = input_size\n",
        "        for i, hidden_size in enumerate(hidden_layers):\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            # Reshape the input for BatchNorm1d\n",
        "            if i == 0:  # Only for the first BatchNorm1d layer\n",
        "                layers.append(ReshapeLayer((-1, hidden_size)))  # Reshape to (batch_size, hidden_size)\n",
        "            layers.append(nn.BatchNorm1d(hidden_size))  # num_features=hidden_size\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.3))\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, output_size))\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.to(self.device)  # Move the model to the device\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Custom Reshape Layer\n",
        "class ReshapeLayer(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(ReshapeLayer, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)\n",
        "\n",
        "\n",
        "    #def forward(self, x):\n",
        "       #  x = x.to(self.device)  # Move input to the device\n",
        "        # x = torch.unsqueeze(x, 1)  # Add a dimension to make it 2D\n",
        "        # ... your model calculations ...\n",
        "         #output = self.model(x) # Assuming self.model is your sequential model\n",
        "         #return output\n",
        "       # return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.device = self.model.device # Add this line\n",
        "        self.model.to(self.device)\n",
        "      #  input_tensor = input_tensor.to(self.device)\n",
        "        # Loss and Optimizer\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=5\n",
        "        )\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, batch_size=32):\n",
        "        # 1. Split data using train_test_split\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=42\n",
        "        )\n",
        "        train_losses = []\n",
        "        val_losses = []  # Initialize list for validation losses\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for batch_x, batch_y in dataloader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(batch_x)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            self.scheduler.step(avg_loss)\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
        "\n",
        "            # Calculate validation loss\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val.to(self.device))\n",
        "                val_loss = self.criterion(val_outputs, y_val.to(self.device))\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "        return train_losses, val_losses # The return is inside the loop\n",
        "\n",
        "\n",
        "\n",
        "             #  return (torch.FloatTensor(X_train),\n",
        "              #     torch.FloatTensor(y_train))\n",
        "\n",
        "def generate_training_data(self, num_samples, block_length, snr_range):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "\n",
        "    polar_code_gen = PolarCodeGenerator(N=block_length, K=block_length // 2)\n",
        "\n",
        "    # Outer loop to iterate through SNR values\n",
        "    for snr in snr_range:\n",
        "        # Inner loop to generate samples for each SNR value\n",
        "        for _ in range(num_samples):\n",
        "            # 1. Generate random information bits\n",
        "            info_bits = np.random.randint(2, size=block_length // 2)\n",
        "\n",
        "            # 2. Encode the information bits\n",
        "            encoded_bits = polar_code_gen.encode(info_bits)\n",
        "\n",
        "            # 3. Apply channel noise\n",
        "            noisy_signal = self._apply_channel_noise(encoded_bits, snr)  # Replace with your channel noise application logic\n",
        "\n",
        "            # 4. Append to X_train and y_train\n",
        "            X_train.append(noisy_signal)\n",
        "            y_train.append(info_bits)\n",
        "\n",
        "    # Convert to single NumPy arrays\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Check final shapes after generation (should be (1000, 128) and (1000, 64) respectively)\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"X_train dtype:\", X_train.dtype)\n",
        "    print(\"y_train dtype:\", y_train.dtype)\n",
        "\n",
        "    return torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    def _polar_encode(self, bits):\n",
        "        # Simplified polar encoding\n",
        "        # Implement actual polar encoding logic\n",
        "        return bits\n",
        "\n",
        "    def _apply_channel_noise(self, signal, snr):\n",
        "        # AWGN channel simulation\n",
        "        noise_std = 10 ** (-snr/20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "\n",
        "\n",
        "    # (Optional: Access results and plot separately if needed)\n",
        "    # ber_traditional, ber_ml, bler_traditional, bler_ml = simulation.evaluate_performance(trainer.model)\n",
        "    # simulation.plot_training_metrics(trainer.train_losses, trainer.val_losses, SNR_RANGE, ber_traditional, ber_ml, bler_traditional, bler_ml, [], [])  # Assuming you have y_true and y_pred\n",
        "    # simulation.plot_confusion_matrix([], [])  # Assuming you have y_true and y_pred\n",
        "\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.device = self.model.device\n",
        "        self.model.to(self.device)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, batch_size=32):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for batch_x, batch_y in dataloader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(batch_x)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            train_losses.append(avg_loss)\n",
        "            self.scheduler.step(avg_loss)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val.to(self.device))\n",
        "                val_loss = self.criterion(val_outputs, y_val.to(self.device))\n",
        "                val_losses.append(val_loss.item())\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def generate_training_data(self, num_samples, block_length, snr_range):\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        polar_code_gen = PolarCodeGenerator(N=block_length, K=block_length // 2)\n",
        "        for snr in snr_range:\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = np.random.randint(2, size=block_length // 2)\n",
        "                encoded_bits = polar_code_gen.encode(info_bits)\n",
        "                noisy_signal = self._apply_channel_noise(encoded_bits, snr)\n",
        "                X_train.append(noisy_signal)\n",
        "                y_train.append(info_bits)\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        print(\"X_train shape:\", X_train.shape)\n",
        "        print(\"y_train shape:\", y_train.shape)\n",
        "        print(\"X_train dtype:\", X_train.dtype)\n",
        "        print(\"y_train dtype:\", y_train.dtype)\n",
        "        return torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    def _apply_channel_noise(self, signal, snr):\n",
        "        noise_std = 10**(-snr / 20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        if self.channel_type == 'AWGN':\n",
        "            return self.awgn_channel(signal, snr)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            return self.rayleigh_fading_channel(signal, snr)\n",
        "\n",
        "    def awgn_channel(self, signal, snr):\n",
        "        noise_std = 10**(-snr / 20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "    def rayleigh_fading_channel(self, signal, snr):\n",
        "        fading_coeff = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "        noisy_signal = fading_coeff * signal\n",
        "        noise_std = 10**(-snr / 20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return noisy_signal + noise\n",
        "\n",
        "class PolarCodeSimulation:\n",
        "    def __init__(self, block_length, info_bits, snr_range, hidden_layers,\n",
        "                 learning_rate, epochs, batch_size, list_sizes=[1, 8, 16]):\n",
        "        \"\"\"\n",
        "        Initialize Polar Code Simulation\n",
        "         # Initialize ChannelSimulator\n",
        "        #self.channel_simulator = ChannelSimulator()  # Create an instance\n",
        "\n",
        "        Args:\n",
        "            block_length (int): Total block length\n",
        "            info_bits (int): Number of information bits\n",
        "            snr_range (np.ndarray): Signal-to-Noise Ratio range\n",
        "            hidden_layers (list): Neural network hidden layer configuration\n",
        "            learning_rate (float): Learning rate for training\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            list_sizes (list): List of SCL decoder list sizes\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.block_length = block_length\n",
        "            self.info_bits = info_bits\n",
        "            self.snr_range = snr_range\n",
        "            self.hidden_layers = hidden_layers\n",
        "            self.learning_rate = learning_rate\n",
        "            self.epochs = epochs\n",
        "            self.batch_size = batch_size\n",
        "            self.list_sizes = list_sizes\n",
        "            self.channel_simulator = ChannelSimulator()  # Create an instance\n",
        "\n",
        "            logger.info(\"PolarCodeSimulation initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"PolarCodeSimulation initialization error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def plot_training_validation_loss(self, train_losses, val_losses):\n",
        "        \"\"\"\n",
        "        Plot training and validation losses\n",
        "\n",
        "        Args:\n",
        "            train_losses (list): Training losses\n",
        "            val_losses (list): Validation losses\n",
        "        \"\"\"\n",
        "        try:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(train_losses, label='Training Loss')\n",
        "            plt.plot(val_losses, label='Validation Loss')\n",
        "            plt.title('Training and Validation Loss')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Training loss plot error: {e}\")\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred, title='Decoder Performance Confusion Matrix'):\n",
        "        \"\"\"\n",
        "        Plot confusion matrix\n",
        "\n",
        "        Args:\n",
        "            y_true (np.ndarray): True labels\n",
        "            y_pred (np.ndarray): Predicted labels\n",
        "            title (str): Plot title\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import seaborn as sns\n",
        "            from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "            # Ensure 1D arrays\n",
        "            y_true = y_true.ravel()\n",
        "            y_pred = y_pred.ravel()\n",
        "\n",
        "            # Compute confusion matrix\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "            # Compute classification report\n",
        "            cr = classification_report(y_true, y_pred)\n",
        "            print(\"Classification Report:\\n\", cr)\n",
        "\n",
        "            # Plot\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "                        yticklabels=['Actual 0', 'Actual 1'])\n",
        "            plt.title(title)\n",
        "            plt.xlabel('Predicted Label')\n",
        "            plt.ylabel('True Label')\n",
        "\n",
        "            # Add performance metrics to the plot\n",
        "            plt.text(0.5, -0.15,\n",
        "                     f'Classification Report:\\n{cr}',\n",
        "                     horizontalalignment='center',\n",
        "                     verticalalignment='center',\n",
        "                     transform=plt.gca().transAxes,\n",
        "                     bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Confusion matrix plot error: {e}\")\n",
        "\n",
        "    def plot_ber_bler(self, snr_range, ber_traditional, ber_ml,\n",
        "                       bler_traditional, bler_ml, channel_type):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        for list_size in self.list_sizes:\n",
        "        # Extract BER/BLER data for the current list size\n",
        "            ber_traditional = performance_results[list_size]['ber_traditional']\n",
        "            ber_ml = performance_results[list_size]['ber_ml']\n",
        "            bler_traditional = performance_results[list_size]['bler_traditional']\n",
        "            bler_ml = performance_results[list_size]['bler_ml']\n",
        "\n",
        "        # Create subplots for BER and BLER\n",
        "            plt.subplot(1, 2, 1)  # BER subplot\n",
        "            plt.semilogy(snr_range, ber_traditional, label=f'Traditional BER (List Size {list_size})')\n",
        "            plt.semilogy(snr_range, ber_ml, label=f'ML BER (List Size {list_size})')\n",
        "        # ... (rest of BER plot settings) ...\n",
        "\n",
        "            plt.subplot(1, 2, 2)  # BLER subplot\n",
        "            plt.semilogy(snr_range, bler_traditional, label=f'Traditional BLER (List Size {list_size})')\n",
        "            plt.semilogy(snr_range, bler_ml, label=f'ML BLER (List Size {list_size})')\n",
        "        # ... (rest of BLER plot settings) ...\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        #except Exception as e:\n",
        "         #   logger.error(f\"BER/BLER plot error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_training_metrics(self, train_losses, val_losses, snr_range,\n",
        "                               ber_traditional, ber_ml,\n",
        "                               bler_traditional, bler_ml,\n",
        "                               y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Comprehensive plotting of training metrics\n",
        "\n",
        "        Args:\n",
        "            train_losses (list): Training losses\n",
        "            val_losses (list): Validation losses\n",
        "            snr_range (np.ndarray): Signal-to-Noise Ratio range\n",
        "            ber_traditional (list): Traditional decoder BER\n",
        "            ber_ml (list): Machine Learning decoder BER\n",
        "            bler_traditional (list): Traditional decoder BLER\n",
        "            bler_ml (list): Machine Learning decoder BLER\n",
        "            y_true (np.ndarray): True labels\n",
        "            y_pred (np.ndarray): Predicted labels\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Plot Training and Validation Loss\n",
        "            self.plot_training_validation_loss(train_losses, val_losses)\n",
        "\n",
        "            # Plot Confusion Matrix\n",
        "            self.plot_confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Training metrics plot error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def run_simulation(self):\n",
        "    \"\"\"\n",
        "    Runs the Polar Code simulation, trains the ML model, evaluates performance, and generates plots.\n",
        "    \"\"\"\n",
        "    # Training\n",
        "    model = MLPolarDecoder(input_size=self.block_length, hidden_layers=self.hidden_layers, output_size=self.info_bits)\n",
        "    trainer = MLTrainer(model, learning_rate=self.learning_rate)\n",
        "    X_train, y_train = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "    train_losses, val_losses = trainer.train(X_train, y_train, epochs=self.epochs, batch_size=self.batch_size)\n",
        "\n",
        "    # Evaluation and Plotting\n",
        "    ber_traditional, ber_ml, bler_traditional, bler_ml = self.evaluate_performance(trainer.model)\n",
        "\n",
        "    # Generate evaluation data and predictions\n",
        "    X_eval, y_true = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "    received_signal_tensor = torch.tensor(X_eval, dtype=torch.float32).to(trainer.device)\n",
        "    y_pred = trainer.model(received_signal_tensor).cpu().detach().numpy()\n",
        "    y_pred = (y_pred > 0.5).astype(int)  # Convert to binary\n",
        "\n",
        "    # Call the plotting functions\n",
        "    self.plot_training_metrics(train_losses, val_losses, self.snr_range,\n",
        "                               ber_traditional, ber_ml,\n",
        "                               bler_traditional, bler_ml,\n",
        "                               y_true.cpu().numpy(), y_pred)  # Pass y_true as NumPy array\n",
        "\n",
        "    self.plot_confusion_matrix(y_true.cpu().numpy(), y_pred)  # Pass y_true as NumPy array\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Hyperparameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 10\n",
        "        BATCH_SIZE = 64\n",
        "        SNR_RANGE = np.linspace(0, 15, 16)\n",
        "        LIST_SIZES = [1, 8, 16]\n",
        "        HIDDEN_LAYERS = [128, 256, 128]\n",
        "\n",
        "        # Logging simulation start\n",
        "        logger.info(\"Starting Polar Code Simulation\")\n",
        "\n",
        "        # Initialize Neural Network Model\n",
        "        model = MLPolarDecoder(\n",
        "            input_size=BLOCK_LENGTH,\n",
        "            hidden_layers=HIDDEN_LAYERS,\n",
        "            output_size=INFO_BITS\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer\n",
        "        trainer = MLTrainer(model, learning_rate=LEARNING_RATE)\n",
        "\n",
        "        # Generate Training Data\n",
        "        X_train, y_train = trainer.generate_training_data(\n",
        "            num_samples=1000,\n",
        "            block_length=BLOCK_LENGTH,\n",
        "            snr_range=SNR_RANGE\n",
        "        )\n",
        "\n",
        "        # Training Process\n",
        "        train_losses, val_losses = trainer.train(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Tensor conversion and prediction\n",
        "        y_true = y_train.cpu().numpy()\n",
        "        y_pred = model(X_train.to(model.device)).sigmoid().cpu().detach().numpy()\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        # Ensure 1D arrays\n",
        "        y_true = y_true.ravel()\n",
        "        y_pred = y_pred.ravel()\n",
        "\n",
        "        # Initialize Simulation\n",
        "        simulation = PolarCodeSimulation(\n",
        "            block_length=BLOCK_LENGTH,\n",
        "            info_bits=INFO_BITS,\n",
        "            snr_range=SNR_RANGE,\n",
        "            hidden_layers=HIDDEN_LAYERS,\n",
        "            learning_rate=LEARNING_RATE,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            list_sizes=LIST_SIZES\n",
        "        )\n",
        "\n",
        "        # Evaluate Performance\n",
        "        performance_results = evaluate_performance(\n",
        "            trainer, BLOCK_LENGTH, INFO_BITS, SNR_RANGE,\n",
        "            channel_type='AWGN'\n",
        "        )\n",
        "\n",
        "        # Plot Training Metrics\n",
        "        simulation.plot_training_metrics(\n",
        "            train_losses,\n",
        "            val_losses,\n",
        "            SNR_RANGE,\n",
        "            performance_results['ber_traditional'],\n",
        "            performance_results['ber_ml'],\n",
        "            performance_results['bler_traditional'],\n",
        "            performance_results['bler_ml'],\n",
        "            y_true,\n",
        "            y_pred\n",
        "        )\n",
        "\n",
        "        # Plot BER/BLER\n",
        "        simulation.plot_ber_bler(\n",
        "            SNR_RANGE,\n",
        "            performance_results['ber_traditional'],\n",
        "            performance_results['ber_ml'],\n",
        "            performance_results['bler_traditional'],\n",
        "            performance_results['bler_ml'],\n",
        "            'AWGN'\n",
        "        )\n",
        "\n",
        "        logger.info(\"Polar Code Simulation completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Simulation failed: {e}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1SUS-fi6DPZj",
        "outputId": "98e6e3bf-19be-4778-9ab5-f524b7397dc6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from Torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from Torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from Torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from Torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from Torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from Torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from Torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from Torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from Torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from Torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from Torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from Torch) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from Torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from Torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from Torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from Torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from Torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from Torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from Torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from Torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->Torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->Torch) (3.0.2)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cufft-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cufft-cu12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-03 15:30:20,869 - __main__ - INFO - Starting Polar Code Simulation\n",
            "INFO:__main__:Starting Polar Code Simulation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (16000, 128)\n",
            "y_train shape: (16000, 64)\n",
            "X_train dtype: float64\n",
            "y_train dtype: int64\n",
            "Epoch 0: Loss = 0.7034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-03 15:30:46,762 - __main__ - INFO - PolarCodeSimulation initialized successfully\n",
            "INFO:__main__:PolarCodeSimulation initialized successfully\n",
            "2025-04-03 15:30:46,764 - __main__ - ERROR - Simulation failed: name 'evaluate_performance' is not defined\n",
            "ERROR:__main__:Simulation failed: name 'evaluate_performance' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate_performance' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5a4e5e4a6daa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5a4e5e4a6daa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;31m# Evaluate Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         performance_results = evaluate_performance(\n\u001b[0m\u001b[1;32m   1118\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCK_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINFO_BITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNR_RANGE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mchannel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AWGN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_performance' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_simulation(self):\n",
        "    \"\"\"\n",
        "    Runs the Polar Code simulation, trains the ML model, evaluates performance, and generates plots.\n",
        "    \"\"\"\n",
        "    # Training\n",
        "    model = MLPolarDecoder(input_size=self.block_length, hidden_layers=self.hidden_layers, output_size=self.info_bits)\n",
        "    trainer = MLTrainer(model, learning_rate=self.learning_rate)\n",
        "    X_train, y_train = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "    train_losses, val_losses = trainer.train(X_train, y_train, epochs=self.epochs, batch_size=self.batch_size)\n",
        "\n",
        "    # Evaluation and Plotting\n",
        "    ber_traditional, ber_ml, bler_traditional, bler_ml = self.evaluate_performance(trainer.model)\n",
        "\n",
        "    # Generate evaluation data and predictions\n",
        "    X_eval, y_true = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "    received_signal_tensor = torch.tensor(X_eval, dtype=torch.float32).to(trainer.device)\n",
        "    y_pred = trainer.model(received_signal_tensor).cpu().detach().numpy()\n",
        "    y_pred = (y_pred > 0.5).astype(int)  # Convert to binary\n",
        "\n",
        "    # Call the plotting functions\n",
        "    self.plot_training_metrics(train_losses, val_losses, self.snr_range,\n",
        "                               ber_traditional, ber_ml,\n",
        "                               bler_traditional, bler_ml,\n",
        "                               y_true.cpu().numpy(), y_pred)  # Pass y_true as NumPy array\n",
        "\n",
        "    self.plot_confusion_matrix(y_true.cpu().numpy(), y_pred)  # Pass y_true as NumPy array"
      ],
      "metadata": {
        "id": "gDHoJOSKR3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "class CRC:\n",
        "    def __init__(self, polynomial=0b10011011, order=7):\n",
        "        self.polynomial = polynomial\n",
        "        self.order = order\n",
        "\n",
        "    def generate_crc(self, data):\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.order, dtype=int)])\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.polynomial >> j) & 1)\n",
        "\n",
        "        return data_with_zeros[-self.order:]\n",
        "\n",
        "    def verify_crc(self, data, received_crc):\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.order + 1):\n",
        "                    full_data[i+j] ^= ((self.polynomial >> j) & 1)\n",
        "\n",
        "        return np.all(full_data[-self.order:] == 0)\n",
        "\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N=128, K=64):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K/N\n",
        "        self.crc = CRC()\n",
        "\n",
        "    def generate_polar_code_matrix(self):\n",
        "        def bhattacharyya_parameter(W, n):\n",
        "            if n == 0:\n",
        "                return W\n",
        "            W_used = bhattacharyya_parameter(W, n-1)\n",
        "            W_transform = 2 * W_used**2 - W_used**4\n",
        "            return W_transform\n",
        "\n",
        "        channel_capacities = []\n",
        "        for i in range(self.N):\n",
        "            W = 0.5\n",
        "            capacity = bhattacharyya_parameter(W, int(np.log2(self.N)))\n",
        "            channel_capacities.append(capacity)\n",
        "\n",
        "        sorted_indices = np.argsort(channel_capacities)\n",
        "        info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "        return info_indices\n",
        "\n",
        "    def encode(self, info_bits):\n",
        "        crc_bits = self.crc.generate_crc(info_bits)\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "        encoded_bits = self._polar_encode(full_info)\n",
        "        return encoded_bits\n",
        "\n",
        "    def _polar_encode(self, bits):\n",
        "        n = int(np.log2(self.N))\n",
        "        x = np.zeros(self.N, dtype=int)\n",
        "        x[:len(bits)] = bits\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(0, self.N, 2**(i+1)):\n",
        "                for k in range(2**i):\n",
        "                    u = x[j+k]\n",
        "                    v = x[j+k+2**i]\n",
        "                    x[j+k] = (u + v) % 2\n",
        "                    x[j+k+2**i] = v\n",
        "\n",
        "        return x\n",
        "\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        if self.channel_type == 'AWGN':\n",
        "            return self.awgn_channel(signal, snr)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            return self.rayleigh_fading_channel(signal, snr)\n",
        "\n",
        "    def awgn_channel(self, signal, snr):\n",
        "        noise_std = 10 ** (-snr/20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return signal + noise\n",
        "\n",
        "    def rayleigh_fading_channel(self, signal, snr):\n",
        "        fading_coeff = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "        noisy_signal = fading_coeff * signal\n",
        "        noise_std = 10 ** (-snr/20)\n",
        "        noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        return noisy_signal + noise\n",
        "\n",
        "class SCLDecoder:\n",
        "    def __init__(self, N, K, list_size=8):\n",
        "        self.N = N  # Code length\n",
        "        self.K = K  # Number of information bits\n",
        "        self.list_size = list_size\n",
        "\n",
        "    def decode(self, received_signal, info_indices):\n",
        "        L = self.list_size  # List size\n",
        "        active_paths = [([0] * self.K, 0)]  # (path, path metric)\n",
        "\n",
        "        for i in range(self.N):\n",
        "            new_paths = []\n",
        "            for path, metric in active_paths:\n",
        "                llr = self._calculate_llr(received_signal[i])\n",
        "\n",
        "                # Extend paths for both 0 and 1\n",
        "                path0 = path + [0]\n",
        "                path1 = path + [1]\n",
        "\n",
        "                # Update path metrics\n",
        "                metric0 = metric + (0 if llr > 0 else -llr)  # If llr > 0, bit is likely 0, so no penalty\n",
        "                metric1 = metric + (0 if llr <= 0 else llr) # If llr <= 0, bit is likely 1, so no penalty\n",
        "\n",
        "                new_paths.extend([(path0, metric0), (path1, metric1)])\n",
        "\n",
        "            # Sort and prune paths\n",
        "            new_paths.sort(key=lambda x: x[1])  # Sort by path metric\n",
        "            active_paths = new_paths[:L]  # Keep only L best paths\n",
        "\n",
        "        # Select best path\n",
        "        best_path, _ = active_paths[0]\n",
        "\n",
        "        decoded_bits = np.array(best_path)\n",
        "        return decoded_bits  # Return the decoded bits\n",
        "\n",
        "    def _calculate_llr(self, received_symbol):\n",
        "        # Placeholder for LLR calculation logic (replace with actual implementation)\n",
        "        # Example for AWGN channel:\n",
        "        llr = 2 * received_symbol / (noise_variance ** 2)\n",
        "        return 0  # Placeholder, replace with actual LLR calculation\n",
        "\n",
        "\n",
        "\n",
        "class PolarCodeSimulation:\n",
        "    def __init__(self, block_length, info_bits, snr_range, hidden_layers, learning_rate, epochs, batch_size, list_sizes=[1, 8, 16]):\n",
        "        self.block_length = block_length\n",
        "        self.info_bits = info_bits\n",
        "        self.snr_range = snr_range\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.list_sizes = list_sizes\n",
        "        self.channel_simulator = ChannelSimulator()\n",
        "        self.polar_code_gen = PolarCodeGenerator(N=block_length, K=info_bits) # Initialize polar_code_gen\n",
        "\n",
        "    def run_simulation(self):\n",
        "        \"\"\"\n",
        "        Runs the Polar Code simulation, trains the ML model, evaluates performance, and generates plots.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Training\n",
        "            # Training\n",
        "            model = MLPolarDecoder(input_size=self.block_length, hidden_layers=self.hidden_layers, output_size=self.info_bits)\n",
        "            trainer = MLTrainer(model, learning_rate=self.learning_rate)\n",
        "            X_train, y_train = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range, polar_code_gen=self.polar_code_gen)  # Pass polar_code_gen here\n",
        "            # ... (rest of your code) ...\n",
        "            train_losses, val_losses = trainer.train(X_train, y_train, epochs=self.epochs, batch_size=self.batch_size)\n",
        "\n",
        "            # Performance Evaluation\n",
        "            performance_results_awgn = self.evaluate_performance(trainer.model, self.polar_code_gen, channel_type='AWGN')\n",
        "            performance_results_rayleigh = self.evaluate_performance(trainer.model, self.polar_code_gen, channel_type='Rayleigh')\n",
        "\n",
        "\n",
        "            # Evaluation and Plotting\n",
        "            ber_traditional_awgn, ber_ml_awgn, bler_traditional_awgn, bler_ml_awgn = self.evaluate_performance(trainer.model, channel_type='AWGN')\n",
        "            ber_traditional_rayleigh, ber_ml_rayleigh, bler_traditional_rayleigh, bler_ml_rayleigh = self.evaluate_performance(trainer.model, channel_type='Rayleigh')\n",
        "\n",
        "            # Generate evaluation data and predictions for AWGN\n",
        "            X_eval_awgn, y_true_awgn = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "            received_signal_tensor_awgn = torch.tensor(X_eval_awgn, dtype=torch.float32).to(trainer.device)\n",
        "            y_pred_awgn = trainer.model(received_signal_tensor_awgn).cpu().detach().numpy()\n",
        "            y_pred_awgn = (y_pred_awgn > 0.5).astype(int)\n",
        "\n",
        "            # Generate evaluation data and predictions for Rayleigh\n",
        "            X_eval_rayleigh, y_true_rayleigh = trainer.generate_training_data(num_samples=1000, block_length=self.block_length, snr_range=self.snr_range)\n",
        "            received_signal_tensor_rayleigh = torch.tensor(X_eval_rayleigh, dtype=torch.float32).to(trainer.device)\n",
        "            y_pred_rayleigh = trainer.model(received_signal_tensor_rayleigh).cpu().detach().numpy()\n",
        "            y_pred_rayleigh = (y_pred_rayleigh > 0.5).astype(int)  # Convert to binary\n",
        "\n",
        "\n",
        "            # Call the plotting functions for combined plot\n",
        "            self.plot_ber_bler(self.snr_range, ber_traditional_awgn, ber_ml_awgn, bler_traditional_awgn, bler_ml_awgn,\n",
        "                               ber_traditional_rayleigh, ber_ml_rayleigh, bler_traditional_rayleigh, bler_ml_rayleigh)\n",
        "\n",
        "            self.plot_confusion_matrix(y_true_awgn.cpu().numpy(), y_pred_awgn)  # Assuming you want the confusion matrix for AWGN\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during simulation: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "class MLPolarDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, output_size):\n",
        "        super(MLPolarDecoder, self).__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.BatchNorm1d(hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.3))\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, output_size))\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3, epochs=50):\n",
        "        self.model = model\n",
        "        self.device = model.device\n",
        "        self.epochs = epochs\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        # Modify scheduler to use epochs\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer,\n",
        "            T_max=epochs\n",
        "        )\n",
        "      #  self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "       #     self.optimizer,\n",
        "        #    mode='min',\n",
        "         #   factor=0.5,\n",
        "          #  patience=5\n",
        "        #)\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=100, batch_size=32):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=42\n",
        "        )\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for batch_x, batch_y in dataloader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(batch_x)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val.to(self.device))\n",
        "                val_loss = self.criterion(val_outputs, y_val.to(self.device))\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            self.scheduler.step(avg_loss)\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: Train Loss = {avg_loss:.4f}, Val Loss = {val_loss.item():.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def generate_training_data(self, num_samples, block_length, snr_range):\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        polar_code_gen = PolarCodeGenerator(N=block_length, K=block_length // 2)\n",
        "        channel_sim = ChannelSimulator()\n",
        "\n",
        "        for snr in snr_range:\n",
        "            for _ in range(num_samples):\n",
        "                info_bits = np.random.randint(2, size=block_length // 2)\n",
        "                encoded_bits = polar_code_gen.encode(info_bits)\n",
        "                noisy_signal = channel_sim.transmit(encoded_bits, snr)\n",
        "\n",
        "                X_train.append(noisy_signal)\n",
        "                y_train.append(info_bits)\n",
        "\n",
        "        return torch.FloatTensor(X_train), torch.FloatTensor(y_train)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "def plot_ber_bler(self, snr_range, ber_traditional_awgn, ber_ml_awgn, bler_traditional_awgn, bler_ml_awgn,\n",
        "                 ber_traditional_rayleigh, ber_ml_rayleigh, bler_traditional_rayleigh, bler_ml_rayleigh):\n",
        "    \"\"\"\n",
        "    Plots the BER and BLER curves for both AWGN and Rayleigh fading channels on the same plot.\n",
        "\n",
        "    Args:\n",
        "        snr_range (np.ndarray): Range of SNR values.\n",
        "        ber_traditional_awgn (list): Traditional BER values for AWGN channel.\n",
        "        ber_ml_awgn (list): ML BER values for AWGN channel.\n",
        "        bler_traditional_awgn (list): Traditional BLER values for AWGN channel.\n",
        "        bler_ml_awgn (list): ML BLER values for AWGN channel.\n",
        "        ber_traditional_rayleigh (list): Traditional BER values for Rayleigh channel.\n",
        "        ber_ml_rayleigh (list): ML BER values for Rayleigh channel.\n",
        "        bler_traditional_rayleigh (list): Traditional BLER values for Rayleigh channel.\n",
        "        bler_ml_rayleigh (list): ML BLER values for Rayleigh channel.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # BER Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.semilogy(snr_range, ber_traditional_awgn, label='Traditional BER (AWGN)')\n",
        "    plt.semilogy(snr_range, ber_ml_awgn, label='ML BER (AWGN)')\n",
        "    plt.semilogy(snr_range, ber_traditional_rayleigh, label='Traditional BER (Rayleigh)')\n",
        "    plt.semilogy(snr_range, ber_ml_rayleigh, label='ML BER (Rayleigh)')\n",
        "    plt.title('Bit Error Rate')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # BLER Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.semilogy(snr_range, bler_traditional_awgn, label='Traditional BLER (AWGN)')\n",
        "    plt.semilogy(snr_range, bler_ml_awgn, label='ML BLER (AWGN)')\n",
        "    plt.semilogy(snr_range, bler_traditional_rayleigh, label='Traditional BLER (Rayleigh)')\n",
        "    plt.semilogy(snr_range, bler_ml_rayleigh, label='ML BLER (Rayleigh)')\n",
        "    plt.title('Block Error Rate')\n",
        "    plt.xlabel('SNR (dB)')\n",
        "    plt.ylabel('BLER')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title='Decoder Performance Confusion Matrix'):\n",
        "    plt.figure(figsize=(10, 8))  # Specify figure size\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'])\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "\n",
        "    # Optional: Add classification report\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    plt.text(0.5, -0.15, report,\n",
        "             horizontalalignment='center',\n",
        "             verticalalignment='center',\n",
        "             transform=plt.gca().transAxes)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# After all class definitions and before main() function\n",
        "\n",
        "def calculate_bit_errors(y_true, y_pred, X_train, snr_range):\n",
        "    \"\"\"\n",
        "    Calculate Bit Error Rate (BER) for different SNR points\n",
        "\n",
        "    Args:\n",
        "        y_true (np.array): True labels\n",
        "        y_pred (np.array): Predicted labels\n",
        "        X_train (torch.Tensor): Training input data\n",
        "        snr_range (np.array): SNR range\n",
        "\n",
        "    Returns:\n",
        "        np.array: Bit error rates for each SNR point\n",
        "    \"\"\"\n",
        "    bit_errors = []\n",
        "\n",
        "    for snr in snr_range:\n",
        "        # Filter data for current SNR\n",
        "        snr_mask = np.isclose(X_train.cpu().numpy()[:, 0], snr, atol=0.5)\n",
        "        snr_true = y_true[snr_mask]\n",
        "        snr_pred = y_pred[snr_mask]\n",
        "\n",
        "        # Compute BER for this SNR point\n",
        "        if len(snr_true) > 0:\n",
        "            ber = np.mean(np.abs(snr_true - snr_pred))\n",
        "            bit_errors.append(ber)\n",
        "        else:\n",
        "            bit_errors.append(np.nan)\n",
        "\n",
        "    return np.array(bit_errors)\n",
        "\n",
        "def calculate_block_errors(y_true, y_pred, X_train, snr_range):\n",
        "    \"\"\"\n",
        "    Calculate Block Error Rate (BLER) for different SNR points\n",
        "\n",
        "    Args:\n",
        "        y_true (np.array): True labels\n",
        "        y_pred (np.array): Predicted labels\n",
        "        X_train (torch.Tensor): Training input data\n",
        "        snr_range (np.array): SNR range\n",
        "\n",
        "    Returns:\n",
        "        np.array: Block error rates for each SNR point\n",
        "    \"\"\"\n",
        "    block_errors = []\n",
        "\n",
        "    for snr in snr_range:\n",
        "        # Filter data for current SNR\n",
        "        snr_mask = np.isclose(X_train.cpu().numpy()[:, 0], snr, atol=0.5)\n",
        "        snr_true = y_true[snr_mask]\n",
        "        snr_pred = y_pred[snr_mask]\n",
        "\n",
        "        # Compute BLER for this SNR point\n",
        "        if len(snr_true) > 0:\n",
        "            bler = np.mean(np.any(snr_true != snr_pred, axis=1))\n",
        "            block_errors.append(bler)\n",
        "        else:\n",
        "            block_errors.append(np.nan)\n",
        "\n",
        "    return np.array(block_errors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def evaluate_performance(trainer, block_length, info_bits, snr_range, channel_type='AWGN'):\n",
        "\n",
        "\n",
        "def evaluate_performance(self, ml_model, polar_code_gen, channel_type='AWGN'):\n",
        "    num_trials = 1000  # Number of simulations for each SNR\n",
        "    ber_traditional_list = {list_size: [] for list_size in self.list_sizes}\n",
        "    ber_ml_list = []\n",
        "    bler_traditional_list = {list_size: [] for list_size in self.list_sizes}\n",
        "    bler_ml_list = []\n",
        "    info_indices = polar_code_gen.generate_polar_code_matrix()  # Get info bit indices\n",
        "\n",
        "    for snr in self.snr_range:\n",
        "        for list_size in self.list_sizes:\n",
        "            ber_traditional = 0\n",
        "            ber_ml = 0\n",
        "            bler_traditional = 0\n",
        "            bler_ml = 0\n",
        "            scl_decoder = SCLDecoder(polar_code_gen.N, polar_code_gen.K, list_size=list_size)  # Create SCLDecoder with current list size\n",
        "            channel_simulator = ChannelSimulator(channel_type=channel_type)  # Create ChannelSimulator with the specified type\n",
        "\n",
        "            for _ in range(num_trials):\n",
        "                info_bits = np.random.randint(2, size=self.info_bits)\n",
        "                encoded_bits = polar_code_gen.encode(info_bits)\n",
        "                received_signal = channel_simulator.transmit(encoded_bits, snr)  # Use the selected channel type\n",
        "\n",
        "                # Traditional Decoding (SCL)\n",
        "                decoded_bits_traditional = scl_decoder.decode(received_signal, info_indices)[:self.info_bits]\n",
        "\n",
        "                # ML Decoding\n",
        "                received_signal_tensor = torch.tensor(received_signal, dtype=torch.float32).to(ml_model.device)\n",
        "                decoded_bits_ml = ml_model(received_signal_tensor).cpu().detach().numpy()\n",
        "                decoded_bits_ml = (decoded_bits_ml > 0.5).astype(int)\n",
        "                decoded_bits_ml = decoded_bits_ml.flatten()  # Flatten to 1D array\n",
        "\n",
        "                # Calculate Errors\n",
        "                ber_traditional += np.sum(np.abs(info_bits - decoded_bits_traditional)) / self.info_bits\n",
        "                ber_ml += np.sum(np.abs(info_bits - decoded_bits_ml)) / self.info_bits\n",
        "                bler_traditional += int(np.any(info_bits != decoded_bits_traditional))\n",
        "                bler_ml += int(np.any(info_bits != decoded_bits_ml))\n",
        "\n",
        "            # Average Errors over Trials and store in the dictionaries\n",
        "            ber_traditional_list[list_size].append(ber_traditional / num_trials)\n",
        "            ber_ml_list.append(ber_ml / num_trials)\n",
        "            bler_traditional_list[list_size].append(bler_traditional / num_trials)\n",
        "            bler_ml_list.append(bler_ml / num_trials)\n",
        "\n",
        "    # Return results for specified list size\n",
        "    ber_traditional_result = ber_traditional_list[8]  # Standard list size for comparison\n",
        "    bler_traditional_result = bler_traditional_list[8]  # Standard list size for comparison\n",
        "    print(\"BLER(Traditional):\", bler_traditional_result)\n",
        "\n",
        "    return {'ber_traditional': ber_traditional_result,\n",
        "            'ber_ml': ber_ml_list,\n",
        "            'bler_traditional': bler_traditional_result,\n",
        "            'bler_ml': bler_ml_list}\n",
        "\n",
        "\n",
        "# scl_decoder = SCLDecoder(polar_code_gen.N, polar_code_gen.K, list_size=8)  # Pass block_length and info_bits here\n",
        "   #except Exception as overall_error:\n",
        "    #    print(f\"Overall performance evaluation error: {overall_error}\")\n",
        "     #   raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Hyperparameters\n",
        "        BLOCK_LENGTH = 128\n",
        "        INFO_BITS = 64\n",
        "        LEARNING_RATE = 1e-3\n",
        "        EPOCHS = 10  # Increased epochs\n",
        "        BATCH_SIZE = 64\n",
        "        SNR_RANGE = np.linspace(0, 15, 16) # Consider a wider SNR range if needed. e.g., np.linspace(0, 10, 21)\n",
        "        LIST_SIZES = [1, 8, 16]\n",
        "        HIDDEN_LAYERS = [128, 256, 128]\n",
        "\n",
        "        # Initialize components\n",
        "        polar_code_gen = PolarCodeGenerator(N=BLOCK_LENGTH, K=INFO_BITS)\n",
        "        channel_sim = ChannelSimulator(channel_type='AWGN')\n",
        "\n",
        "        # Initialize Neural Network Model\n",
        "        model = MLPolarDecoder(\n",
        "            input_size=BLOCK_LENGTH,\n",
        "            hidden_layers=HIDDEN_LAYERS,\n",
        "            output_size=INFO_BITS\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer\n",
        "        trainer = MLTrainer(model, learning_rate=LEARNING_RATE, epochs=EPOCHS)\n",
        "\n",
        "        # Generate Training Data with increased samples\n",
        "        X_train, y_train = trainer.generate_training_data(\n",
        "            num_samples=1000,  # Increased samples\n",
        "            block_length=BLOCK_LENGTH,\n",
        "            snr_range=SNR_RANGE\n",
        "        )\n",
        "\n",
        "        # Training Process\n",
        "        train_losses, val_losses = trainer.train(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # ... (rest of your main function remains the same) ...\n",
        "\n",
        "\n",
        "        # Tensor conversion and prediction\n",
        "        y_true = y_train.cpu().numpy()\n",
        "        y_pred = model(X_train.to(model.device)).sigmoid().cpu().detach().numpy()\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        # Ensure 1D arrays\n",
        "        y_true = y_true.ravel()\n",
        "        y_pred = y_pred.ravel()\n",
        "\n",
        "        # Plotting Training and Validation Losses\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.title('Training and Validation Losses')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Performance Results for AWGN and Rayleigh Channels\n",
        "        performance_results_awgn = evaluate_performance(\n",
        "            trainer, BLOCK_LENGTH, INFO_BITS, SNR_RANGE,\n",
        "            channel_type='AWGN'\n",
        "        )\n",
        "\n",
        "        performance_results_rayleigh = evaluate_performance(\n",
        "            trainer, BLOCK_LENGTH, INFO_BITS, SNR_RANGE,\n",
        "            channel_type='Rayleigh'\n",
        "        )\n",
        "\n",
        "        # Plot BER and BLER for Both Channels\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # BER Subplot\n",
        "        plt.subplot(121)\n",
        "        plt.semilogy(SNR_RANGE, performance_results_awgn['ber_traditional'],\n",
        "                     label='Traditional BER (AWGN)', marker='o')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_awgn['ber_ml'],\n",
        "                     label='ML BER (AWGN)', marker='s')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_rayleigh['ber_traditional'],\n",
        "                     label='Traditional BER (Rayleigh)', marker='^')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_rayleigh['ber_ml'],\n",
        "                     label='ML BER (Rayleigh)', marker='d')\n",
        "\n",
        "        plt.title('Bit Error Rate')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('BER')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # BLER Subplot\n",
        "        plt.subplot(122)\n",
        "        plt.semilogy(SNR_RANGE, performance_results_awgn['bler_traditional'],\n",
        "                     label='Traditional BLER (AWGN)', marker='o')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_awgn['bler_ml'],\n",
        "                     label='ML BLER (AWGN)', marker='s')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_rayleigh['bler_traditional'],\n",
        "                     label='Traditional BLER (Rayleigh)', marker='^')\n",
        "        plt.semilogy(SNR_RANGE, performance_results_rayleigh['bler_ml'],\n",
        "                     label='ML BLER (Rayleigh)', marker='d')\n",
        "\n",
        "        plt.title('Block Error Rate')\n",
        "        plt.xlabel('SNR (dB)')\n",
        "        plt.ylabel('BLER')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "  # Confusion Matrix Plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plot_confusion_matrix(y_true, y_pred)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        logger.info(\"Polar Code Simulation completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Simulation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "HucfsveaSKwY",
        "outputId": "0888f412-b1ef-40a5-ca59-77932fec3bc2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss = 0.7038, Val Loss = 0.6919\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-04 04:34:37,309 - __main__ - ERROR - Simulation failed: evaluate_performance() got multiple values for argument 'channel_type'\n",
            "ERROR:__main__:Simulation failed: evaluate_performance() got multiple values for argument 'channel_type'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-56-c0bac04782d8>\", line 578, in main\n",
            "    performance_results_awgn = evaluate_performance(\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: evaluate_performance() got multiple values for argument 'channel_type'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}