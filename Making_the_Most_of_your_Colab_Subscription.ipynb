{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumuds4/BCH/blob/master/Making_the_Most_of_your_Colab_Subscription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to select from several accelerator options, subject to availability.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, check out these tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-neJgdNazFT",
        "outputId": "84f69a7c-032b-474e-b811-f16d221864ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Imports and Core Classes\n",
        "\n",
        "# Essential Scientific and Deep Learning Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Machine Learning and Data Handling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# System and Utilities\n",
        "import logging\n",
        "import traceback\n",
        "\n",
        "# Polar Code Generator Class\n",
        "import numpy as np\n",
        "import math\n",
        "class PolarCodeGenerator:\n",
        "    def __init__(self, N=128, K=64):\n",
        "        # Existing initialization\n",
        "\n",
        "        # CRC-7 Polynomial\n",
        "        self.crc_polynomial = 0b10100011  # Standard CRC-7 polynomial\n",
        "        self.crc_order = 7\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.R = K / N  # Code rate\n",
        "\n",
        "\n",
        "    def crc_generate(self, data):\n",
        "        \"\"\"\n",
        "        Generate CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Input data bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: CRC checksum bits\n",
        "        \"\"\"\n",
        "        # Convert input to numpy array\n",
        "        data = np.asarray(data)\n",
        "\n",
        "        # Create data with zero padding for CRC\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.crc_order, dtype=int)])\n",
        "\n",
        "        # CRC calculation\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Return the last 'crc_order' bits as CRC\n",
        "        return data_with_zeros[-self.crc_order:]\n",
        "\n",
        "    def crc_verify(self, data, received_crc):\n",
        "        \"\"\"\n",
        "        Verify CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Original data bits\n",
        "            received_crc (np.ndarray): Received CRC checksum\n",
        "\n",
        "        Returns:\n",
        "            bool: True if CRC is valid, False otherwise\n",
        "        \"\"\"\n",
        "        # Combine data and received CRC\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        # CRC verification\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    full_data[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Check if the last 'crc_order' bits are zero\n",
        "        return np.all(full_data[-self.crc_order:] == 0)\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with CRC\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Place information bits\n",
        "        encoded_bits[:len(full_info)] = full_info\n",
        "\n",
        "        return encoded_bits\n",
        "\n",
        "\n",
        "    def bhattacharyya_parameter(self, W, n):\n",
        "        \"\"\"\n",
        "        Compute Bhattacharyya parameter for channel polarization\n",
        "\n",
        "        Args:\n",
        "            W (float): Initial channel crossover probability\n",
        "            n (int): Recursion depth\n",
        "\n",
        "        Returns:\n",
        "            float: Bhattacharyya parameter\n",
        "        \"\"\"\n",
        "        if n == 0:\n",
        "            return W\n",
        "\n",
        "        # Recursive Bhattacharyya parameter computation\n",
        "        W_used = self.bhattacharyya_parameter(W, n-1)\n",
        "        W_transform = 2 * (W_used ** 2) - (W_used ** 4)\n",
        "\n",
        "        return W_transform\n",
        "\n",
        "    def _generate_polar_code_matrix(self, W=0.5):\n",
        "        \"\"\"\n",
        "        Generate polar code matrix using Bhattacharyya parameter\n",
        "\n",
        "        Args:\n",
        "            W (float): Initial channel crossover probability\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Indices of information bit positions\n",
        "        \"\"\"\n",
        "        # Compute channel capacities\n",
        "        channel_capacities = []\n",
        "        for _ in range(self.N):\n",
        "            # Compute Bhattacharyya parameter\n",
        "            capacity = self.bhattacharyya_parameter(W, int(math.log2(self.N)))\n",
        "            channel_capacities.append(capacity)\n",
        "\n",
        "        # Sort channel capacities\n",
        "        sorted_indices = np.argsort(channel_capacities)\n",
        "\n",
        "        # Select best channels for information bits\n",
        "        info_indices = sorted_indices[self.N - self.K:]\n",
        "\n",
        "        return info_indices\n",
        "\n",
        "    def crc_generate(self, data):\n",
        "        \"\"\"\n",
        "        Generate CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Input data bits\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: CRC checksum bits\n",
        "        \"\"\"\n",
        "        # Convert input to numpy array\n",
        "        data = np.asarray(data)\n",
        "\n",
        "        # Create data with zero padding for CRC\n",
        "        data_with_zeros = np.concatenate([data, np.zeros(self.crc_order, dtype=int)])\n",
        "\n",
        "        # CRC calculation\n",
        "        for i in range(len(data)):\n",
        "            if data_with_zeros[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    data_with_zeros[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Return the last 'crc_order' bits as CRC\n",
        "        return data_with_zeros[-self.crc_order:]\n",
        "\n",
        "    def polar_encode(self, info_bits):\n",
        "        \"\"\"\n",
        "        Systematic Polar Encoding with Bhattacharyya parameter-based channel polarization\n",
        "\n",
        "        Args:\n",
        "            info_bits (np.ndarray): Information bits to encode\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        # Generate CRC\n",
        "        crc_bits = self.crc_generate(info_bits)\n",
        "\n",
        "        # Combine info bits and CRC\n",
        "        full_info = np.concatenate([info_bits, crc_bits])\n",
        "\n",
        "        # Initialize codeword\n",
        "        encoded_bits = np.zeros(self.N, dtype=int)\n",
        "\n",
        "        # Get channel indices for information bits\n",
        "        info_indices = self.channel_capacity\n",
        "        info_indices = info_indices[:len(full_info)]\n",
        "\n",
        "        # Place information bits at selected indices\n",
        "        encoded_bits[info_indices] = full_info\n",
        "\n",
        "        # Polar transform encoding\n",
        "        return self._polar_transform(encoded_bits)\n",
        "\n",
        "    def _polar_transform(self, codeword):\n",
        "        \"\"\"\n",
        "        Polar transform encoding\n",
        "\n",
        "        Args:\n",
        "            codeword (np.ndarray): Initial codeword\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded codeword\n",
        "        \"\"\"\n",
        "        n = int(np.log2(len(codeword)))\n",
        "\n",
        "        # In-place Hadamard transform\n",
        "        for i in range(n):\n",
        "            for j in range(0, len(codeword), 2**(i+1)):\n",
        "                for k in range(2**i):\n",
        "                    u = codeword[j + k]\n",
        "                    v = codeword[j + k + 2**i]\n",
        "                    codeword[j + k] = (u + v) % 2\n",
        "                    codeword[j + k + 2**i] = (u - v) % 2\n",
        "\n",
        "        return codeword\n",
        "\n",
        "    def crc_verify(self, data, received_crc):\n",
        "        \"\"\"\n",
        "        Verify CRC-7 checksum\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Original data bits\n",
        "            received_crc (np.ndarray): Received CRC checksum\n",
        "\n",
        "        Returns:\n",
        "            bool: True if CRC is valid, False otherwise\n",
        "        \"\"\"\n",
        "        # Combine data and received CRC\n",
        "        full_data = np.concatenate([data, received_crc])\n",
        "\n",
        "        # CRC verification\n",
        "        for i in range(len(data)):\n",
        "            if full_data[i] == 1:\n",
        "                for j in range(self.crc_order + 1):\n",
        "                    full_data[i+j] ^= ((self.crc_polynomial >> j) & 1)\n",
        "\n",
        "        # Check if the last 'crc_order' bits are zero\n",
        "        return np.all(full_data[-self.crc_order:] == 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Channel Simulator Class\n",
        "class ChannelSimulator:\n",
        "    def __init__(self, channel_type='AWGN'):\n",
        "        \"\"\"\n",
        "        Initialize Channel Simulator\n",
        "\n",
        "        Args:\n",
        "            channel_type (str): Type of channel (AWGN or Rayleigh)\n",
        "        \"\"\"\n",
        "        self.channel_type = channel_type\n",
        "\n",
        "    def transmit(self, signal, snr):\n",
        "        \"\"\"\n",
        "        Transmit signal through channel\n",
        "\n",
        "        Args:\n",
        "            signal (np.ndarray): Input signal\n",
        "            snr (float): Signal-to-Noise Ratio in dB\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Received noisy signal\n",
        "        \"\"\"\n",
        "        # Convert SNR to linear scale\n",
        "        snr_linear = 10 ** (snr / 10)\n",
        "\n",
        "        # Noise standard deviation\n",
        "        noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "\n",
        "        # Generate noise\n",
        "        if self.channel_type == 'AWGN':\n",
        "            noise = np.random.normal(0, noise_std, signal.shape)\n",
        "        elif self.channel_type == 'Rayleigh':\n",
        "            fading = np.random.rayleigh(scale=1, size=signal.shape)\n",
        "            noise = fading * np.random.normal(0, noise_std, signal.shape)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported channel type: {self.channel_type}\")\n",
        "\n",
        "        return signal + noise\n",
        "\n",
        "# Logging Configuration\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s'\n",
        "class TraditionalPolarDecoder:\n",
        "    def __init__(self, N, K, list_size=1):\n",
        "        \"\"\"\n",
        "        Successive Cancellation List (SCL) Decoder\n",
        "\n",
        "        Args:\n",
        "            N (int): Codeword length\n",
        "            K (int): Information bit length\n",
        "            list_size (int): Size of the decoding list\n",
        "        \"\"\"\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.list_size = list_size\n",
        "\n",
        "    def _polar_transform(self, llr):\n",
        "        \"\"\"\n",
        "        Polar transform for bit likelihood computation\n",
        "\n",
        "        Args:\n",
        "            llr (np.ndarray): Log-likelihood ratios\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Transformed LLRs\n",
        "        \"\"\"\n",
        "        n = len(llr)\n",
        "        if n == 1:\n",
        "            return llr\n",
        "\n",
        "        # Recursive polar transform\n",
        "        llr_left = self._combine_llr(llr[:n//2], llr[n//2:])\n",
        "        return np.concatenate([llr_left, llr[n//2:]])\n",
        "\n",
        "    def _combine_llr(self, llr1, llr2):\n",
        "        \"\"\"\n",
        "        Combine log-likelihood ratios\n",
        "\n",
        "        Args:\n",
        "            llr1 (np.ndarray): First set of LLRs\n",
        "            llr2 (np.ndarray): Second set of LLRs\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Combined LLRs\n",
        "        \"\"\"\n",
        "        return np.log((1 + np.exp(llr1 + llr2)) / (1 + np.exp(llr1 - llr2)))\n",
        "\n",
        "    def decode(self, received_signal, noise_variance):\n",
        "        \"\"\"\n",
        "        SCL Decoding algorithm\n",
        "\n",
        "        Args:\n",
        "            received_signal (np.ndarray): Received noisy signal\n",
        "            noise_variance (float): Noise variance\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Decoded information bits\n",
        "        \"\"\"\n",
        "        # Compute initial log-likelihood ratios\n",
        "        llr = 2 * received_signal / noise_variance\n",
        "\n",
        "        # Initialize list decoder\n",
        "        path_metrics = [0]\n",
        "        path_list = [np.zeros(self.N, dtype=int)]\n",
        "\n",
        "        for i in range(self.N):\n",
        "            new_path_metrics = []\n",
        "            new_path_list = []\n",
        "\n",
        "            for metric, path in zip(path_metrics, path_list):\n",
        "                # Try both 0 and 1 for current bit\n",
        "                for bit in [0, 1]:\n",
        "                    new_path = path.copy()\n",
        "                    new_path[i] = bit\n",
        "\n",
        "                    # Compute path metric\n",
        "                    new_metric = metric - np.log(1 + np.exp(-llr[i] * (-1)**bit))\n",
        "\n",
        "                    # Add to list if not exceeding list size\n",
        "                    if len(new_path_metrics) < self.list_size:\n",
        "                        new_path_metrics.append(new_metric)\n",
        "                        new_path_list.append(new_path)\n",
        "                    else:\n",
        "                        # Replace worst path if new path is better\n",
        "                        worst_idx = np.argmax(new_path_metrics)\n",
        "                        if new_metric < new_path_metrics[worst_idx]:\n",
        "                            new_path_metrics[worst_idx] = new_metric\n",
        "                            new_path_list[worst_idx] = new_path\n",
        "\n",
        "            path_metrics = new_path_metrics\n",
        "            path_list = new_path_list\n",
        "\n",
        "        # Select best path\n",
        "        best_path_idx = np.argmin(path_metrics)\n",
        "        decoded_codeword = path_list[best_path_idx]\n",
        "\n",
        "        # Extract information bits (excluding CRC)\n",
        "        return decoded_codeword[:self.K]\n",
        "\n",
        "    def compute_performance(self, channel, snr_range, polar_code_gen):\n",
        "        \"\"\"\n",
        "        Compute performance metrics\n",
        "\n",
        "        Args:\n",
        "            channel: Channel simulator\n",
        "            snr_range: SNR range\n",
        "            polar_code_gen: Polar code generator\n",
        "\n",
        "        Returns:\n",
        "            tuple: BER and BLER arrays\n",
        "        \"\"\"\n",
        "        ber_values = []\n",
        "        bler_values = []\n",
        "\n",
        "        for snr in snr_range:\n",
        "            bit_errors_accumulator = []\n",
        "            block_errors_accumulator = []\n",
        "\n",
        "            for _ in range(100):  # Number of trials\n",
        "                # Generate info bits\n",
        "                info_bits = polar_code_gen.generate_info_bits()\n",
        "\n",
        "                # Encode\n",
        "                encoded_signal = polar_code_gen.polar_encode(info_bits)\n",
        "\n",
        "                # Add channel noise\n",
        "                noise_std = 10 ** (-snr / 20)\n",
        "                received_signal = encoded_signal + np.random.normal(0, noise_std, encoded_signal.shape)\n",
        "\n",
        "                # Decode\n",
        "                decoded_bits = self.decode(received_signal, noise_std**2)\n",
        "\n",
        "                # Compute errors\n",
        "                bit_errors = np.sum(info_bits != decoded_bits)\n",
        "                block_error = not np.array_equal(info_bits, decoded_bits)\n",
        "\n",
        "                bit_errors_accumulator.append(bit_errors / len(info_bits))\n",
        "                block_errors_accumulator.append(1 if block_error else 0)\n",
        "\n",
        "            # Compute average BER and BLER\n",
        "            ber_values.append(np.mean(bit_errors_accumulator))\n",
        "            bler_values.append(np.mean(block_errors_accumulator))\n",
        "\n",
        "        return np.array(ber_values), np.array(bler_values)\n",
        "\n",
        "# Part 2: Neural Network Decoder Architectures\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
        "        \"\"\"\n",
        "        Recurrent Neural Network (RNN) Decoder\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Size of input features\n",
        "            hidden_size (int): Number of hidden units\n",
        "            num_layers (int): Number of RNN layers\n",
        "        \"\"\"\n",
        "        super(RNNDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=1,  # Single feature per time step\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the RNN decoder\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoded probabilities\n",
        "        \"\"\"\n",
        "        # Reshape input for LSTM\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(2)  # Add channel dimension\n",
        "\n",
        "        # LSTM processing\n",
        "        rnn_out, _ = self.rnn(x)\n",
        "\n",
        "        # Take the last time step\n",
        "        out = rnn_out[:, -1, :]\n",
        "\n",
        "        # Final classification\n",
        "        return self.fc(out)\n",
        "\n",
        "class MLDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers=[128, 64, 32]):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) Decoder\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Size of input features\n",
        "            hidden_layers (list): Number of neurons in hidden layers\n",
        "        \"\"\"\n",
        "        super(MLDecoder, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        # Hidden layers\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.BatchNorm1d(hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        layers.extend([\n",
        "            nn.Linear(prev_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        ])\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the MLP decoder\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoded probabilities\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "def weights_init(m):\n",
        "    \"\"\"\n",
        "    Custom weight initialization\n",
        "\n",
        "    Args:\n",
        "        m (nn.Module): Neural network layer\n",
        "    \"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                nn.init.orthogonal_(param)\n",
        "\n",
        "# Model creation functions\n",
        "def create_rnn_model(input_size):\n",
        "    \"\"\"\n",
        "    Create RNN Decoder model\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features\n",
        "\n",
        "    Returns:\n",
        "        RNNDecoder: Initialized RNN model\n",
        "    \"\"\"\n",
        "    model = RNNDecoder(input_size)\n",
        "    model.apply(weights_init)\n",
        "    return model\n",
        "\n",
        "def create_ml_model(input_size):\n",
        "    \"\"\"\n",
        "    Create MLP Decoder model\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features\n",
        "\n",
        "    Returns:\n",
        "        MLDecoder: Initialized MLP model\n",
        "    \"\"\"\n",
        "    model = MLDecoder(input_size)\n",
        "    model.apply(weights_init)\n",
        "\n",
        " # Part 2: Neural Network Decoder Architectures\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
        "        \"\"\"\n",
        "        Recurrent Neural Network (RNN) Decoder\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Size of input features\n",
        "            hidden_size (int): Number of hidden units\n",
        "            num_layers (int): Number of RNN layers\n",
        "        \"\"\"\n",
        "        super(RNNDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=1,  # Single feature per time step\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the RNN decoder\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoded probabilities\n",
        "        \"\"\"\n",
        "        # Reshape input for LSTM\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(2)  # Add channel dimension\n",
        "\n",
        "        # LSTM processing\n",
        "        rnn_out, _ = self.rnn(x)\n",
        "\n",
        "        # Take the last time step\n",
        "        out = rnn_out[:, -1, :]\n",
        "\n",
        "        # Final classification\n",
        "        return self.fc(out)\n",
        "\n",
        "class MLDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers=[128, 64, 32]):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) Decoder\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Size of input features\n",
        "            hidden_layers (list): Number of neurons in hidden layers\n",
        "        \"\"\"\n",
        "        super(MLDecoder, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        # Hidden layers\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.BatchNorm1d(hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        layers.extend([\n",
        "            nn.Linear(prev_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        ])\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the MLP decoder\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoded probabilities\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "def weights_init(m):\n",
        "    \"\"\"\n",
        "    Custom weight initialization\n",
        "\n",
        "    Args:\n",
        "        m (nn.Module): Neural network layer\n",
        "    \"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                nn.init.orthogonal_(param)\n",
        "\n",
        "# Model creation functions\n",
        "def create_rnn_model(input_size):\n",
        "    \"\"\"\n",
        "    Create RNN Decoder model\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features\n",
        "\n",
        "    Returns:\n",
        "        RNNDecoder: Initialized RNN model\n",
        "    \"\"\"\n",
        "    model = RNNDecoder(input_size)\n",
        "    model.apply(weights_init)\n",
        "    return model\n",
        "\n",
        "def create_ml_model(input_size):\n",
        "    \"\"\"\n",
        "    Create MLP Decoder model\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features\n",
        "\n",
        "    Returns:\n",
        "        MLDecoder: Initialized MLP model\n",
        "    \"\"\"\n",
        "    model = MLDecoder(input_size)\n",
        "    model.apply(weights_init)\n",
        " # Part 3: Trainer Classes\n",
        "\n",
        "class RNNTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize RNN Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): RNN neural network model\n",
        "            learning_rate (float): Optimization learning rate\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Loss and Optimizer\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=5\n",
        "        )\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=200, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the RNN model\n",
        "\n",
        "        Args:\n",
        "            X_train (torch.Tensor): Training features\n",
        "            y_train (torch.Tensor): Training labels\n",
        "            epochs (int): Number of training epochs\n",
        "            batch_size (int): Training batch size\n",
        "            validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training and validation losses\n",
        "        \"\"\"\n",
        "        # Prepare data\n",
        "        X_train = X_train.to(self.device)\n",
        "        y_train = y_train.to(self.device)\n",
        "\n",
        "        # Split into train and validation\n",
        "        train_size = int((1 - validation_split) * len(X_train))\n",
        "        X_val, y_val = X_train[train_size:], y_train[train_size:]\n",
        "        X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
        "\n",
        "        # Tracking metrics\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accuracies, val_accuracies = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            epoch_train_loss, train_acc = self._train_epoch(X_train, y_train, batch_size)\n",
        "            train_losses.append(epoch_train_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_loss, val_acc = self._validate(X_val, y_val)\n",
        "                val_losses.append(val_loss)\n",
        "                val_accuracies.append(val_acc)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Periodic reporting\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: \"\n",
        "                      f\"Train Loss={epoch_train_loss:.4f}, Train Acc={train_acc:.4f} | \"\n",
        "                      f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def _train_epoch(self, X, y, batch_size):\n",
        "        \"\"\"\n",
        "        Single training epoch\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): Training features\n",
        "            y (torch.Tensor): Training labels\n",
        "            batch_size (int): Batch size\n",
        "\n",
        "        Returns:\n",
        "            tuple: Average loss and accuracy\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "        # Shuffle data\n",
        "        indices = torch.randperm(X.size(0))\n",
        "        X, y = X[indices], y[indices]\n",
        "\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch_X = X[i:i+batch_size]\n",
        "            batch_y = y[i:i+batch_size]\n",
        "\n",
        "            # Forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Metrics\n",
        "            total_loss += loss.item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total_correct += (predicted == batch_y).float().sum().item()\n",
        "            total_samples += batch_y.size(0)\n",
        "\n",
        "        avg_loss = total_loss / (len(X) // batch_size)\n",
        "        accuracy = total_correct / total_samples\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def _validate(self, X, y):\n",
        "        \"\"\"\n",
        "        Validation phase\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): Validation features\n",
        "            y (torch.Tensor): Validation labels\n",
        "\n",
        "        Returns:\n",
        "            tuple: Loss and accuracy\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "            loss = self.criterion(outputs, y)\n",
        "\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            accuracy = (predicted == y).float().mean().item()\n",
        "\n",
        "        return loss.item(), accuracy\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Ensure correct input shape\n",
        "        if X.dim() == 2:\n",
        "            X = X.unsqueeze(2)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "\n",
        "        return outputs.cpu().numpy()\n",
        "\n",
        "# Similar implementation for MLTrainer would follow the same pattern\n",
        "class MLTrainer:\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize ML Trainer\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Neural network model\n",
        "            learning_rate (float): Optimization learning rate\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Loss and Optimizer\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=5\n",
        "        )\n",
        "\n",
        "    # The methods would be very similar to RNNTrainer\n",
        "    # Only difference would be in prediction method due to different model architecture\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input features\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Predicted probabilities\n",
        "        \"\"\"\n",
        "        # Ensure input is a tensor\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X).to(self.device)\n",
        "\n",
        "        # Prediction\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        " # Part 5: Main Simulation Function\n",
        "def plot_confusion_matrices(X_test, y_test, rnn_trainer, ml_trainer):\n",
        "    \"\"\"\n",
        "    Plot Confusion Matrices for RNN and ML Decoders\n",
        "\n",
        "    Args:\n",
        "        X_test (torch.Tensor): Test features\n",
        "        y_test (torch.Tensor): Test labels\n",
        "        rnn_trainer (RNNTrainer): RNN Decoder trainer\n",
        "        ml_trainer (MLTrainer): ML Decoder trainer\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # RNN Decoder Confusion Matrix\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "    # Predict using RNN decoder\n",
        "    rnn_predictions = rnn_trainer.predict(X_test.cpu().numpy())\n",
        "    rnn_pred_classes = (rnn_predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    rnn_cm = confusion_matrix(y_test.cpu().numpy(), rnn_pred_classes)\n",
        "\n",
        "    # Plot heatmap\n",
        "    sns.heatmap(\n",
        "        rnn_cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        square=True,\n",
        "        cbar=False\n",
        "    )\n",
        "    plt.title('RNN Decoder\\nConfusion Matrix', fontsize=14)\n",
        "    plt.xlabel('Predicted Label', fontsize=10)\n",
        "    plt.ylabel('True Label', fontsize=10)\n",
        "\n",
        "    # ML Decoder Confusion Matrix\n",
        "    plt.subplot(1, 2, 2)\n",
        "\n",
        "    # Predict using ML decoder\n",
        "    ml_predictions = ml_trainer.predict(X_test.cpu().numpy())\n",
        "    ml_pred_classes = (ml_predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    ml_cm = confusion_matrix(y_test.cpu().numpy(), ml_pred_classes)\n",
        "\n",
        "    # Plot heatmap\n",
        "    sns.heatmap(\n",
        "        ml_cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Greens',\n",
        "        square=True,\n",
        "        cbar=False\n",
        "    )\n",
        "    plt.title('ML Decoder\\nConfusion Matrix', fontsize=14)\n",
        "    plt.xlabel('Predicted Label', fontsize=10)\n",
        "    plt.ylabel('True Label', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('decoder_confusion_matrices.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Optional: Print classification reports\n",
        "    print(\"RNN Decoder Classification Report:\")\n",
        "    print(classification_report(\n",
        "        y_test.cpu().numpy(),\n",
        "        rnn_pred_classes\n",
        "    ))\n",
        "\n",
        "    print(\"\\nML Decoder Classification Report:\")\n",
        "    print(classification_report(\n",
        "        y_test.cpu().numpy(),\n",
        "        ml_pred_classes\n",
        "    ))\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Comprehensive Polar Code Simulation and Machine Learning Decoder Evaluation\n",
        "    \"\"\"\n",
        "    # Simulation Parameters\n",
        "    SIMULATION_PARAMS = {\n",
        "        'BLOCK_LENGTH': 128,\n",
        "        'INFO_BITS': 64,\n",
        "        'LEARNING_RATE': 1e-3,\n",
        "        'EPOCHS': 200,\n",
        "        'BATCH_SIZE': 64,\n",
        "        'NUM_SAMPLES': 15000,\n",
        "        'TEST_SPLIT': 0.2,\n",
        "        'SNR_RANGE': np.linspace(0, 10, 10),\n",
        "        'LIST_SIZES': [1, 8, 16],\n",
        "        'NUM_TRIALS': 4000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Device Configuration\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"🚀 Using Device: {device}\")\n",
        "\n",
        "        # 1. Polar Code Generator\n",
        "        polar_code_gen = PolarCodeGenerator(\n",
        "            N=SIMULATION_PARAMS['BLOCK_LENGTH'],\n",
        "            K=SIMULATION_PARAMS['INFO_BITS']\n",
        "        )\n",
        "        print(\"✅ Polar Code Generator Initialized\")\n",
        "\n",
        "        # 2. Dataset Preparation\n",
        "        X, y = prepare_polar_dataset(\n",
        "            polar_code_gen,\n",
        "            num_samples=SIMULATION_PARAMS['NUM_SAMPLES']\n",
        "        )\n",
        "\n",
        "        # Normalize features\n",
        "        X, _ = normalize_features(X, X)\n",
        "\n",
        "        # Split Dataset\n",
        "        X_train, X_test, y_train, y_test = prepare_dataset_for_training(\n",
        "            X, y,\n",
        "            test_size=SIMULATION_PARAMS['TEST_SPLIT']\n",
        "        )\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        X_train = torch.FloatTensor(X_train).to(device)\n",
        "        X_test = torch.FloatTensor(X_test).to(device)\n",
        "        y_train = torch.FloatTensor(y_train).to(device).view(-1, 1)\n",
        "        y_test = torch.FloatTensor(y_test).to(device).view(-1, 1)\n",
        "\n",
        "        # 3. RNN Decoder Training\n",
        "        rnn_model = create_rnn_model(input_size=SIMULATION_PARAMS['BLOCK_LENGTH']).to(device)\n",
        "        rnn_trainer = RNNTrainer(rnn_model, learning_rate=SIMULATION_PARAMS['LEARNING_RATE'])\n",
        "\n",
        "        rnn_train_losses, rnn_val_losses = rnn_trainer.train(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=SIMULATION_PARAMS['EPOCHS'],\n",
        "            batch_size=SIMULATION_PARAMS['BATCH_SIZE']\n",
        "        )\n",
        "        print(\"✅ RNN Decoder Training Completed\")\n",
        "\n",
        "        # 4. ML Decoder Training\n",
        "        ml_model = create_ml_model(input_size=SIMULATION_PARAMS['BLOCK_LENGTH']).to(device)\n",
        "        ml_trainer = MLTrainer(ml_model, learning_rate=SIMULATION_PARAMS['LEARNING_RATE'])\n",
        "\n",
        "        ml_train_losses, ml_val_losses = ml_trainer.train(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=SIMULATION_PARAMS['EPOCHS'],\n",
        "            batch_size=SIMULATION_PARAMS['BATCH_SIZE']\n",
        "        )\n",
        "        print(\"✅ ML Decoder Training Completed\")\n",
        "\n",
        "        # 5. Training Performance Visualization\n",
        "        plot_training_performance(\n",
        "            rnn_train_losses,\n",
        "            rnn_val_losses,\n",
        "            ml_train_losses,\n",
        "            ml_val_losses\n",
        "        )\n",
        "        print(\"✅ Training Performance Plots Saved\")\n",
        "\n",
        "        # 6. Channel Simulators\n",
        "        channels = {\n",
        "            'AWGN': ChannelSimulator(channel_type='AWGN'),\n",
        "            'Rayleigh': ChannelSimulator(channel_type='Rayleigh')\n",
        "        }\n",
        "\n",
        "        # 7. Comprehensive Performance Plotting\n",
        "        plt.figure(figsize=(20, 15))\n",
        "\n",
        "        # Plot configurations\n",
        "        plot_configs = [\n",
        "            ('BER', 'Bit Error Rate', True),\n",
        "            ('BLER', 'Block Error Rate', False)\n",
        "        ]\n",
        "\n",
        "        channel_names = ['AWGN', 'Rayleigh']\n",
        "\n",
        "        for idx, (error_type, y_label, is_ber) in enumerate(plot_configs):\n",
        "            for channel_idx, channel_name in enumerate(channel_names):\n",
        "                plt.subplot(2, 2, idx * 2 + channel_idx + 1)\n",
        "\n",
        "                for decoder_name, decoder in [('RNN', rnn_trainer), ('ML', ml_trainer)]:\n",
        "                    for list_size in SIMULATION_PARAMS['LIST_SIZES']:\n",
        "                        # Compute performance\n",
        "                        ber, bler = compute_channel_performance(\n",
        "                            decoder,\n",
        "                            channels[channel_name],\n",
        "                            SIMULATION_PARAMS['SNR_RANGE'],\n",
        "                            polar_code_gen,\n",
        "                            list_size=list_size,\n",
        "                            num_trials=SIMULATION_PARAMS['NUM_TRIALS']\n",
        "                        )\n",
        "\n",
        "                        # Select the appropriate performance metric\n",
        "                        performance = ber if is_ber else bler\n",
        "\n",
        "                        plt.semilogy(\n",
        "                            SIMULATION_PARAMS['SNR_RANGE'],\n",
        "                            performance,\n",
        "                            label=f'{decoder_name} {error_type} (List={list_size})',\n",
        "                            marker='o'\n",
        "                        )\n",
        "\n",
        "                plt.title(f'{error_type} - {channel_name} Channel')\n",
        "                plt.xlabel('SNR (dB)')\n",
        "                plt.ylabel(y_label)\n",
        "                plt.ylim(1e-5, 1e0)\n",
        "                plt.legend()\n",
        "                plt.grid(True, which='both', ls='-', alpha=0.5)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('comprehensive_performance.png', dpi=300)\n",
        "        plt.close()\n",
        "        print(\"✅ Comprehensive Performance Plots Saved\")\n",
        "\n",
        "        print(\"🎉 Simulation Complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🆘 Comprehensive Simulation Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "Key Features:"
      ],
      "metadata": {
        "id": "5wSEwXDqLAQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1-OixOfGdn0D",
        "outputId": "a6e38ecd-7c22-4200-8379-353e5e9d401c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd59f27f-cbff-4865-afe3-ed9b8026ff42\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd59f27f-cbff-4865-afe3-ed9b8026ff42\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving MLPolarKSALT.py to MLPolarKSALT.py\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}